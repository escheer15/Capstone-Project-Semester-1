{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semester 1 Project Submission\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elliot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here - remember to use markdown cells for comments as well!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Items to be Resolved:\n",
    "- Check for nulls in the sql database tables being used\n",
    "    - See following cell for findings.\n",
    "- Resolve found nulls \n",
    "    - Rows where null can be excluded. This is due to size and number of entries in dataset tables.\n",
    "- Experiment with joins to get tables wanted\n",
    "    - Joined movie_basics with movie_ratings. Tried further joins but they get very large, very quickly (even using inner joins).\n",
    "- Export joined tables to dataframe\n",
    "    - Complete.\n",
    "- Determine how to best use data for analysis\n",
    "    - Complete.\n",
    "    \n",
    "### Hypothesis Testing Checklist\n",
    "- Test runtime to domestic revenue and worldwide revenue - Complete.\n",
    "    - Runtime to revenue would assist with recommending best length of film to make for optimal revenue outlook\n",
    "- Break down runtime into buckets of time periods to calculate for correlation - Complete.\n",
    "    - Will isolate periods with best correlation to complement observations from runtime and revenue correlation tests.\n",
    "____________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Observations and Exploration\n",
    "\n",
    "- persons % bunch of null values in birth_year, death_year, and in primary_profession\n",
    "- writers % NONE ARE NULL\n",
    "- directors % NONE ARE NULL\n",
    "- known_for % NONE ARE NULL\n",
    "- principals % NO NULLS IN CATEGORY\n",
    "- movie_basics % missing data in genres, runtime_minutes\n",
    "- movie_ratings % NONE ARE NULL\n",
    "- movie_akas % NO TITLES ARE NULL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating connection to database\n",
    "conn = sql.connect(\"databases/im.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# movie basics query stage 1\n",
    "q = \"\"\"\n",
    "SELECT\n",
    "    *\n",
    "FROM\n",
    "    movie_basics\n",
    "/*where statement below reduces dataset from 146144 rows to 112233*/\n",
    "WHERE\n",
    "    runtime_minutes IS NOT NULL AND genres IS NOT NULL\n",
    ";\"\"\"\n",
    "pd.read_sql(q, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test to see how many values of each genre there are\n",
    "q = \"\"\"\n",
    "SELECT\n",
    "    *\n",
    "FROM\n",
    "    movie_basics\n",
    "/*where statement below reduces dataset from 146144 rows to 112233*/\n",
    "WHERE\n",
    "    runtime_minutes IS NOT NULL AND genres IS NOT NULL\n",
    ";\"\"\"\n",
    "test2_df = pd.read_sql(q, conn)\n",
    "test2_df.value_counts('genres')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# movie ratings query stage 1\n",
    "q = \"\"\"\n",
    "SELECT\n",
    "    *\n",
    "FROM\n",
    "    movie_ratings\n",
    "/*where statement below reduces dataset from 73856 rows to 73856 NO NULLS*/\n",
    "WHERE\n",
    "    averagerating IS NOT NULL AND numvotes IS NOT NULL\n",
    ";\"\"\"\n",
    "pd.read_sql(q, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# movie_akas query stage 1\n",
    "q = \"\"\"\n",
    "SELECT\n",
    "    *\n",
    "FROM\n",
    "    movie_akas\n",
    "/*where statement below reduces dataset from 331703 rows to 331703 NO NULLS*/\n",
    "WHERE\n",
    "    title IS NOT NULL\n",
    ";\"\"\"\n",
    "pd.read_sql(q, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# persons table query stage 1\n",
    "q = \"\"\"\n",
    "SELECT\n",
    "    *\n",
    "FROM\n",
    "    persons\n",
    "WHERE\n",
    "    primary_profession IS NULL\n",
    ";\"\"\"\n",
    "pd.read_sql(q, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# principals exploration query\n",
    "q = \"\"\"\n",
    "SELECT\n",
    "    *\n",
    "FROM\n",
    "    principals\n",
    ";\"\"\"\n",
    "pd.read_sql(q, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# principals category query\n",
    "q = \"\"\"\n",
    "SELECT\n",
    "    movie_id, person_id, category\n",
    "FROM\n",
    "    principals\n",
    ";\"\"\"\n",
    "test1_df = pd.read_sql(q, conn)\n",
    "test1_df.value_counts('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directors exploration query\n",
    "q = \"\"\"\n",
    "SELECT\n",
    "    *\n",
    "FROM\n",
    "    directors\n",
    ";\"\"\"\n",
    "pd.read_sql(q, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# known_for exploration query\n",
    "q = \"\"\"\n",
    "SELECT\n",
    "    *\n",
    "FROM\n",
    "    known_for\n",
    ";\"\"\"\n",
    "pd.read_sql(q, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consolidation Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining movie basics and movie ratings\n",
    "q = \"\"\"\n",
    "SELECT\n",
    "    mb.primary_title\n",
    "    ,mb.runtime_minutes\n",
    "    ,mb.genres\n",
    "    ,mr.averagerating AS AverageRating\n",
    "    ,mr.numvotes AS Num_Votes\n",
    "FROM\n",
    "    movie_basics AS mb\n",
    "    JOIN movie_ratings AS mr\n",
    "        USING(movie_id)\n",
    "WHERE\n",
    "    CAST(Num_Votes AS int) > 30\n",
    "    AND mb.runtime_minutes IS NOT NULL\n",
    "ORDER BY\n",
    "    mr.averagerating DESC\n",
    ";\"\"\"\n",
    "pd.read_sql(q, conn)\n",
    "# added in a filter that would filter out rows that have less than 30 votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining movie basics and movie ratings\n",
    "q = \"\"\"\n",
    "SELECT\n",
    "    mb.primary_title, mb.runtime_minutes, mb.genres, mr.averagerating\n",
    "FROM\n",
    "    movie_basics AS mb\n",
    "    JOIN movie_ratings AS mr\n",
    "        USING(movie_id)\n",
    "WHERE\n",
    "    CAST(averagerating AS float) == 10\n",
    "    AND runtime_minutes IS NOT NULL\n",
    "ORDER BY\n",
    "    mr.averagerating DESC\n",
    ";\"\"\"\n",
    "# checking to see titles with a rating of 10.0\n",
    "# update to above comment: restricting num_votes by 30 (like above) will\n",
    "test3_df = pd.read_sql(q, conn)\n",
    "test3_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# persons to principals to movie table NO FILTERS\n",
    "q = \"\"\"\n",
    "SELECT \n",
    "    pe.person_id\n",
    "    ,pe.primary_name\n",
    "    ,AVG(mr.averagerating) AS AverageRating\n",
    "    ,COUNT(mb.primary_title) AS Num_of_Appearances\n",
    "FROM\n",
    "    persons AS pe\n",
    "    JOIN principals AS pr\n",
    "        USING(person_id)\n",
    "    JOIN movie_basics AS mb\n",
    "        USING(movie_id)\n",
    "    JOIN movie_ratings as mr\n",
    "        USING(movie_id)\n",
    "GROUP BY\n",
    "    pe.primary_name\n",
    "ORDER BY\n",
    "    Num_of_Appearances DESC\n",
    "LIMIT 10\n",
    ";\"\"\"\n",
    "pd.read_sql(q, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding the average ratings per film and num of appearances for writers\n",
    "q = \"\"\"\n",
    "SELECT \n",
    "    pe.person_id\n",
    "    ,pr.category\n",
    "    ,pe.primary_name\n",
    "    ,AVG(mr.averagerating) AS AverageRating\n",
    "    ,COUNT(mb.primary_title) AS Num_of_Appearances\n",
    "FROM\n",
    "    persons AS pe\n",
    "    JOIN principals AS pr\n",
    "        USING(person_id)\n",
    "    JOIN movie_basics AS mb\n",
    "        USING(movie_id)\n",
    "    JOIN movie_ratings as mr\n",
    "        USING(movie_id)\n",
    "WHERE\n",
    "    pr.category = 'writer'\n",
    "    \n",
    "GROUP BY\n",
    "    pe.primary_name\n",
    "ORDER BY\n",
    "    Num_of_Appearances DESC\n",
    ";\"\"\"\n",
    "pd.read_sql(q, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding the average ratings per film and num of appearances for directors\n",
    "q = \"\"\"\n",
    "SELECT \n",
    "    pe.person_id\n",
    "    ,pr.category\n",
    "    ,pe.primary_name\n",
    "    ,AVG(mr.averagerating) AS AverageRating\n",
    "    ,COUNT(mb.primary_title) AS Num_of_Appearances\n",
    "FROM\n",
    "    persons AS pe\n",
    "    JOIN principals AS pr\n",
    "        USING(person_id)\n",
    "    JOIN movie_basics AS mb\n",
    "        USING(movie_id)\n",
    "    JOIN movie_ratings as mr\n",
    "        USING(movie_id)\n",
    "WHERE\n",
    "    pr.category = 'director'\n",
    "    \n",
    "GROUP BY\n",
    "    pe.primary_name\n",
    "HAVING\n",
    "    CAST(Num_of_Appearances AS int) > 1\n",
    "ORDER BY\n",
    "    Num_of_Appearances DESC\n",
    ";\"\"\"\n",
    "pd.read_sql(q, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding the average ratings per film and num of appearances for lead actor/actress\n",
    "# lead actor/actress is found by filtering on principals' column called ordering for the 1st actor\n",
    "q = \"\"\"\n",
    "SELECT \n",
    "    pe.person_id\n",
    "    ,pr.category\n",
    "    ,pe.primary_name\n",
    "    ,AVG(mr.averagerating) AS AverageRating\n",
    "    ,COUNT(mb.primary_title) AS Num_of_Appearances\n",
    "FROM\n",
    "    persons AS pe\n",
    "    JOIN principals AS pr\n",
    "        USING(person_id)\n",
    "    JOIN movie_basics AS mb\n",
    "        USING(movie_id)\n",
    "    JOIN movie_ratings as mr\n",
    "        USING(movie_id)\n",
    "WHERE\n",
    "    pr.category IN ('actor', 'actress')\n",
    "    AND CAST(AverageRating AS float) >= 6\n",
    "    AND CAST(pr.ordering AS int) == 1\n",
    "GROUP BY\n",
    "    pe.primary_name\n",
    "HAVING\n",
    "    CAST(Num_of_Appearances AS int) > 2\n",
    "ORDER BY\n",
    "    Num_of_Appearances DESC\n",
    ";\"\"\"\n",
    "# filtering for only actor/actresses who had an average rating of 6 or greater\n",
    "pd.read_sql(q, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding the average ratings per film and num of appearances for actor/actress\n",
    "q = \"\"\"\n",
    "SELECT \n",
    "    pe.person_id\n",
    "    ,pr.category\n",
    "    ,pe.primary_name\n",
    "    ,AVG(mr.averagerating) AS AverageRating\n",
    "    ,COUNT(mb.primary_title) AS Num_of_Appearances\n",
    "FROM\n",
    "    persons AS pe\n",
    "    JOIN principals AS pr\n",
    "        USING(person_id)\n",
    "    JOIN movie_basics AS mb\n",
    "        USING(movie_id)\n",
    "    JOIN movie_ratings as mr\n",
    "        USING(movie_id)\n",
    "WHERE\n",
    "    pr.category IN ('actor', 'actress')\n",
    "    AND CAST(AverageRating AS float) >= 6\n",
    "GROUP BY\n",
    "    pe.primary_name\n",
    "HAVING\n",
    "    CAST(Num_of_Appearances AS int) > 2\n",
    "ORDER BY\n",
    "    Num_of_Appearances DESC\n",
    ";\"\"\"\n",
    "# filtering for only actor/actresses who had an average rating of 6 or greater\n",
    "pd.read_sql(q, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# finding the average ratings per film and num of appearances for producer\n",
    "# hard to quantify where to limit here regarding appearances -- producers often only produce once, apparently\n",
    "q = \"\"\"\n",
    "SELECT \n",
    "    pe.person_id\n",
    "    ,pr.category\n",
    "    ,pe.primary_name\n",
    "    ,AVG(mr.averagerating) AS AverageRating\n",
    "    ,COUNT(mb.primary_title) AS Num_of_Appearances\n",
    "FROM\n",
    "    persons AS pe\n",
    "    JOIN principals AS pr\n",
    "        USING(person_id)\n",
    "    JOIN movie_basics AS mb\n",
    "        USING(movie_id)\n",
    "    JOIN movie_ratings as mr\n",
    "        USING(movie_id)\n",
    "WHERE\n",
    "    pr.category = 'producer'\n",
    "    AND CAST(AverageRating AS float) >= 6\n",
    "GROUP BY\n",
    "    pe.primary_name\n",
    "HAVING\n",
    "    CAST(Num_of_Appearances AS int) > 1\n",
    "ORDER BY\n",
    "    AverageRating DESC\n",
    ";\"\"\"\n",
    "pd.read_sql(q, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to Check for Statistically Significant Correlation\n",
    "\n",
    "1. State your null and alternative hypotheses, along with your alpha.\n",
    "2. Retrieve the sample being tested\n",
    "3. Calculate the test statistic, r\n",
    "4. Calculate degrees of freedom and find r-critical using table or calculator (source I used since we have large datasets with degrees of freedom that are hard to find on a table and I could not locate a stastical package to calculate the r-critical in-notebook): https://www.calculators.tech/t-value-calculator)\n",
    "5. If the absolute value of r is greater than r-critical, the correlation is statistically significant and we reject the null hypothesis. If the absolute value of r is less than r-critical, the correlation is not statistically signifcant and we fail to reject the null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Runtime and Average Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# added WHERE clause to remove movies from dataframe if longer than 3.5 hours - took away 65 values from dataset\n",
    "# and reduced runtime mean, std dev.!\n",
    "q = \"\"\"\n",
    "SELECT\n",
    "    mb.movie_id\n",
    "    ,mb.primary_title AS title\n",
    "    ,mb.runtime_minutes AS Runtime\n",
    "    ,mb.genres\n",
    "    ,mr.averagerating AS AverageRating\n",
    "    ,mr.numvotes AS Num_Votes\n",
    "FROM\n",
    "    movie_basics AS mb\n",
    "    JOIN movie_ratings AS mr\n",
    "        USING(movie_id)\n",
    "WHERE\n",
    "    CAST(Num_Votes AS int) > 30\n",
    "    AND CAST(mb.runtime_minutes as float) <= 210\n",
    "    AND mb.runtime_minutes IS NOT NULL\n",
    "    AND mb.genres IS NOT NULL\n",
    "ORDER BY\n",
    "    mb.runtime_minutes DESC\n",
    ";\"\"\"\n",
    "df_allrt = pd.read_sql(q, conn)\n",
    "df_allrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_allrt.duplicated().value_counts() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ho:\n",
    "##### - There is no correlation between runtime and average rating. \n",
    "\n",
    "### Ha:\n",
    "##### - There is a statistically significant correlation between runtime and average rating at the 95% level. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_allrt['Runtime'].count() - 2 # getting degrees of freedom to determine r-critical\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r-critical value to test if found r is statistically signifcant\n",
    "critical_r = 0.0081\n",
    "# Source: https://www.calculators.tech/t-value-calculator\n",
    "# (Unable to calculate by hand as I have been unable to find a direct formula to find this - must use either r-critical table or a r-crit calculator like the above source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# calculating correlation\n",
    "\n",
    "x = df_allrt['Runtime']\n",
    "y = df_allrt['AverageRating']\n",
    "\n",
    "r = x.corr(y) # result is the pearson correlation coefficient -- seems we do have a positive correlation!\n",
    "r\n",
    "\n",
    "print(f'Pearson Correlation: {r} | r-critical: {critical_r} | Is r greater? {abs(r) >= critical_r}')\n",
    "if abs(r) >= critical_r:\n",
    "    print(\"Reject the null\")\n",
    "elif abs(r) < critical_r:\n",
    "    print(\"Fail to reject null\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"talk\")\n",
    "sns.lmplot(x=\"Runtime\", y=\"AverageRating\", data=df_allrt, line_kws={'color': 'red'}, height=8, aspect=1.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion:\n",
    "- For 95% of cases, there is a weak positive correlation of 0.1014 between runtime and rating.\n",
    "- Now, we will drill in further to observe individual groupings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operating Notion with Runtime Samples:\n",
    "- \"The Academy of Motion Picture Arts and Sciences defines a feature as a film that runs for more than 40 minutes (with short films being 40 or fewer minutes). Still, the Screen Actors Guild asserts that a feature's running time is 60 minutes, so there's not exactly a widespread agreement.\"\n",
    "\n",
    "Source: https://www.arcstudiopro.com/blog/what-is-a-feature-film#:~:text=The%20Academy%20of%20Motion%20Picture,not%20exactly%20a%20widespread%20agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardizing population for secondary visualizations to follow\n",
    "mu = df_allrt['AverageRating'].mean()\n",
    "std = df_allrt['AverageRating'].std()\n",
    "\n",
    "pop_standardized_rating = [(x-mu)/std for x in df_allrt['AverageRating']]\n",
    "pop_z_mean = np.mean(pop_standardized_rating)\n",
    "pop_z_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Less than 40 Minutes Testing\n",
    "\n",
    "### Z-Test\n",
    "\n",
    "### Ho:\n",
    "##### - There is no difference between the average rating of a movie that has a runtime of less than 40 minutes and other movies in the population.\n",
    "\n",
    "### Ha:\n",
    "##### - There is a statistically significant difference between the average rating of a movie that has a runtime of less than 40 minutes and the population. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# runtime sample 1 - short films (between 0 and 40 minutes)\n",
    "q = \"\"\"\n",
    "SELECT\n",
    "    mb.movie_id\n",
    "    ,mb.primary_title AS title\n",
    "    ,mb.runtime_minutes AS Runtime\n",
    "    ,mb.genres\n",
    "    ,mr.averagerating AS AverageRating\n",
    "    ,mr.numvotes AS Num_Votes\n",
    "FROM\n",
    "    movie_basics AS mb\n",
    "    JOIN movie_ratings AS mr\n",
    "        USING(movie_id)\n",
    "WHERE\n",
    "    CAST(Num_Votes AS int) > 30\n",
    "    AND CAST(mb.runtime_minutes as float) <= 40\n",
    "    AND mb.runtime_minutes IS NOT NULL\n",
    "    AND mb.genres IS NOT NULL\n",
    "    AND mb.primary_title != 'The Death of a Security Guard'\n",
    "ORDER BY\n",
    "    mb.runtime_minutes DESC\n",
    ";\"\"\"\n",
    "df_up40 = pd.read_sql(q, conn)\n",
    "df_up40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z-test - less than 40 minutes ratings run\n",
    "\n",
    "# two-tailed z-test\n",
    "\n",
    "a = 0.025\n",
    "\n",
    "x_bar = df_up40['AverageRating'].mean()\n",
    "n = df_up40['AverageRating'].count()\n",
    "std = df_allrt['AverageRating'].std()\n",
    "mu = df_allrt['AverageRating'].mean()\n",
    "\n",
    "z = (x_bar - mu)/(std/np.sqrt(n))\n",
    "p = 1 - stats.norm.cdf(np.absolute(z))\n",
    "\n",
    "# displaying results\n",
    "print(f'Sample Mean: {x_bar} | Population Mean: {mu} | Sample Size: {n}')\n",
    "print(f'p-value: {p} | z-score: {z} | Is p less than alpha? {p < a}')\n",
    "if p < a:\n",
    "    print(\"Reject the null\")\n",
    "elif p >= a:\n",
    "    print(\"Fail to reject null\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing distribution with for loop\n",
    "samp_standardized_rating = [(x-mu)/std for x in df_up40['AverageRating']]\n",
    "z_mean = np.mean(samp_standardized_rating)\n",
    "print(f' Standardized Sample Mean: {z_mean}')\n",
    "\n",
    "# visualizing above distribution as histogram\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "\n",
    "ax.hist(samp_standardized_rating, bins=11, density=True, color='r', alpha=0.9)\n",
    "ax.set_xlabel('Z Scores')\n",
    "ax.set_title('Less than 40 Minutes - Ratings')\n",
    "\n",
    "# applying normalized curve over histogram\n",
    "sns.kdeplot(samp_standardized_rating, ax=ax, color='k')\n",
    "\n",
    "# marking standardized_mean\n",
    "ax.vlines(x=z_mean, ymin=0, ymax=0.7, color='b', label='Mean: 0.7702')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting tested runtime sample against population\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "\n",
    "plt.hist(pop_standardized_rating, bins=45, density=True, color='b', alpha = 0.5)\n",
    "sns.kdeplot(pop_standardized_rating, ax=ax, color='y')\n",
    "\n",
    "plt.hist(samp_standardized_rating, bins=11, density=True, color='r', alpha = 0.5)\n",
    "sns.kdeplot(samp_standardized_rating, ax=ax, color='k')\n",
    "\n",
    "plt.vlines(x=z_mean, ymin=0, ymax=0.7, color='m', label='x<=40 Mean: 0.7702')\n",
    "plt.vlines(x=pop_z_mean, ymin=0, ymax=0.7, label='Population Mean: 0.0')\n",
    "                                              \n",
    "plt.xlabel('Z Scores')\n",
    "plt.title('Less than 40 Minutes to All Films - Ratings')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation\n",
    "\n",
    "### Ho:\n",
    "##### - There is no correlation between runtime and average rating for movies that are less than 40 minutes. \n",
    "\n",
    "### Ha:\n",
    "##### - There is a statistically significant correlation between runtime and average rating at the 95% level for movies that are less than 40 minutes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r-critical value to test if found r is statistically signifcant\n",
    "critical_r = 0.2510\n",
    "# Source: https://www.calculators.tech/t-value-calculator\n",
    "# (Unable to calculate by hand as I have been unable to find a direct formula to find this - must use either r-critical table or a r-crit calculator like the above source)\n",
    "df = df_up40['Runtime'].count() - 2 # getting degrees of freedom to determine r-critical\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating correlation\n",
    "\n",
    "x = df_up40['Runtime']\n",
    "y = df_up40['AverageRating']\n",
    "\n",
    "r = x.corr(y) # result is the pearson correlation coefficient\n",
    "r\n",
    "\n",
    "print(f'Pearson Correlation: {r} | r-critical: {critical_r} | Is r greater? {abs(r) >= critical_r}')\n",
    "if abs(r) >= critical_r:\n",
    "    print(\"Reject the null\")\n",
    "elif abs(r) < critical_r:\n",
    "    print(\"Fail to reject null\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x=\"Runtime\", y=\"AverageRating\", data=df_up40, line_kws={'color': 'red'}, height=8, aspect=1.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 40 to 60 Minutes Testing\n",
    "\n",
    "### Z-Test\n",
    "\n",
    "### Ho:\n",
    "##### - There is no difference between the average rating of a movie that has a runtime of between 40 minutes and 60 minutes and other movies in the population.\n",
    "\n",
    "### Ha:\n",
    "##### - There is a statistically significant difference between the average rating of a movie that has a runtime of between 40 minutes and 60 minutes and other movies in the population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# runtime sample 2 - long-form short films (40.0001 minutes to 60 minutes)\n",
    "q = \"\"\"\n",
    "SELECT\n",
    "    mb.movie_id\n",
    "    ,mb.primary_title AS title\n",
    "    ,mb.runtime_minutes AS Runtime\n",
    "    ,mb.genres\n",
    "    ,mr.averagerating AS AverageRating\n",
    "    ,mr.numvotes AS Num_Votes\n",
    "FROM\n",
    "    movie_basics AS mb\n",
    "    JOIN movie_ratings AS mr\n",
    "        USING(movie_id)\n",
    "WHERE\n",
    "    CAST(Num_Votes AS int) > 30\n",
    "    AND CAST(mb.runtime_minutes as float) BETWEEN 40.0001 AND 60\n",
    "    AND mb.runtime_minutes IS NOT NULL\n",
    "    AND mb.genres IS NOT NULL\n",
    "ORDER BY\n",
    "    mb.runtime_minutes DESC\n",
    ";\"\"\"\n",
    "df_4060 = pd.read_sql(q, conn)\n",
    "df_4060"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# z-test - 40 to 60 minutes ratings run\n",
    "\n",
    "a = 0.025\n",
    "\n",
    "# two-tailed z-test\n",
    "\n",
    "x_bar = df_4060['AverageRating'].mean()\n",
    "n = df_4060['AverageRating'].count()\n",
    "std = df_allrt['AverageRating'].std()\n",
    "mu = df_allrt['AverageRating'].mean()\n",
    "\n",
    "z = (x_bar - mu)/(std/np.sqrt(n))\n",
    "p = 1 - stats.norm.cdf(np.absolute(z))\n",
    "\n",
    "# displaying results\n",
    "print(f'Sample Mean: {x_bar} | Population Mean: {mu} | Sample Size: {n}')\n",
    "print(f'p-value: {p} | z-score: {z} | Is p less than alpha? {p < a}')\n",
    "if p < a:\n",
    "    print(\"Reject the null\")\n",
    "elif p >= a:\n",
    "    print(\"Fail to reject null\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing distribution with for loop\n",
    "samp_standardized_rating = [(x-mu)/std for x in df_4060['AverageRating']]\n",
    "z_mean = np.mean(samp_standardized_rating)\n",
    "print(f' Standardized Sample Mean: {z_mean}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizing above distribution as histogram\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "\n",
    "ax.hist(samp_standardized_rating, bins=15, density=True, color='r')\n",
    "ax.set_xlabel('Z Scores')\n",
    "ax.set_title('40 to 60 Minutes - Ratings')\n",
    "\n",
    "# applying normalized curve over histogram\n",
    "sns.kdeplot(samp_standardized_rating, ax=ax, color='k')\n",
    "\n",
    "# marking standardized_mean\n",
    "ax.vlines(x=z_mean, ymin=0, ymax=0.7, color='b', label='Mean: 0.6132')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting tested runtime sample against population\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "\n",
    "plt.hist(pop_standardized_rating, bins=45, density=True, color='b', alpha = 0.5)\n",
    "sns.kdeplot(pop_standardized_rating, ax=ax, color='y')\n",
    "\n",
    "plt.hist(samp_standardized_rating, bins=15, density=True, color='r', alpha = 0.5)\n",
    "sns.kdeplot(samp_standardized_rating, ax=ax, color='k')\n",
    "\n",
    "plt.vlines(x=z_mean, ymin=0, ymax=0.7, color='m', label='40 < x <= 60 Mean: 0.6132')\n",
    "plt.vlines(x=pop_z_mean, ymin=0, ymax=0.7, label='Population Mean: 0.0')\n",
    "                                              \n",
    "plt.xlabel('Z Scores')\n",
    "plt.title('40 to 60 Minutes to All Films - Ratings')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation\n",
    "\n",
    "### Ho:\n",
    "##### - There is no correlation between runtime and average rating for movies that are between 40 and 60 minutes. \n",
    "\n",
    "### Ha:\n",
    "##### - There is a statistically significant correlation between runtime and average rating at the 95% level for movies that are between 40 and 60 minutes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r-critical value to test if found r is statistically signifcant\n",
    "critical_r = 0.0529\n",
    "# Source: https://www.calculators.tech/t-value-calculator\n",
    "# (Unable to calculate by hand as I have been unable to find a direct formula to find this - must use either r-critical table or a r-crit calculator like the above source)\n",
    "df = df_4060['Runtime'].count() - 2 # getting degrees of freedom to determine r-critical\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# calculating correlation\n",
    "\n",
    "x = df_4060['Runtime']\n",
    "y = df_4060['AverageRating']\n",
    "\n",
    "r = x.corr(y) # result is the pearson correlation coefficient\n",
    "r\n",
    "\n",
    "print(f'Pearson Correlation: {r} | r-critical: {critical_r} | Is r greater? {abs(r) >= critical_r}')\n",
    "if abs(r) >= critical_r:\n",
    "    print(\"Reject the null\")\n",
    "elif abs(r) < critical_r:\n",
    "    print(\"Fail to reject null\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.lmplot(x=\"Runtime\", y=\"AverageRating\", data=df_4060, line_kws={'color': 'red'}, height=8, aspect=1.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 60 to 90 Minutes Testing\n",
    "\n",
    "### Z-Test\n",
    "\n",
    "### Ho:\n",
    "##### - There is no difference between the average rating of a movie that has a runtime of between 60 minutes and 90 minutes and other movies in the population.\n",
    "\n",
    "### Ha:\n",
    "##### - There is a statistically significant difference between the average rating of a movie that has a runtime of between 60 minutes and 90 minutes and other movies in the population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# runtime sample 3 - short-mid length films (60.0001 minutes to 90 minutes)\n",
    "q = \"\"\"\n",
    "SELECT\n",
    "    mb.movie_id\n",
    "    ,mb.primary_title AS title\n",
    "    ,mb.runtime_minutes AS Runtime\n",
    "    ,mb.genres\n",
    "    ,mr.averagerating AS AverageRating\n",
    "    ,mr.numvotes AS Num_Votes\n",
    "FROM\n",
    "    movie_basics AS mb\n",
    "    JOIN movie_ratings AS mr\n",
    "        USING(movie_id)\n",
    "WHERE\n",
    "    CAST(Num_Votes AS int) > 30\n",
    "    AND CAST(mb.runtime_minutes as float) BETWEEN 60.0001 AND 90\n",
    "    AND mb.runtime_minutes IS NOT NULL\n",
    "    AND mb.genres IS NOT NULL\n",
    "ORDER BY\n",
    "    mb.runtime_minutes DESC\n",
    ";\"\"\"\n",
    "df_6090 = pd.read_sql(q, conn)\n",
    "df_6090"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# z-test - 60 to 90 minutes ratings run\n",
    "\n",
    "a = 0.025\n",
    "\n",
    "# two-tailed z-test\n",
    "\n",
    "x_bar = df_6090['AverageRating'].mean()\n",
    "n = df_6090['AverageRating'].count()\n",
    "std = df_allrt['AverageRating'].std()\n",
    "mu = df_allrt['AverageRating'].mean()\n",
    "\n",
    "z = (x_bar - mu)/(std/np.sqrt(n))\n",
    "p = 1 - stats.norm.cdf(np.absolute(z))\n",
    "\n",
    "# displaying results\n",
    "print(f'Sample Mean: {x_bar} | Population Mean: {mu} | Sample Size: {n}')\n",
    "print(f'p-value: {p} | z-score: {z} | Is p less than alpha? {p < a}')\n",
    "if p < a:\n",
    "    print(\"Reject the null\")\n",
    "elif p >= a:\n",
    "    print(\"Fail to reject null\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing distribution with for loop\n",
    "samp_standardized_rating = [(x-mu)/std for x in df_6090['AverageRating']]\n",
    "z_mean = np.mean(samp_standardized_rating)\n",
    "print(f' Standardized Sample Mean: {z_mean}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizing above distribution as histogram\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "\n",
    "ax.hist(samp_standardized_rating, bins=22, density=True, color='r')\n",
    "ax.set_xlabel('Z Scores')\n",
    "ax.set_title('60 to 90 Minutes - Ratings')\n",
    "\n",
    "# applying normalized curve over histogram\n",
    "sns.kdeplot(samp_standardized_rating, ax=ax, color='k')\n",
    "\n",
    "# marking standardized_mean\n",
    "ax.vlines(x=z_mean, ymin=0, ymax=0.7, color='b', label='Mean: -0.1648')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting tested runtime sample against population\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "\n",
    "plt.hist(pop_standardized_rating, bins=45, density=True, color='b', alpha = 0.5)\n",
    "sns.kdeplot(pop_standardized_rating, ax=ax, color='y')\n",
    "\n",
    "plt.hist(samp_standardized_rating, bins=22, density=True, color='r', alpha = 0.5)\n",
    "sns.kdeplot(samp_standardized_rating, ax=ax, color='k')\n",
    "\n",
    "plt.vlines(x=z_mean, ymin=0, ymax=0.7, color='m', label='60 < x <= 90 Mean: -0.1648')\n",
    "plt.vlines(x=pop_z_mean, ymin=0, ymax=0.7, label='Population Mean: 0.0')\n",
    "                                              \n",
    "plt.xlabel('Z Scores')\n",
    "plt.title('60 to 90 Minutes to All Films - Ratings')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation\n",
    "\n",
    "### Ho:\n",
    "##### - There is no correlation between runtime and average rating for movies that are between 60 and 90 minutes. \n",
    "\n",
    "### Ha:\n",
    "##### - There is a statistically significant correlation between runtime and average rating at the 95% level for movies that are between 60 and 90 minutes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r-critical value to test if found r is statistically signifcant\n",
    "critical_r = 0.0132\n",
    "# Source: https://www.calculators.tech/t-value-calculator\n",
    "# (Unable to calculate by hand as I have been unable to find a direct formula to find this - must use either r-critical table or a r-crit calculator like the above source)\n",
    "df = df_6090['Runtime'].count() - 2 # getting degrees of freedom to determine r-critical\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating correlation\n",
    "\n",
    "x = df_6090['Runtime']\n",
    "y = df_6090['AverageRating']\n",
    "\n",
    "r = x.corr(y) # result is the pearson correlation coefficient\n",
    "r\n",
    "\n",
    "print(f'Pearson Correlation: {r} | r-critical: {critical_r} | Is r greater? {abs(r) >= critical_r}')\n",
    "if abs(r) >= critical_r:\n",
    "    print(\"Reject the null\")\n",
    "elif abs(r) < critical_r:\n",
    "    print(\"Fail to reject null\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x=\"Runtime\", y=\"AverageRating\", data=df_6090, line_kws={'color': 'red'}, height=8, aspect=1.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 90 to 120 Minutes Testing\n",
    "\n",
    "### Z-Test\n",
    "\n",
    "### Ho\n",
    "##### - There is no difference between the average rating of a movie that has a runtime of between 90 minutes and 120 minutes and other movies in the population.\n",
    "\n",
    "### Ha:\n",
    "##### - There is a statistically significant difference between the average rating of a movie that has a runtime of between 90 minutes and 120 minutes and other movies in the population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# runtime sample 4 - relative average length films (90.0001 minutes to 120 minutes)\n",
    "q = \"\"\"\n",
    "SELECT\n",
    "    mb.movie_id\n",
    "    ,mb.primary_title AS title\n",
    "    ,mb.runtime_minutes AS Runtime\n",
    "    ,mb.genres\n",
    "    ,mr.averagerating AS AverageRating\n",
    "    ,mr.numvotes AS Num_Votes\n",
    "FROM\n",
    "    movie_basics AS mb\n",
    "    JOIN movie_ratings AS mr\n",
    "        USING(movie_id)\n",
    "WHERE\n",
    "    CAST(Num_Votes AS int) > 30\n",
    "    AND CAST(mb.runtime_minutes as float) BETWEEN 90.0001 AND 120\n",
    "    AND mb.runtime_minutes IS NOT NULL\n",
    "    AND mb.genres IS NOT NULL\n",
    "ORDER BY\n",
    "    mb.runtime_minutes DESC\n",
    ";\"\"\"\n",
    "df_90120 = pd.read_sql(q, conn)\n",
    "df_90120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z-test - 90 to 120 minutes ratings run\n",
    "\n",
    "a = 0.025\n",
    "\n",
    "# two-tailed z-test\n",
    "\n",
    "x_bar = df_90120['AverageRating'].mean()\n",
    "n = df_90120['AverageRating'].count()\n",
    "std = df_allrt['AverageRating'].std()\n",
    "mu = df_allrt['AverageRating'].mean()\n",
    "\n",
    "z = (x_bar - mu)/(std/np.sqrt(n))\n",
    "p = 1 - stats.norm.cdf(np.absolute(z))\n",
    "\n",
    "# displaying results\n",
    "print(f'Sample Mean: {x_bar} | Population Mean: {mu} | Sample Size: {n}')\n",
    "print(f'p-value: {p} | z-score: {z} | Is p less than alpha? {p < a}')\n",
    "if p < a:\n",
    "    print(\"Reject the null\")\n",
    "elif p >= a:\n",
    "    print(\"Fail to reject null\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing distribution with for loop\n",
    "samp_standardized_rating = [(x-mu)/std for x in df_90120['AverageRating']]\n",
    "z_mean = np.mean(samp_standardized_rating)\n",
    "print(f' Standardized Sample Mean: {z_mean}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizing above distribution as histogram\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "\n",
    "ax.hist(samp_standardized_rating, bins=24, density=True, color='r')\n",
    "ax.set_xlabel('Z Scores')\n",
    "ax.set_title('90 to 120 minutes - Ratings')\n",
    "\n",
    "# applying normalized curve over histogram\n",
    "sns.kdeplot(samp_standardized_rating, ax=ax, color='k')\n",
    "\n",
    "# marking standardized_mean\n",
    "ax.vlines(x=z_mean, ymin=0, ymax=0.7, color='b', label='Mean: 0.0270')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting tested runtime sample against population\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "\n",
    "plt.hist(pop_standardized_rating, bins=45, density=True, color='b', alpha = 0.5)\n",
    "sns.kdeplot(pop_standardized_rating, ax=ax, color='y')\n",
    "\n",
    "plt.hist(samp_standardized_rating, bins=24, density=True, color='r', alpha = 0.5)\n",
    "sns.kdeplot(samp_standardized_rating, ax=ax, color='k')\n",
    "\n",
    "plt.vlines(x=z_mean, ymin=0, ymax=0.7, color='m', label='90 < x <= 120 Mean: 0.0270')\n",
    "plt.vlines(x=pop_z_mean, ymin=0, ymax=0.7, label='Population Mean: 0.0')\n",
    "                                              \n",
    "plt.xlabel('Z Scores')\n",
    "plt.title('90 to 120 minutes to All Films - Ratings')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation\n",
    "\n",
    "### Ho:\n",
    "##### - There is no correlation between runtime and average rating for movies that are between 90 and 120 minutes. \n",
    "\n",
    "### Ha:\n",
    "##### - There is a statistically significant correlation between runtime and average rating at the 95% level for movies that are between 90 and 120 minutes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r-critical value to test if found r is statistically signifcant\n",
    "critical_r = 0.0118\n",
    "# Source: https://www.calculators.tech/t-value-calculator\n",
    "# (Unable to calculate by hand as I have been unable to find a direct formula to find this - must use either r-critical table or a r-crit calculator like the above source)\n",
    "df = df_90120['Runtime'].count() - 2 # getting degrees of freedom to determine r-critical\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating correlation\n",
    "\n",
    "x = df_90120['Runtime']\n",
    "y = df_90120['AverageRating']\n",
    "\n",
    "r = x.corr(y) # result is the pearson correlation coefficient\n",
    "r\n",
    "\n",
    "print(f'Pearson Correlation: {r} | r-critical: {critical_r} | Is r greater? {abs(r) >= critical_r}')\n",
    "if abs(r) >= critical_r:\n",
    "    print(\"Reject the null\")\n",
    "elif abs(r) < critical_r:\n",
    "    print(\"Fail to reject null\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x=\"Runtime\", y=\"AverageRating\", data=df_90120, line_kws={'color': 'red'}, height=8, aspect=1.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 120 Minutes and Up Testing\n",
    "\n",
    "### Z-Test\n",
    "\n",
    "### Ho\n",
    "##### - There is no difference between the average rating of a movie that has a runtime of 120 minutes or greater and other movies in the population.\n",
    "\n",
    "### Ha:\n",
    "##### - There is a statistically significant difference between the average rating of a movie that has a runtime of 120 minutes or greater and other movies in the population at the 95% level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# runtime sample 5 - long length films (120.0001 minutes and up films)\n",
    "q = \"\"\"\n",
    "SELECT\n",
    "    mb.movie_id\n",
    "    ,mb.primary_title AS title\n",
    "    ,mb.runtime_minutes AS Runtime\n",
    "    ,mb.genres\n",
    "    ,mr.averagerating AS AverageRating\n",
    "    ,mr.numvotes AS Num_Votes\n",
    "FROM\n",
    "    movie_basics AS mb\n",
    "    JOIN movie_ratings AS mr\n",
    "        USING(movie_id)\n",
    "WHERE\n",
    "    CAST(Num_Votes AS int) > 30\n",
    "    AND CAST(mb.runtime_minutes as float) BETWEEN 120.0001 AND 210\n",
    "    AND mb.runtime_minutes IS NOT NULL\n",
    "    AND mb.genres IS NOT NULL\n",
    "ORDER BY\n",
    "    mb.runtime_minutes DESC\n",
    ";\"\"\"\n",
    "df_120up = pd.read_sql(q, conn)\n",
    "df_120up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z-test - 120 minutes and up ratings run\n",
    "\n",
    "a = 0.025\n",
    "\n",
    "# two-tailed z-test\n",
    "\n",
    "x_bar = df_120up['AverageRating'].mean()\n",
    "n = df_120up['AverageRating'].count()\n",
    "std = df_allrt['AverageRating'].std()\n",
    "mu = df_allrt['AverageRating'].mean()\n",
    "\n",
    "z = (x_bar - mu)/(std/np.sqrt(n))\n",
    "p = 1 - stats.norm.cdf(np.absolute(z))\n",
    "\n",
    "# displaying results\n",
    "print(f'Sample Mean: {x_bar} | Population Mean: {mu} | Sample Size: {n}')\n",
    "print(f'p-value: {p} | z-score: {z} | Is p less than alpha? {p < a}')\n",
    "if p < a:\n",
    "    print(\"Reject the null\")\n",
    "elif p >= a:\n",
    "    print(\"Fail to reject null\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing distribution with for loop\n",
    "samp_standardized_rating = [(x-mu)/std for x in df_120up['AverageRating']]\n",
    "z_mean = np.mean(samp_standardized_rating)\n",
    "print(f' Standardized Sample Mean: {z_mean}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizing above distribution as histogram\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "\n",
    "ax.hist(samp_standardized_rating, bins=15, density=True, color='r')\n",
    "ax.set_xlabel('Z Scores')\n",
    "ax.set_title('120 Minutes and Up - Ratings')\n",
    "\n",
    "# applying normalized curve over histogram\n",
    "sns.kdeplot(samp_standardized_rating, ax=ax, color='k')\n",
    "\n",
    "# marking standardized_mean\n",
    "ax.vlines(x=z_mean, ymin=0, ymax=0.7, color='b', label='Mean: 0.2899')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting tested runtime sample against population\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "\n",
    "plt.hist(pop_standardized_rating, bins=45, density=True, color='b', alpha = 0.5)\n",
    "sns.kdeplot(pop_standardized_rating, ax=ax, color='y')\n",
    "\n",
    "plt.hist(samp_standardized_rating, bins=15, density=True, color='r', alpha = 0.5)\n",
    "sns.kdeplot(samp_standardized_rating, ax=ax, color='k')\n",
    "\n",
    "plt.vlines(x=z_mean, ymin=0, ymax=0.7, color='m', label='120 < x Mean: 0.2899')\n",
    "plt.vlines(x=pop_z_mean, ymin=0, ymax=0.7, label='Population Mean: 0.0')\n",
    "                                              \n",
    "plt.xlabel('Z Scores')\n",
    "plt.title('120 Minutes and Up to All Films - Ratings')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation:\n",
    "\n",
    "##### Ho:\n",
    "##### - There is no correlation between runtime and average rating for movies that are 120 minutes or longer. \n",
    "\n",
    "##### Ha:\n",
    "##### - There is a statistically significant correlation between runtime and average rating at the 95% level for movies that are 120 minutes or longer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r-critical value to test if found r is statistically signifcant\n",
    "critical_r = 0.0235\n",
    "# Source: https://www.calculators.tech/t-value-calculator\n",
    "# (Unable to calculate by hand as I have been unable to find a direct formula to find this - must use either r-critical table or a r-crit calculator like the above source)\n",
    "df = df_120up['Runtime'].count() - 2 # getting degrees of freedom to determine r-critical\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating correlation\n",
    "\n",
    "x = df_120up['Runtime']\n",
    "y = df_120up['AverageRating']\n",
    "\n",
    "r = x.corr(y) # result is the pearson correlation coefficient\n",
    "r\n",
    "\n",
    "print(f'Pearson Correlation: {r} | r-critical: {critical_r} | Is r greater? {abs(r) >= critical_r}')\n",
    "if abs(r) >= critical_r:\n",
    "    print(\"Reject the null\")\n",
    "elif abs(r) < critical_r:\n",
    "    print(\"Fail to reject null\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the regression showing the line of best fit with slope of r\n",
    "sns.lmplot(x=\"Runtime\", y=\"AverageRating\", data=df_120up, line_kws={'color': 'red'}, height=8, aspect=1.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions from Runtime Sample Testing for Average Ratings\n",
    "\n",
    "Z-Tests:\n",
    "- For films that are less than 40 minute runtimes, we can reject the null hypothesis with a statistically significant p-value of 0.0000001193, meaning that in 95% of cases we can expect our average ratings to be higher because of this set of runtimes.\n",
    "    ##### - Reject the Null\n",
    "- For films that have between 40 and 60 minute runtimes, we can reject the null hypothesis with a statistically significant p-value of 0.0, meaning that in 95% of cases we can expect our average ratings to be higher because of this set of runtimes.\n",
    "    ##### - Reject the Null\n",
    "- For films that have between 60 and 90 minute runtimes, we can reject the null hypothesis with a statistically significant p-value of 0.0, meaning that in 95% of cases we can expect our average ratings to be lower because of this set of runtimes.\n",
    "    ##### - Reject the Null\n",
    "- For films that have between 90 and 120 minute runtimes, we can reject the null hypothesis with a statistically significant p-value of 0.00008571, meaning that in 95% of cases we can expect our average ratings to be higher because of this set of runtimes.\n",
    "    ##### - Reject the Null\n",
    "- For films that have either 120 minute runtimes or longer, we can reject the null hypothesis with a statistically significant p-value of 0.0, meaning that in 95% of cases we can expect our average ratings to be higher because of this set of runtimes.\n",
    "    ##### - Reject the Null\n",
    "\n",
    "Correlation:\n",
    "- In 95% of cases, movies that 90 minutes or longer have a weak positive correlation between their runtime and their ratings. \n",
    "- In 95% of cases, movies that last between 60 and 90 minutes have a weak negative correlation between their runtime and ratings.\n",
    "- For movies that are less than 60 minutes long, we cannot conclude that there is a statistically significant correlation either.\n",
    "\n",
    "For all films less than 3.5 hours long (where we cut off movie runtimes that client would be unlikely to want to pursue), there is a statistically significant weak positive correlation between runtime and average rating of a film in 95% of cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging Data from SQL IMdb and Box Office Records (Elliot's Effort)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Domestic Revenue per Rating Table \n",
    "- Merging on title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# merging dr_movie_db with the sql database data\n",
    "domgross_im_db = dr_movie_db.merge(df_allrt,how='inner',on='title')\n",
    "domgross_im_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# checking for unintentionally duplicated values\n",
    "domgross_im_db.duplicated('title').value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dropping found unintentionally duplicated values\n",
    "domgross_im_db = domgross_im_db.drop_duplicates(subset='title')\n",
    "domgross_im_db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis for Runtime and Domestic Gross Revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardizing population for secondary visualizations to follow\n",
    "mu = domgross_im_db['domestic_gross'].mean()\n",
    "std = domgross_im_db['domestic_gross'].std()\n",
    "\n",
    "pop_standardized_rating = [(x-mu)/std for x in domgross_im_db['domestic_gross']]\n",
    "pop_z_mean = np.mean(pop_standardized_rating)\n",
    "pop_z_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Up to 40 Minutes Testing\n",
    "\n",
    "### Z-Test\n",
    "\n",
    "### Ho:\n",
    "##### - There is no difference between the domestic revenue of a movie that has a runtime of 40 minutes or less and other movies in the population.\n",
    "\n",
    "### Ha:\n",
    "##### - There is a statistically significant difference between the domestic revenue of a movie that has a runtime of between 40 minutes or less minutes and other movies in the population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pulling sample based on runtime from combined data\n",
    "domgross_40_db = domgross_im_db.loc[domgross_im_db['Runtime'] <= 40]\n",
    "domgross_40_db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Unable to perform z-test for this as there are no rows in sample for this range."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 40 to 60 Minutes Testing\n",
    "\n",
    "### Z-Test\n",
    "\n",
    "### Ho:\n",
    "##### - There is no difference between the domestic revenue of a movie that has a runtime of between 40 minutes and 60 minutes and other movies in the population.\n",
    "\n",
    "### Ha:\n",
    "##### - There is a statistically significant difference between the domestic revenue of a movie that has a runtime of between 40 minutes and 60 minutes and other movies in the population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# pulling sample based on runtime from combined data\n",
    "domgross_4060_db = domgross_im_db.loc[(domgross_im_db['Runtime'] > 40) & (domgross_im_db['Runtime'] <= 60)]\n",
    "domgross_4060_db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Unable to perform z-test for this as there are no rows in sample for this range."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 60 to 90 Minutes Testing\n",
    "\n",
    "### Z-Test\n",
    "\n",
    "### Ho:\n",
    "##### - There is no difference between the domestic revenue of a movie that has a runtime of between 60 minutes and 90 minutes and other movies in the population.\n",
    "\n",
    "### Ha:\n",
    "##### - There is a statistically significant difference between the domestic revenue of a movie that has a runtime of between 60 minutes and 90 minutes and other movies in the population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pulling sample based on runtime from combined data\n",
    "domgross_6090_db = domgross_im_db.loc[(domgross_im_db['Runtime'] > 60) & (domgross_im_db['Runtime'] <= 90)]\n",
    "domgross_6090_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z-test - 60 minutes to 90 minutes domestic revenue run\n",
    "\n",
    "a = 0.025\n",
    "\n",
    "# two-tailed z-test\n",
    "x_bar = domgross_6090_db['domestic_gross'].mean()\n",
    "n = domgross_6090_db['domestic_gross'].count()\n",
    "std = domgross_im_db['domestic_gross'].std()\n",
    "mu = domgross_im_db['domestic_gross'].mean()\n",
    "\n",
    "z = (x_bar - mu)/(std/np.sqrt(n))\n",
    "p = 1 - stats.norm.cdf(np.absolute(z))\n",
    "\n",
    "# displaying results\n",
    "print(f'Sample Mean: {x_bar} | Population Mean: {mu} | Sample Size: {n}')\n",
    "print(f'p-value: {p} | z-score: {z} | Is p less than alpha? {p < a}')\n",
    "if p < a:\n",
    "    print(\"Reject the null\")\n",
    "elif p >= a:\n",
    "    print(\"Fail to reject null\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing distribution with for loop\n",
    "samp_standardized_rating = [(x-mu)/std for x in domgross_6090_db['domestic_gross']]\n",
    "z_mean = np.mean(samp_standardized_rating)\n",
    "print(f' Standardized Sample Mean: {z_mean}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizing above distribution as histogram\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "\n",
    "ax.hist(samp_standardized_rating, bins=11, density=True, color='r')\n",
    "ax.set_xlabel('Z Scores')\n",
    "ax.set_title('60 to 90 Minutes - DM Revenue')\n",
    "\n",
    "# applying normalized curve over histogram\n",
    "sns.kdeplot(samp_standardized_rating, ax=ax, color='k')\n",
    "\n",
    "# marking standardized_mean\n",
    "ax.vlines(x=z_mean, ymin=0, ymax=0.7, color='b', label='Mean: -0.2567')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting tested runtime sample against population\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "\n",
    "plt.hist(pop_standardized_rating, bins=16, density=True, color='b', alpha = 0.5)\n",
    "sns.kdeplot(pop_standardized_rating, ax=ax, color='y')\n",
    "\n",
    "plt.hist(samp_standardized_rating, bins=11, density=True, color='r', alpha = 0.5)\n",
    "sns.kdeplot(samp_standardized_rating, ax=ax, color='k')\n",
    "\n",
    "plt.vlines(x=z_mean, ymin=0, ymax=0.7, color='m', label='60 < x <= 90 Mean: -0.2567')\n",
    "plt.vlines(x=pop_z_mean, ymin=0, ymax=0.7, label='Population Mean: 0.0')\n",
    "                                              \n",
    "plt.xlabel('Z Scores')\n",
    "plt.title('60 to 90 Minutes to All Films - DM Revenue')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 90 to 120 Minutes Testing\n",
    "\n",
    "### Z-Test\n",
    "\n",
    "### Ho:\n",
    "##### - There is no difference between the domestic revenue of a movie that has a runtime of between 90 minutes and 120 minutes and other movies in the population.\n",
    "\n",
    "### Ha:\n",
    "##### - There is a statistically significant difference between the domestic revenue of a movie that has a runtime of between 90 minutes and 120 minutes and other movies in the population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pulling sample based on runtime from combined data\n",
    "domgross_90120_db = domgross_im_db.loc[(domgross_im_db['Runtime'] > 90) & (domgross_im_db['Runtime'] <= 120)]\n",
    "domgross_90120_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z-test - 90 minutes to 120 minutes domestic revenue run\n",
    "\n",
    "a = 0.025\n",
    "\n",
    "# two-tailed z-test\n",
    "x_bar = domgross_90120_db['domestic_gross'].mean()\n",
    "n = domgross_90120_db['domestic_gross'].count()\n",
    "std = domgross_im_db['domestic_gross'].std()\n",
    "mu = domgross_im_db['domestic_gross'].mean()\n",
    "\n",
    "z = (x_bar - mu)/(std/np.sqrt(n))\n",
    "p = 1 - stats.norm.cdf(np.absolute(z))\n",
    "\n",
    "# displaying results\n",
    "print(f'Sample Mean: {x_bar} | Population Mean: {mu} | Sample Size: {n}')\n",
    "print(f'p-value: {p} | z-score: {z} | Is p less than alpha? {p < a}')\n",
    "if p < a:\n",
    "    print(\"Reject the null\")\n",
    "elif p >= a:\n",
    "    print(\"Fail to reject null\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing distribution with for loop\n",
    "samp_standardized_rating = [(x-mu)/std for x in domgross_90120_db['domestic_gross']]\n",
    "z_mean = np.mean(samp_standardized_rating)\n",
    "print(f' Standardized Sample Mean: {z_mean}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizing above distribution as histogram\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "\n",
    "ax.hist(samp_standardized_rating, bins=22, density=True, color='r')\n",
    "ax.set_xlabel('Z Scores')\n",
    "ax.set_title('90 to 120 Minutes - DM Revenue')\n",
    "\n",
    "# applying normalized curve over histogram\n",
    "sns.kdeplot(samp_standardized_rating, ax=ax, color='k')\n",
    "\n",
    "# marking standardized_mean\n",
    "ax.vlines(x=z_mean, ymin=0, ymax=0.7, color='b', label='Mean: -0.04584')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting tested runtime sample against population\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "\n",
    "plt.hist(pop_standardized_rating, bins=45, density=True, color='b', alpha = 0.5)\n",
    "sns.kdeplot(pop_standardized_rating, ax=ax, color='y')\n",
    "\n",
    "plt.hist(samp_standardized_rating, bins=15, density=True, color='r', alpha = 0.5)\n",
    "sns.kdeplot(samp_standardized_rating, ax=ax, color='k')\n",
    "\n",
    "plt.vlines(x=z_mean, ymin=0, ymax=0.7, color='m', label='90 < x <= 120 Mean: -0.04584')\n",
    "plt.vlines(x=pop_z_mean, ymin=0, ymax=0.7, label='Population Mean: 0.0')\n",
    "                                              \n",
    "plt.xlabel('Z Scores')\n",
    "plt.title('90 to 120 Minutes to All Films - DM Revenue')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 120 Minutes and Up Testing\n",
    "\n",
    "### Z-Test\n",
    "\n",
    "### Ho:\n",
    "##### - There is no difference between the domestic revenue of a movie that has a runtime of 120 minutes or greater and other movies in the population.\n",
    "\n",
    "### Ha:\n",
    "##### - There is a statistically significant difference between the domestic revenue of a movie that has a runtime of 120 minutes or greater and other movies in the population at the 95% level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pulling sample based on runtime from combined data\n",
    "domgross_120up_db = domgross_im_db.loc[domgross_im_db['Runtime'] > 120]\n",
    "domgross_120up_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z-test - 120 minutes and up domestic revenue run\n",
    "\n",
    "a = 0.025\n",
    "\n",
    "# two-tailed z-test\n",
    "x_bar = domgross_120up_db['domestic_gross'].mean()\n",
    "n = domgross_120up_db['domestic_gross'].count()\n",
    "std = domgross_im_db['domestic_gross'].std()\n",
    "mu = domgross_im_db['domestic_gross'].mean()\n",
    "\n",
    "z = (x_bar - mu)/(std/np.sqrt(n))\n",
    "p = 1 - stats.norm.cdf(np.absolute(z))\n",
    "\n",
    "# displaying results\n",
    "print(f'Sample Mean: {x_bar} | Population Mean: {mu} | Sample Size: {n}')\n",
    "print(f'p-value: {p} | z-score: {z} | Is p less than alpha? {p < a}')\n",
    "if p < a:\n",
    "    print(\"Reject the null\")\n",
    "elif p >= a:\n",
    "    print(\"Fail to reject null\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing distribution with for loop\n",
    "samp_standardized_rating = [(x-mu)/std for x in domgross_120up_db['domestic_gross']]\n",
    "z_mean = np.mean(samp_standardized_rating)\n",
    "print(f' Standardized Sample Mean: {z_mean}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizing above distribution as histogram\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "\n",
    "ax.hist(samp_standardized_rating, bins=11, density=True, color='r')\n",
    "ax.set_xlabel('Z Scores')\n",
    "ax.set_title('120 Minutes and Up - DM Revenue')\n",
    "\n",
    "# applying normalized curve over histogram\n",
    "sns.kdeplot(samp_standardized_rating, ax=ax, color='k')\n",
    "\n",
    "# marking standardized_mean\n",
    "ax.vlines(x=z_mean, ymin=0, ymax=0.7, color='b', label='Mean: 0.3130')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting tested runtime sample against population\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "\n",
    "plt.hist(pop_standardized_rating, bins=45, density=True, color='b', alpha = 0.5)\n",
    "sns.kdeplot(pop_standardized_rating, ax=ax, color='y')\n",
    "\n",
    "plt.hist(samp_standardized_rating, bins=15, density=True, color='r', alpha = 0.5)\n",
    "sns.kdeplot(samp_standardized_rating, ax=ax, color='k')\n",
    "\n",
    "plt.vlines(x=z_mean, ymin=0, ymax=0.7, color='m', label='120 < x Mean: 0.3130')\n",
    "plt.vlines(x=pop_z_mean, ymin=0, ymax=0.7, label='Population Mean: 0.0')\n",
    "                                              \n",
    "plt.xlabel('Z Scores')\n",
    "plt.title('120 Minutes and Up to All Films - DM Revenue')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation\n",
    "\n",
    "### Ho:\n",
    "##### - There is no correlation between runtime and the domestic gross revenue for a given movie at the 95% level.  \n",
    "\n",
    "### Ha:\n",
    "##### - There is a statistically significant correlation between runtime and the domestic gross revenue at the 95% level for a given movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r-critical value to test if found r is statistically signifcant\n",
    "critical_r = 0.0510\n",
    "# Source: https://www.calculators.tech/t-value-calculator\n",
    "# (Unable to calculate by hand as I have been unable to find a direct formula to find this - must use either r-critical table or a r-crit calculator like the above source)\n",
    "df = domgross_im_db['Runtime'].count() - 2 # getting degrees of freedom to determine r-critical\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating correlation\n",
    "\n",
    "x = domgross_im_db['Runtime']\n",
    "y = domgross_im_db['domestic_gross']\n",
    "\n",
    "r = x.corr(y) # result is the pearson correlation coefficient\n",
    "r\n",
    "\n",
    "print(f'Pearson Correlation: {r} | r-critical: {critical_r} | Is r greater? {abs(r) >= critical_r}')\n",
    "if abs(r) >= critical_r:\n",
    "    print(\"Reject the null\")\n",
    "elif abs(r) < critical_r:\n",
    "    print(\"Fail to reject null\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x=\"Runtime\", y=\"domestic_gross\", data=domgross_im_db, line_kws={'color': 'red'}, height=8, aspect=1.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Worldwide Revenue per Rating Table \n",
    "- Merging on title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging dr_movie_db with the sql database data\n",
    "wwgross_im_db = wwr_movie_db.merge(df_allrt,how='inner',on='title')\n",
    "wwgross_im_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking for unintentionally duplicated values\n",
    "wwgross_im_db.duplicated('title').value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dropping found unintentionally duplicated values\n",
    "wwgross_im_db = wwgross_im_db.drop_duplicates(subset='title')\n",
    "wwgross_im_db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis Testing for Runtime and Worldwide Gross Revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardizing population for secondary visualizations to follow\n",
    "mu = wwgross_im_db['worldwide_gross'].mean()\n",
    "std = wwgross_im_db['worldwide_gross'].std()\n",
    "\n",
    "pop_standardized_rating = [(x-mu)/std for x in wwgross_im_db['worldwide_gross']]\n",
    "pop_z_mean = np.mean(pop_standardized_rating)\n",
    "pop_z_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Less than 40 Minutes Testing\n",
    "\n",
    "### Z-Test\n",
    "\n",
    "### Ho:\n",
    "##### - There is no difference between the worldwide revenue of a movie that has a runtime of less than 40 minutes and other movies in the population.\n",
    "\n",
    "### Ha:\n",
    "##### - There is a statistically significant difference between the worldwide revenue of a movie that has a runtime of less than 40 minutes and the population. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wwgross_40_db = wwgross_im_db.loc[wwgross_im_db['Runtime'] <= 40]\n",
    "wwgross_40_db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Unable to perform z-test for this as there are no rows in sample for this range."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 40 to 60 Minutes Testing\n",
    "\n",
    "### Z-Test\n",
    "\n",
    "### Ho:\n",
    "##### - There is no difference between the worldwide revenue of a movie that has a runtime of between 40 minutes and 60 minutes and other movies in the population.\n",
    "\n",
    "### Ha:\n",
    "##### - There is a statistically significant difference between the worldwide revenue of a movie that has a runtime of between 40 minutes and 60 minutes and other movies in the population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wwgross_4060_db = wwgross_im_db.loc[(wwgross_im_db['Runtime'] > 40) & (wwgross_im_db['Runtime'] <= 60)]\n",
    "wwgross_4060_db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Unable to perform z-test for this as there are no rows in sample for this range."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 60 to 90 Minutes Testing\n",
    "\n",
    "### Z-Test\n",
    "\n",
    "### Ho:\n",
    "##### - There is no difference between the worldwide revenue of a movie that has a runtime of between 60 minutes and 90 minutes and other movies in the population.\n",
    "\n",
    "### Ha:\n",
    "##### - There is a statistically significant difference between the worldwide revenue of a movie that has a runtime of between 60 minutes and 90 minutes and other movies in the population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wwgross_6090_db = wwgross_im_db.loc[(wwgross_im_db['Runtime'] > 60) & (wwgross_im_db['Runtime'] <= 90)]\n",
    "wwgross_6090_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z-test - 60 minutes to 90 minutes worldwide revenue run\n",
    "\n",
    "a = 0.025\n",
    "\n",
    "# two-tailed z-test\n",
    "x_bar = wwgross_6090_db['worldwide_gross'].mean()\n",
    "n = wwgross_6090_db['worldwide_gross'].count()\n",
    "std = wwgross_im_db['worldwide_gross'].std()\n",
    "mu = wwgross_im_db['worldwide_gross'].mean()\n",
    "\n",
    "z = (x_bar - mu)/(std/np.sqrt(n))\n",
    "p = 1 - stats.norm.cdf(np.absolute(z))\n",
    "\n",
    "# displaying results\n",
    "print(f'Sample Mean: {x_bar} | Population Mean: {mu} | Sample Size: {n}')\n",
    "print(f'p-value: {p} | z-score: {z} | Is p less than alpha? {p < a}')\n",
    "if p < a:\n",
    "    print(\"Reject the null\")\n",
    "elif p >= a:\n",
    "    print(\"Fail to reject null\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing distribution with for loop\n",
    "samp_standardized_rating = [(x-mu)/std for x in wwgross_6090_db['worldwide_gross']]\n",
    "z_mean = np.mean(samp_standardized_rating)\n",
    "print(f' Standardized Sample Mean: {z_mean}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizing above distribution as histogram\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "\n",
    "ax.hist(samp_standardized_rating, bins=11, density=True, color='r')\n",
    "ax.set_xlabel('Z Scores')\n",
    "ax.set_title('60 to 90 Minutes - WW Revenue')\n",
    "\n",
    "# applying normalized curve over histogram\n",
    "sns.kdeplot(samp_standardized_rating, ax=ax, color='k')\n",
    "\n",
    "# marking standardized_mean\n",
    "ax.vlines(x=z_mean, ymin=0, ymax=0.7, color='b', label='Mean: -0.3105')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting tested runtime sample against population\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "\n",
    "plt.hist(pop_standardized_rating, bins=16, density=True, color='b', alpha = 0.5)\n",
    "sns.kdeplot(pop_standardized_rating, ax=ax, color='y')\n",
    "\n",
    "plt.hist(samp_standardized_rating, bins=11, density=True, color='r', alpha = 0.5)\n",
    "sns.kdeplot(samp_standardized_rating, ax=ax, color='k')\n",
    "\n",
    "plt.vlines(x=z_mean, ymin=0, ymax=0.7, color='m', label='60 < x <= 90 Mean: -0.3105')\n",
    "plt.vlines(x=pop_z_mean, ymin=0, ymax=0.7, label='Population Mean: 0.0')\n",
    "                                              \n",
    "plt.xlabel('Z Scores')\n",
    "plt.title('60 to 90 Minutes to All Films - WW Revenue')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 90 to 120 Minutes Testing\n",
    "\n",
    "### Z-Test\n",
    "\n",
    "### Ho:\n",
    "##### - There is no difference between the worldwide revenue of a movie that has a runtime of between 90 minutes and 120 minutes and other movies in the population.\n",
    "\n",
    "### Ha:\n",
    "##### - There is a statistically significant difference between the worldwide revenue of a movie that has a runtime of between 90 minutes and 120 minutes and other movies in the population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wwgross_90120_db = wwgross_im_db.loc[(wwgross_im_db['Runtime'] > 90) & (wwgross_im_db['Runtime'] <= 120)]\n",
    "wwgross_90120_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z-test - 90 minutes to 120 minutes worldwide revenue run\n",
    "\n",
    "a = 0.025\n",
    "\n",
    "# two-tailed z-test\n",
    "x_bar = wwgross_90120_db['worldwide_gross'].mean()\n",
    "n = wwgross_90120_db['worldwide_gross'].count()\n",
    "std = wwgross_im_db['worldwide_gross'].std()\n",
    "mu = wwgross_im_db['worldwide_gross'].mean()\n",
    "\n",
    "z = (x_bar - mu)/(std/np.sqrt(n))\n",
    "p = 1 - stats.norm.cdf(np.absolute(z))\n",
    "\n",
    "# displaying results\n",
    "print(f'Sample Mean: {x_bar} | Population Mean: {mu} | Sample Size: {n}')\n",
    "print(f'p-value: {p} | z-score: {z} | Is p less than alpha? {p < a}')\n",
    "if p < a:\n",
    "    print(\"Reject the null\")\n",
    "elif p >= a:\n",
    "    print(\"Fail to reject null\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing distribution with for loop\n",
    "samp_standardized_rating = [(x-mu)/std for x in wwgross_90120_db['worldwide_gross']]\n",
    "z_mean = np.mean(samp_standardized_rating)\n",
    "print(f' Standardized Sample Mean: {z_mean}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizing above distribution as histogram\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "\n",
    "ax.hist(samp_standardized_rating, bins=15, density=True, color='r')\n",
    "ax.set_xlabel('Z Scores')\n",
    "ax.set_title('90 to 120 Minutes - WW Revenue')\n",
    "\n",
    "# applying normalized curve over histogram\n",
    "sns.kdeplot(samp_standardized_rating, ax=ax, color='k')\n",
    "\n",
    "# marking standardized_mean\n",
    "ax.vlines(x=z_mean, ymin=0, ymax=0.7, color='b', label='Mean: -0.0203')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting tested runtime sample against population\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "\n",
    "plt.hist(pop_standardized_rating, bins=45, density=True, color='b', alpha = 0.5)\n",
    "sns.kdeplot(pop_standardized_rating, ax=ax, color='y')\n",
    "\n",
    "plt.hist(samp_standardized_rating, bins=15, density=True, color='r', alpha = 0.5)\n",
    "sns.kdeplot(samp_standardized_rating, ax=ax, color='k')\n",
    "\n",
    "plt.vlines(x=z_mean, ymin=0, ymax=0.7, color='m', label='90 < x <= 120 Mean: -0.0203')\n",
    "plt.vlines(x=pop_z_mean, ymin=0, ymax=0.7, label='Population Mean: 0.0')\n",
    "                                              \n",
    "plt.xlabel('Z Scores')\n",
    "plt.title('90 to 120 Minutes to All Films - WW Revenue')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 120 and up Minutes Testing\n",
    "\n",
    "### Z-Test\n",
    "\n",
    "### Ho:\n",
    "##### - There is no difference between the worldwide revenue of a movie that has a runtime of 120 minutes or greater and other movies in the population.\n",
    "\n",
    "### Ha:\n",
    "##### - There is a statistically significant difference between the worldwide revenue of a movie that has a runtime of 120 minutes or greater and other movies in the population at the 95% level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wwgross_120up_db = wwgross_im_db.loc[wwgross_im_db['Runtime'] > 120]\n",
    "wwgross_120up_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z-test - 120 minutes and up worldwide revenue run\n",
    "\n",
    "a = 0.025\n",
    "\n",
    "# two-tailed z-test\n",
    "x_bar = wwgross_120up_db['worldwide_gross'].mean()\n",
    "n = wwgross_120up_db['worldwide_gross'].count()\n",
    "std = wwgross_im_db['worldwide_gross'].std()\n",
    "mu = wwgross_im_db['worldwide_gross'].mean()\n",
    "\n",
    "z = (x_bar - mu)/(std/np.sqrt(n))\n",
    "p = 1 - stats.norm.cdf(np.absolute(z))\n",
    "\n",
    "# displaying results\n",
    "print(f'Sample Mean: {x_bar} | Population Mean: {mu} | Sample Size: {n}')\n",
    "print(f'p-value: {p} | z-score: {z} | Is p less than alpha? {p < a}')\n",
    "if p < a:\n",
    "    print(\"Reject the null\")\n",
    "elif p >= a:\n",
    "    print(\"Fail to reject null\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing distribution with for loop\n",
    "samp_standardized_rating = [(x-mu)/std for x in wwgross_120up_db['worldwide_gross']]\n",
    "z_mean = np.mean(samp_standardized_rating)\n",
    "print(f' Standardized Sample Mean: {z_mean}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizing above distribution as histogram\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "\n",
    "ax.hist(samp_standardized_rating, bins=15, density=True, color='r')\n",
    "ax.set_xlabel('Z Scores')\n",
    "ax.set_title('120 Minutes and Up - WW Revenue')\n",
    "\n",
    "# applying normalized curve over histogram\n",
    "sns.kdeplot(samp_standardized_rating, ax=ax, color='k')\n",
    "\n",
    "# marking standardized_mean\n",
    "ax.vlines(x=z_mean, ymin=0, ymax=0.7, color='b', label='Mean: 0.2631')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting tested runtime sample against population\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "\n",
    "plt.hist(pop_standardized_rating, bins=45, density=True, color='b', alpha = 0.5)\n",
    "sns.kdeplot(pop_standardized_rating, ax=ax, color='y')\n",
    "\n",
    "plt.hist(samp_standardized_rating, bins=15, density=True, color='r', alpha = 0.5)\n",
    "sns.kdeplot(samp_standardized_rating, ax=ax, color='k')\n",
    "\n",
    "plt.vlines(x=z_mean, ymin=0, ymax=0.7, color='m', label='120 < x Mean: 0.2631')\n",
    "plt.vlines(x=pop_z_mean, ymin=0, ymax=0.7, label='Population Mean: 0.0')\n",
    "                                              \n",
    "plt.xlabel('Z Scores')\n",
    "plt.title('120 Minutes and Up to All Films - WW Revenue')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Domestic Gross Z-Tests:\n",
    "- For films that are less than 40 minute runtimes, we cannot perform a hypothesis test because our filter returns no values in this runtime range.\n",
    "    ##### - Inconclusive\n",
    "- For films that have between 40 and 60 minute runtimes, we cannot perform a hypothesis test because our filter returns no values in this runtime range.\n",
    "    ##### - Inconclusive\n",
    "- For films that have between 60 and 90 minute runtimes, we can reject the null hypothesis with a statistically significant p-value of 0.0026, meaning that in 95% of cases we can expect our revenue to be lower (due to negative z-score) if a film falls within this set of runtimes.\n",
    "    ##### - Reject the Null\n",
    "- For films that have between 90 and 120 minute runtimes, we fail to reject the null hypothesis for a p-value of 0.1094 because it is greater than our alpha 0.025.\n",
    "    ##### - Fail to reject the Null\n",
    "- For films that have either 120 minute runtimes or longer, we can reject the null hypothesis with a statistically significant p-value of 0.000004, meaning that in 95% of cases we can expect our revenue to be higher (due to positive z-score) because of the movie falling this range of runtimes.\n",
    "    ##### - Reject the Null\n",
    "    \n",
    "### Worldwide Gross Z-Tests:\n",
    "- For films that are less than 40 minute runtimes, we cannot perform a hypothesis test because our filter returns no values in this runtime range.\n",
    "    ##### - Inconclusive\n",
    "- For films that have between 40 and 60 minute runtimes, we can reject the null hypothesis with a statistically significant p-value of 0.0, meaning that in 95% of cases we can expect our average ratings to be higher because of this set of runtimes.\n",
    "    ##### - Inconclusive\n",
    "- For films that have between 60 and 90 minute runtimes, we can reject the null hypothesis with a statistically significant p-value of 0.0004, meaning that in 95% of cases we can expect our revenue to be lower (due to negative z-score) if a film falls within this set of runtimes.\n",
    "    ##### - Reject the Null\n",
    "- For films that have between 90 and 120 minute runtimes, we fail to reject the null hypothesis for a p-value of 0.2937 because it is greater than our alpha 0.025.\n",
    "    ##### - Fail to reject the Null\n",
    "- For films that have either 120 minute runtimes or longer, we can reject the null hypothesis with a statistically significant p-value of 0.0001, meaning that in 95% of cases we can expect our revenue to be higher (due to positive z-score) because of the movie falling this range of runtimes.\n",
    "    ##### - Reject the Null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation for Worldwide Gross Revenue\n",
    "\n",
    "### Ho:\n",
    "##### - There is no correlation between runtime and the worldwide gross revenue for a given movie at the 95% level.  \n",
    "\n",
    "### Ha:\n",
    "##### - There is a statistically significant correlation between runtime and the worldwide gross revenue at the 95% level for a given movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r-critical value to test if found r is statistically signifcant\n",
    "critical_r = 0.0515\n",
    "# Source: https://www.calculators.tech/t-value-calculator\n",
    "# (Unable to calculate by hand as I have been unable to find a direct formula to find this - must use either r-critical table or a r-crit calculator like the above source)\n",
    "df = wwgross_im_db['Runtime'].count() - 2 # getting degrees of freedom to determine r-critical\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating correlation\n",
    "\n",
    "x = wwgross_im_db['Runtime']\n",
    "y = wwgross_im_db['worldwide_gross']\n",
    "\n",
    "r = x.corr(y) # result is the pearson correlation coefficient\n",
    "r\n",
    "\n",
    "print(f'Pearson Correlation: {r} | r-critical: {critical_r} | Is r greater? {abs(r) >= critical_r}')\n",
    "if abs(r) >= critical_r:\n",
    "    print(\"Reject the null\")\n",
    "elif abs(r) < critical_r:\n",
    "    print(\"Fail to reject null\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x=\"Runtime\", y=\"worldwide_gross\", data=wwgross_im_db, line_kws={'color': 'red'}, height=8, aspect=1.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here - remember to use markdown cells for comments as well!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enrique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here - remember to use markdown cells for comments as well!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## John"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here - remember to use markdown cells for comments as well!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
