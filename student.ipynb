{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semester 1 Project Submission\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import needed libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import collections\n",
    "import scipy.stats as stats\n",
    "from math import sqrt\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import csv\n",
    "\n",
    "# Importing librarys for text cleaning\n",
    "import re\n",
    "import math\n",
    "import nltk \n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "#set plot space as inline for inline plots and qt for external plots\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elliot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genre_ids</th>\n",
       "      <th>id</th>\n",
       "      <th>original_language</th>\n",
       "      <th>popularity</th>\n",
       "      <th>release_date</th>\n",
       "      <th>title</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[12, 14, 10751]</td>\n",
       "      <td>12444</td>\n",
       "      <td>en</td>\n",
       "      <td>33.533</td>\n",
       "      <td>2010-11-19</td>\n",
       "      <td>Harry Potter and the Deathly Hallows: Part 1</td>\n",
       "      <td>7.7</td>\n",
       "      <td>10788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[14, 12, 16, 10751]</td>\n",
       "      <td>10191</td>\n",
       "      <td>en</td>\n",
       "      <td>28.734</td>\n",
       "      <td>2010-03-26</td>\n",
       "      <td>How to Train Your Dragon</td>\n",
       "      <td>7.7</td>\n",
       "      <td>7610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[12, 28, 878]</td>\n",
       "      <td>10138</td>\n",
       "      <td>en</td>\n",
       "      <td>28.515</td>\n",
       "      <td>2010-05-07</td>\n",
       "      <td>Iron Man 2</td>\n",
       "      <td>6.8</td>\n",
       "      <td>12368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[16, 35, 10751]</td>\n",
       "      <td>862</td>\n",
       "      <td>en</td>\n",
       "      <td>28.005</td>\n",
       "      <td>1995-11-22</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>7.9</td>\n",
       "      <td>10174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[28, 878, 12]</td>\n",
       "      <td>27205</td>\n",
       "      <td>en</td>\n",
       "      <td>27.920</td>\n",
       "      <td>2010-07-16</td>\n",
       "      <td>Inception</td>\n",
       "      <td>8.3</td>\n",
       "      <td>22186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26512</th>\n",
       "      <td>[27, 18]</td>\n",
       "      <td>488143</td>\n",
       "      <td>en</td>\n",
       "      <td>0.600</td>\n",
       "      <td>2018-10-13</td>\n",
       "      <td>Laboratory Conditions</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26513</th>\n",
       "      <td>[18, 53]</td>\n",
       "      <td>485975</td>\n",
       "      <td>en</td>\n",
       "      <td>0.600</td>\n",
       "      <td>2018-05-01</td>\n",
       "      <td>_EXHIBIT_84xxx_</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26514</th>\n",
       "      <td>[14, 28, 12]</td>\n",
       "      <td>381231</td>\n",
       "      <td>en</td>\n",
       "      <td>0.600</td>\n",
       "      <td>2018-10-01</td>\n",
       "      <td>The Last One</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26515</th>\n",
       "      <td>[10751, 12, 28]</td>\n",
       "      <td>366854</td>\n",
       "      <td>en</td>\n",
       "      <td>0.600</td>\n",
       "      <td>2018-06-22</td>\n",
       "      <td>Trailer Made</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26516</th>\n",
       "      <td>[53, 27]</td>\n",
       "      <td>309885</td>\n",
       "      <td>en</td>\n",
       "      <td>0.600</td>\n",
       "      <td>2018-10-05</td>\n",
       "      <td>The Church</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25497 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 genre_ids      id original_language  popularity release_date  \\\n",
       "0          [12, 14, 10751]   12444                en      33.533   2010-11-19   \n",
       "1      [14, 12, 16, 10751]   10191                en      28.734   2010-03-26   \n",
       "2            [12, 28, 878]   10138                en      28.515   2010-05-07   \n",
       "3          [16, 35, 10751]     862                en      28.005   1995-11-22   \n",
       "4            [28, 878, 12]   27205                en      27.920   2010-07-16   \n",
       "...                    ...     ...               ...         ...          ...   \n",
       "26512             [27, 18]  488143                en       0.600   2018-10-13   \n",
       "26513             [18, 53]  485975                en       0.600   2018-05-01   \n",
       "26514         [14, 28, 12]  381231                en       0.600   2018-10-01   \n",
       "26515      [10751, 12, 28]  366854                en       0.600   2018-06-22   \n",
       "26516             [53, 27]  309885                en       0.600   2018-10-05   \n",
       "\n",
       "                                              title  vote_average  vote_count  \n",
       "0      Harry Potter and the Deathly Hallows: Part 1           7.7       10788  \n",
       "1                          How to Train Your Dragon           7.7        7610  \n",
       "2                                        Iron Man 2           6.8       12368  \n",
       "3                                         Toy Story           7.9       10174  \n",
       "4                                         Inception           8.3       22186  \n",
       "...                                             ...           ...         ...  \n",
       "26512                         Laboratory Conditions           0.0           1  \n",
       "26513                               _EXHIBIT_84xxx_           0.0           1  \n",
       "26514                                  The Last One           0.0           1  \n",
       "26515                                  Trailer Made           0.0           1  \n",
       "26516                                    The Church           0.0           1  \n",
       "\n",
       "[25497 rows x 8 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read tmdb file, make sure values are in the same format, and drop null values\n",
    "tmdb_movie_db = pd.read_csv('databases/tmdb.movies.csv', na_filter=True, na_values='[]', encoding = 'utf-8', index_col = 0)\n",
    "tmdb_movie_db.dropna()\n",
    "#drop extra title column\n",
    "tmdb_movie_db = tmdb_movie_db.drop('original_title', axis = 1)\n",
    "#standardize release date into date format\n",
    "tmdb_movie_db['release_date'] = pd.to_datetime(tmdb_movie_db['release_date'])\n",
    "#strip whitespace from title\n",
    "tmdb_movie_db['title'] = tmdb_movie_db['title'].str.strip()\n",
    "#remove duplicates\n",
    "tmdb_movie_db = tmdb_movie_db.drop_duplicates()\n",
    "\n",
    "tmdb_movie_db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Movie Genre Key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Action: 28 Adventure: 12 Animation: 16 Comedy: 35 Crime: 80 Documentary: 99 Drama: 18 Family: 10751 Fantasy: 14 History: 36 Horror: 27 Music: 10402 Mystery: 9648 Romance: 10749 Science Fiction: 878 TV Movie: 10770 Thriller: 53 War: 10752 Western: 37"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Popularity Model is based on:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of votes for the day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of views for the day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of users who marked it as a \"favourite\" for the day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of users who added it to their \"watchlist\" for the day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Release date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of total votes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previous days score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#information regarding The Movie Database\n",
    "tmdb_movie_db.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check to see if there any null values\n",
    "tmdb_movie_db.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check to see that there are no duplicates\n",
    "tmdb_movie_db.duplicated().value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#view shape of data\n",
    "tmdb_movie_db.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Numbers Data Cleanse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read tn file, make sure values are in the same format, and drop null values\n",
    "tn_movie_db = pd.read_csv('databases/tn.movie_budgets.csv', na_filter=True, na_values='[]', encoding = 'utf-8', index_col = 0)\n",
    "tn_movie_db.dropna()\n",
    "#standardize release date into date format\n",
    "tn_movie_db['release_date'] = pd.to_datetime(tn_movie_db['release_date'])\n",
    "#strip whitespace from title\n",
    "tn_movie_db['movie'] = tn_movie_db['movie'].str.strip()\n",
    "#strip $\n",
    "tn_movie_db['production_budget'] = tn_movie_db['production_budget'].str.strip('$')\n",
    "tn_movie_db['domestic_gross'] = tn_movie_db['domestic_gross'].str.strip('$')\n",
    "tn_movie_db['worldwide_gross'] = tn_movie_db['worldwide_gross'].str.strip('$')\n",
    "#remove ,\n",
    "tn_movie_db['production_budget'] = tn_movie_db['production_budget'].replace(\",\", \"\", regex=True)\n",
    "tn_movie_db['domestic_gross'] = tn_movie_db['domestic_gross'].replace(\",\", \"\", regex=True)\n",
    "tn_movie_db['worldwide_gross'] = tn_movie_db['worldwide_gross'].replace(\",\", \"\", regex=True)\n",
    "#convert to integers\n",
    "tn_movie_db['production_budget'] = tn_movie_db['production_budget'].astype(int)\n",
    "tn_movie_db['domestic_gross'] = tn_movie_db['domestic_gross'].astype(int)\n",
    "tn_movie_db['worldwide_gross'] = tn_movie_db['worldwide_gross'].astype(float)\n",
    "#create metric ratios\n",
    "tn_movie_db['dom_gross / budget'] = tn_movie_db['domestic_gross'] / tn_movie_db['production_budget']\n",
    "tn_movie_db['ww_gross / budget'] = tn_movie_db['worldwide_gross'] / tn_movie_db['production_budget']\n",
    "tn_movie_db['dom_profit'] = tn_movie_db['domestic_gross'] - tn_movie_db['production_budget']\n",
    "tn_movie_db['profit'] = tn_movie_db['worldwide_gross'] - tn_movie_db['production_budget']\n",
    "\n",
    "tn_movie_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#information regarding The Numbers\n",
    "tn_movie_db.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check to see if there any null values\n",
    "tn_movie_db.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check to see that there are no duplicates\n",
    "tn_movie_db.duplicated().value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#view shape of data\n",
    "tn_movie_db.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge both tables to combine data to connect genres to production costs and boxoffice revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge title and movie name\n",
    "tn_movie_db = tn_movie_db.rename(columns = {\"movie\":\"title\"})\n",
    "\n",
    "#special cases where movie titles do not match\n",
    "tn_movie_db['title'].replace({'Harry Potter and the Deathly Hallows: Part I' : 'Harry Potter and the Deathly Hallows: Part 1'}, inplace=True)\n",
    "tn_movie_db['title'].replace({'Harry Potter and the Deathly Hallows: Part II' : 'Harry Potter and the Deathly Hallows: Part 2'}, inplace=True)\n",
    "tmdb_movie_db['title'].replace({'Fast & Furious 6':'Fast and Furious 6'}, inplace=True)\n",
    "tn_movie_db['title'].replace({'Star Wars: The Force Awakens' : 'Star Wars Ep. VII: The Force Awakens'}, inplace=True)\n",
    "tn_movie_db['title'].replace({'Star Wars: The Last Jedi' : 'Star Wars Ep. VIII: The Last Jedi'}, inplace=True)\n",
    "\n",
    "#merge databases\n",
    "movie_db = tmdb_movie_db.merge(tn_movie_db, how = 'left')\n",
    "\n",
    "#drop null values\n",
    "movie_db = movie_db.dropna()\n",
    "\n",
    "movie_db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check to see if worldwide_gross and domestic_gross is 0 to remove outliers\n",
    "dcount = 0\n",
    "for x in movie_db['domestic_gross']:\n",
    "    if x == 0:\n",
    "        dcount += 1\n",
    "print(dcount)\n",
    "\n",
    "wwcount = 0\n",
    "for x in movie_db['worldwide_gross']:\n",
    "    if x == 0:\n",
    "        wwcount += 1\n",
    "print(wwcount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove values that have 0 in the domestic_gross column\n",
    "new_movie_db = movie_db.drop(movie_db[movie_db['domestic_gross'] < 1].index)\n",
    "new_movie_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check to make sure that there are no values with 0\n",
    "new_movie_db.loc[movie_db['worldwide_gross'] < 1]\n",
    "sorted(new_movie_db['worldwide_gross'].value_counts().index.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#information regarding new db\n",
    "new_movie_db.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Domestic Revenue per Rating Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#determine outliers\n",
    "p25 = np.percentile(new_movie_db['domestic_gross'], 25)\n",
    "p75 = np.percentile(new_movie_db['domestic_gross'], 75)\n",
    "iqr = p75 - p25\n",
    "outlier = p75 + (1.5 * iqr)\n",
    "#create db that removes upper outliers\n",
    "dr_movie_db = new_movie_db.drop(new_movie_db[new_movie_db['domestic_gross'] > outlier].index)\n",
    "dr_movie_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#graph visual\n",
    "x = dr_movie_db['vote_average']\n",
    "\n",
    "y = dr_movie_db['domestic_gross']\n",
    "\n",
    "plt.scatter(x, y)\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Domestic Revenue')\n",
    "plt.title('Domestic Revenue per Rating')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create line of best fit\n",
    "sns.lmplot(x = 'vote_average', y = 'domestic_gross', data = dr_movie_db, height = 8, aspect = 1.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Worldwide Revenue per Rating Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#determine outliers\n",
    "p25 = np.percentile(new_movie_db['worldwide_gross'], 25)\n",
    "p75 = np.percentile(new_movie_db['worldwide_gross'], 75)\n",
    "iqr = p75 - p25\n",
    "outlier = p75 + (1.5 * iqr)\n",
    "#create db that removes upper outliers\n",
    "wwr_movie_db = new_movie_db.drop(new_movie_db[new_movie_db['worldwide_gross'] > outlier].index)\n",
    "wwr_movie_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#graph visual\n",
    "x = wwr_movie_db['vote_average']\n",
    "\n",
    "y = wwr_movie_db['worldwide_gross']\n",
    "\n",
    "plt.scatter(x, y)\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Worldwide Revenue (hundred million $)')\n",
    "plt.title('Worldwide Revenue per Rating')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create line of best fit\n",
    "sns.lmplot(x = 'vote_average', y = 'worldwide_gross', data = wwr_movie_db, height = 8, aspect = 1.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Domestic Profit per Rating Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#graph visual\n",
    "x = new_movie_db['vote_average']\n",
    "\n",
    "y = new_movie_db['dom_profit']\n",
    "\n",
    "plt.scatter(x, y)\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Domestic Profit')\n",
    "plt.title('Domestic Profit per Rating')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create line of best fit\n",
    "sns.lmplot(x = 'vote_average', y = 'dom_profit', data = new_movie_db, height = 8, aspect = 1.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Profit per Rating Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#determine outliers\n",
    "p25 = np.percentile(new_movie_db['profit'], 25)\n",
    "p75 = np.percentile(new_movie_db['profit'], 75)\n",
    "iqr = p75 - p25\n",
    "outlier = p75 + (1.5 * iqr)\n",
    "#create db that removes upper outliers\n",
    "wwp_movie_db = new_movie_db.drop(new_movie_db[new_movie_db['worldwide_gross'] > outlier].index)\n",
    "wwp_movie_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#determine outliers\n",
    "p25 = np.percentile(wwp_movie_db['vote_average'], 25)\n",
    "p75 = np.percentile(wwp_movie_db['vote_average'], 75)\n",
    "iqr = p75 - p25\n",
    "outlier = p75 + (1.5 * iqr)\n",
    "#create db that removes upper outliers\n",
    "wwp1_movie_db = wwp_movie_db.drop(wwp_movie_db[wwp_movie_db['vote_average'] > outlier].index)\n",
    "wwp1_movie_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#graph visual\n",
    "x = wwp1_movie_db['vote_average']\n",
    "\n",
    "y = wwp1_movie_db['profit']\n",
    "\n",
    "plt.scatter(x, y)\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Profit (hundred million $)')\n",
    "plt.title('Profit per Rating')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create line of best fit\n",
    "sns.lmplot(x = 'vote_average', y = 'profit', data = wwp1_movie_db, height = 8, aspect = 1.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Domestic Revenue per Budget Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#graph visual\n",
    "x = new_movie_db['production_budget']\n",
    "\n",
    "y = new_movie_db['domestic_gross']\n",
    "\n",
    "plt.scatter(x, y)\n",
    "plt.xlabel('Budget')\n",
    "plt.ylabel('Domestic Revenue')\n",
    "plt.title('Domestic Revenue per Budget')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create line of best fit\n",
    "sns.lmplot(x = 'production_budget', y = 'domestic_gross', data = new_movie_db, height = 8, aspect = 1.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Worldwide Revenue per Budget Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#graph visual\n",
    "x = new_movie_db['production_budget']\n",
    "\n",
    "y = new_movie_db['worldwide_gross']\n",
    "\n",
    "plt.scatter(x, y)\n",
    "plt.xlabel('Budget')\n",
    "plt.ylabel('Worldwide Revenue')\n",
    "plt.title('Worldwide Revenue per Budget')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create line of best fit\n",
    "sns.lmplot(x = 'production_budget', y = 'worldwide_gross', data = new_movie_db, height = 8, aspect = 1.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Domestic Revenue per Popularity Rating Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#determine outliers\n",
    "p25 = np.percentile(new_movie_db['popularity'], 25)\n",
    "p75 = np.percentile(new_movie_db['popularity'], 75)\n",
    "iqr = p75 - p25\n",
    "outlier = p75 + (1.5 * iqr)\n",
    "#create db that removes upper outliers\n",
    "popularity_movie_db = new_movie_db.drop(new_movie_db[new_movie_db['popularity'] > outlier].index)\n",
    "popularity_movie_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#determine outliers\n",
    "p25 = np.percentile(popularity_movie_db['domestic_gross'], 25)\n",
    "p75 = np.percentile(popularity_movie_db['domestic_gross'], 75)\n",
    "iqr = p75 - p25\n",
    "outlier = p75 + (1.5 * iqr)\n",
    "#create db that removes upper outliers\n",
    "popularity1_movie_db = popularity_movie_db.drop(popularity_movie_db[popularity_movie_db['domestic_gross'] > outlier].index)\n",
    "popularity1_movie_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#graph visual\n",
    "x = popularity1_movie_db['popularity']\n",
    "\n",
    "y = popularity1_movie_db['domestic_gross']\n",
    "\n",
    "plt.scatter(x, y)\n",
    "plt.xlabel('Popularity')\n",
    "plt.ylabel('Domestic Revenue')\n",
    "plt.title('Domestic Revenue per Popularity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create line of best fit\n",
    "sns.lmplot(x = 'popularity', y = 'domestic_gross', data = popularity1_movie_db, height = 8, aspect = 1.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Worldwide Revenue per Popularity Rating Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#determine outliers\n",
    "p25 = np.percentile(popularity_movie_db['worldwide_gross'], 25)\n",
    "p75 = np.percentile(popularity_movie_db['worldwide_gross'], 75)\n",
    "iqr = p75 - p25\n",
    "outlier = p75 + (1.5 * iqr)\n",
    "#create db that removes upper outliers\n",
    "popularity2_movie_db = popularity_movie_db.drop(popularity_movie_db[popularity_movie_db['worldwide_gross'] > outlier].index)\n",
    "popularity2_movie_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#graph visual\n",
    "x = popularity2_movie_db['popularity']\n",
    "\n",
    "y = popularity2_movie_db['worldwide_gross']\n",
    "\n",
    "plt.scatter(x, y)\n",
    "plt.xlabel('Popularity')\n",
    "plt.ylabel('Worldwide Revenue (hundred million $)')\n",
    "plt.title('Worldwide Revenue per Popularity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create line of best fit\n",
    "sns.lmplot(x = 'popularity', y = 'worldwide_gross', data = popularity2_movie_db, height = 8, aspect = 1.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Domestic Profit per Popularity Rating Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#determine outliers\n",
    "p25 = np.percentile(popularity_movie_db['dom_profit'], 25)\n",
    "p75 = np.percentile(popularity_movie_db['dom_profit'], 75)\n",
    "iqr = p75 - p25\n",
    "outlier = p75 + (1.5 * iqr)\n",
    "#create db that removes upper outliers\n",
    "popularity3_movie_db = popularity_movie_db.drop(popularity_movie_db[popularity_movie_db['dom_profit'] > outlier].index)\n",
    "popularity3_movie_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#determine outliers\n",
    "p25 = np.percentile(popularity3_movie_db['dom_profit'], 25)\n",
    "p75 = np.percentile(popularity3_movie_db['dom_profit'], 75)\n",
    "iqr = p75 - p25\n",
    "outlier = p25 - (1.5 * iqr)\n",
    "#create db that removes lower outliers\n",
    "popularity4_movie_db = popularity3_movie_db.drop(popularity3_movie_db[popularity3_movie_db['dom_profit'] < outlier].index)\n",
    "popularity4_movie_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#graph visual including outliers\n",
    "x = popularity4_movie_db['popularity']\n",
    "\n",
    "y = popularity4_movie_db['dom_profit']\n",
    "\n",
    "plt.scatter(x, y)\n",
    "plt.xlabel('Popularity')\n",
    "plt.ylabel('Domestic Profit')\n",
    "plt.title('Domestic Profit per Popularity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create line of best fit\n",
    "sns.lmplot(x = 'popularity', y = 'dom_profit', data = popularity4_movie_db, height = 8, aspect = 1.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Profit per Popularity Rating Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#determine outliers\n",
    "p25 = np.percentile(popularity_movie_db['profit'], 25)\n",
    "p75 = np.percentile(popularity_movie_db['profit'], 75)\n",
    "iqr = p75 - p25\n",
    "outlier = p75 + (1.5 * iqr)\n",
    "#create db that removes upper outliers\n",
    "popularity5_movie_db = popularity_movie_db.drop(popularity_movie_db[popularity_movie_db['profit'] > outlier].index)\n",
    "popularity5_movie_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#graph visual\n",
    "x = popularity5_movie_db['popularity']\n",
    "\n",
    "y = popularity5_movie_db['profit']\n",
    "\n",
    "plt.scatter(x, y,)\n",
    "plt.xlabel('Popularity')\n",
    "plt.ylabel('Profit (hundred million $)')\n",
    "plt.title('Profit per Popularity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create line of best fit\n",
    "sns.lmplot(x = 'popularity', y = 'profit', data = popularity5_movie_db, height = 8, aspect = 1.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#population must have more than 100 votes\n",
    "population_movie_db = new_movie_db.drop(new_movie_db[new_movie_db['vote_count'] < 100].index)\n",
    "population_movie_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample must have a vote average higher than 6\n",
    "sample_movie_db = new_movie_db.drop(new_movie_db[new_movie_db['vote_average'] < 6].index)\n",
    "sample_movie_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import needed libraries\n",
    "import scipy.stats as stats\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Does rating have an impact on worldwide revenue?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ho: There is no relationship between ratings and worldwide revenue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ha: There is a relationship between ratings and worldwide revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run a two tail z test using a 95% confidence level\n",
    "alpha = 0.025\n",
    "x_bar = sample_movie_db['worldwide_gross'].mean() #sample mean \n",
    "n = sample_movie_db['worldwide_gross'].count() #number of samples\n",
    "sigma = population_movie_db['worldwide_gross'].std() #std of population\n",
    "mu = population_movie_db['worldwide_gross'].mean() #population mean \n",
    "\n",
    "#calculate the z score \n",
    "z = (x_bar - mu) / (sigma / sqrt(n))\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate p-value\n",
    "pval = 1 - stats.norm.cdf(z)\n",
    "pval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#view results to identify if statistically significant\n",
    "print('p-value', pval)\n",
    "print('alpha', alpha)\n",
    "\n",
    "if pval < alpha:\n",
    "    print('Reject Null Hypothesis')\n",
    "elif pval >= alpha:\n",
    "    print('Fail to Reject Null Hypothesis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Does rating have an impact on profit?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ho: There is no relationship between ratings and profit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ha: There is a relationship between ratings and profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run a two tail z test using a 95% confidence level\n",
    "alpha = 0.025\n",
    "x_bar = sample_movie_db['profit'].mean() # sample mean \n",
    "n = sample_movie_db['profit'].count() # number\n",
    "sigma = population_movie_db['profit'].std() # std of population\n",
    "mu = population_movie_db['profit'].mean() # Population mean \n",
    "\n",
    "#calculate the z score \n",
    "z = (x_bar - mu) / (sigma / sqrt(n))\n",
    "z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate p-value\n",
    "pval = 1 - stats.norm.cdf(z)\n",
    "pval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#view results to identify if statistically significant\n",
    "print('p-value', pval)\n",
    "print('alpha', alpha)\n",
    "\n",
    "if pval < alpha:\n",
    "    print('Reject Null Hypothesis')\n",
    "elif pval >= alpha:\n",
    "    print('Fail to Reject Null Hypothesis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing distribution with for loop\n",
    "samp_standardized_rating = [(x-mu)/sigma for x in sample_movie_db['profit']]\n",
    "z_mean = np.mean(samp_standardized_rating)\n",
    "print(f' Standardized Sample Mean: {z_mean}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizing above distribution as histogram\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "\n",
    "ax.hist(samp_standardized_rating, bins=15, density=True, color='r')\n",
    "ax.set_xlabel('Z Scores')\n",
    "ax.set_title('Profit per Movie Rating')\n",
    "\n",
    "# applying normalized curve over histogram\n",
    "sns.kdeplot(samp_standardized_rating, ax=ax, color='k')\n",
    "\n",
    "# marking standardized_mean\n",
    "ax.vlines(x=z_mean, ymin=0, ymax=0.7, color='b', label='Mean: 0.2331')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardizing population for secondary visualizations to follow\n",
    "mu = population_movie_db['profit'].mean()\n",
    "std = population_movie_db['profit'].std()\n",
    "\n",
    "pop_standardized_rating = [(x-mu)/std for x in population_movie_db['profit']]\n",
    "pop_z_mean = np.mean(pop_standardized_rating)\n",
    "pop_z_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting tested runtime sample against population\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "\n",
    "plt.hist(pop_standardized_rating, bins=45, density=True, color='b', alpha = 0.5)\n",
    "sns.kdeplot(pop_standardized_rating, ax=ax, color='y')\n",
    "\n",
    "plt.hist(samp_standardized_rating, bins=15, density=True, color='r', alpha = 0.5)\n",
    "sns.kdeplot(samp_standardized_rating, ax=ax, color='k')\n",
    "\n",
    "plt.vlines(x=z_mean, ymin=0, ymax=0.7, color='m', label='Sample Mean: 0.2331')\n",
    "plt.vlines(x=pop_z_mean, ymin=0, ymax=0.7, label='Population Mean: 0.0')\n",
    "                                              \n",
    "plt.xlabel('Z Scores')\n",
    "plt.title('Profit per Movie Rating')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#graph visual\n",
    "x = sample_movie_db['vote_average']\n",
    "\n",
    "y = sample_movie_db['profit']\n",
    "\n",
    "plt.bar(x, y)\n",
    "plt.xlabel('Movie Rating')\n",
    "plt.ylabel('Profit (in hundred million $)')\n",
    "plt.title('Profit per Movie Rating')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Does popularity have an impact on worldwide revenue?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ho: There is no relationship between popularity and worldwide revenue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ha: There is a relationship between popularity and worldwide revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample must have a popularity rating higher than 10\n",
    "sample_movie_db = new_movie_db.drop(new_movie_db[new_movie_db['popularity'] < 10].index)\n",
    "sample_movie_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run a two tail z test using a 95% confidence level\n",
    "alpha = 0.025\n",
    "x_bar = sample_movie_db['worldwide_gross'].mean() #sample mean \n",
    "n = sample_movie_db['worldwide_gross'].count() #number of samples\n",
    "sigma = new_movie_db['worldwide_gross'].std() #std of population\n",
    "mu = new_movie_db['worldwide_gross'].mean() #population mean \n",
    "\n",
    "#calculate the z score \n",
    "z = (x_bar - mu) / (sigma / sqrt(n))\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate p-value\n",
    "pval = 1 - stats.norm.cdf(z)\n",
    "pval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#view results to identify if statistically significant\n",
    "print('p-value', pval)\n",
    "print('alpha', alpha)\n",
    "\n",
    "if pval < alpha:\n",
    "    print('Reject Null Hypothesis')\n",
    "elif pval >= alpha:\n",
    "    print('Fail to Reject Null Hypothesis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing distribution with for loop\n",
    "samp_standardized_rating = [(x-mu)/sigma for x in sample_movie_db['worldwide_gross']]\n",
    "z_mean = np.mean(samp_standardized_rating)\n",
    "print(f' Standardized Sample Mean: {z_mean}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizing above distribution as histogram\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "\n",
    "ax.hist(samp_standardized_rating, bins=15, density=True, color='r')\n",
    "ax.set_xlabel('Z Scores')\n",
    "ax.set_title('Worldwide Revenue per Popularity')\n",
    "\n",
    "# applying normalized curve over histogram\n",
    "sns.kdeplot(samp_standardized_rating, ax=ax, color='k')\n",
    "\n",
    "# marking standardized_mean\n",
    "ax.vlines(x=z_mean, ymin=0, ymax=0.7, color='b', label='Mean: 0.4928')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardizing population for secondary visualizations to follow\n",
    "mu = new_movie_db['worldwide_gross'].mean()\n",
    "std = new_movie_db['worldwide_gross'].std()\n",
    "\n",
    "pop_standardized_rating = [(x-mu)/std for x in new_movie_db['worldwide_gross']]\n",
    "pop_z_mean = np.mean(pop_standardized_rating)\n",
    "pop_z_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting tested runtime sample against population\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "\n",
    "plt.hist(pop_standardized_rating, bins=45, density=True, color='b', alpha = 0.5)\n",
    "sns.kdeplot(pop_standardized_rating, ax=ax, color='y')\n",
    "\n",
    "plt.hist(samp_standardized_rating, bins=15, density=True, color='r', alpha = 0.5)\n",
    "sns.kdeplot(samp_standardized_rating, ax=ax, color='k')\n",
    "\n",
    "plt.vlines(x=z_mean, ymin=0, ymax=0.7, color='m', label='Sample Mean: 0.4928')\n",
    "plt.vlines(x=pop_z_mean, ymin=0, ymax=0.7, label='Population Mean: 0.0')\n",
    "                                              \n",
    "plt.xlabel('Z Scores')\n",
    "plt.title('Worldwide Revenue per Movie Rating')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#graph visual\n",
    "x = sample_movie_db['popularity']\n",
    "\n",
    "y = sample_movie_db['worldwide_gross']\n",
    "\n",
    "plt.bar(x, y)\n",
    "plt.xlabel('Movie Popularity')\n",
    "plt.ylabel('Worldwide Revenue')\n",
    "plt.title('Worldwide Revenue per Movie Popularity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Does popularity have an impact on profit?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ho: There is no relationship between popularity and profit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ha: There is a relationship between popularity and profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05\n",
    "x_bar = sample_movie_db['profit'].mean() #sample mean \n",
    "n = sample_movie_db['profit'].count() #number of samples\n",
    "sigma = new_movie_db['profit'].std() #std of population\n",
    "mu = new_movie_db['profit'].mean() #population mean \n",
    "\n",
    "#calculate the z score \n",
    "z = (x_bar - mu) / (sigma / sqrt(n))\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate p-value\n",
    "pval = 1 - stats.norm.cdf(z)\n",
    "pval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#view results to identify if statistically significant\n",
    "print('p-value', pval)\n",
    "print('alpha', alpha)\n",
    "\n",
    "if pval < alpha:\n",
    "    print('Reject Null Hypothesis')\n",
    "elif pval >= alpha:\n",
    "    print('Fail to Reject Null Hypothesis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing distribution with for loop\n",
    "samp_standardized_rating = [(x-mu)/sigma for x in sample_movie_db['profit']]\n",
    "z_mean = np.mean(samp_standardized_rating)\n",
    "print(f' Standardized Sample Mean: {z_mean}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizing above distribution as histogram\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "\n",
    "ax.hist(samp_standardized_rating, bins=15, density=True, color='r')\n",
    "ax.set_xlabel('Z Scores')\n",
    "ax.set_title('Profit per Popularity')\n",
    "\n",
    "# applying normalized curve over histogram\n",
    "sns.kdeplot(samp_standardized_rating, ax=ax, color='k')\n",
    "\n",
    "# marking standardized_mean\n",
    "ax.vlines(x=z_mean, ymin=0, ymax=0.7, color='b', label='Mean: 0.0042')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardizing population for secondary visualizations to follow\n",
    "mu = new_movie_db['profit'].mean()\n",
    "std = new_movie_db['profit'].std()\n",
    "\n",
    "pop_standardized_rating = [(x-mu)/std for x in new_movie_db['profit']]\n",
    "pop_z_mean = np.mean(pop_standardized_rating)\n",
    "pop_z_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting tested runtime sample against population\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "\n",
    "plt.hist(pop_standardized_rating, bins=45, density=True, color='b', alpha = 0.5)\n",
    "sns.kdeplot(pop_standardized_rating, ax=ax, color='y')\n",
    "\n",
    "plt.hist(samp_standardized_rating, bins=15, density=True, color='r', alpha = 0.5)\n",
    "sns.kdeplot(samp_standardized_rating, ax=ax, color='k')\n",
    "\n",
    "plt.vlines(x=z_mean, ymin=0, ymax=0.7, color='m', label='Sample Mean: 0.0042')\n",
    "plt.vlines(x=pop_z_mean, ymin=0, ymax=0.7, label='Population Mean: 0.0')\n",
    "                                              \n",
    "plt.xlabel('Z Scores')\n",
    "plt.title('Profit per Movie Rating')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#average production budget from other released movies\n",
    "new_movie_db['production_budget'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#average domestic revenue from other released movies\n",
    "new_movie_db['domestic_gross'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#average production budget from other released movies\n",
    "new_movie_db['worldwide_gross'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#average domestic revenue multiplier based on production budget from other released movies\n",
    "new_movie_db['dom_gross / budget'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#average worldwide revenue multiplier based on production budget\n",
    "new_movie_db['ww_gross / budget'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#average domestic profits from other released movies\n",
    "new_movie_db['dom_profit'].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#average worldwide profits from other released movies\n",
    "new_movie_db['profit'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#average movie rating\n",
    "new_movie_db['vote_average'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#average movie popularity rating\n",
    "new_movie_db['popularity'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#information regarding genres\n",
    "movie_db['genre_ids'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Items to be Resolved:\n",
    "- Check for nulls in the sql database tables being used\n",
    "    - See following cell for findings.\n",
    "- Resolve found nulls \n",
    "    - Rows where null can be excluded. This is due to size and number of entries in dataset tables.\n",
    "- Experiment with joins to get tables wanted\n",
    "    - Joined movie_basics with movie_ratings. Tried further joins but they get very large, very quickly (even using inner joins).\n",
    "- Export joined tables to dataframe\n",
    "    - Complete.\n",
    "- Determine how to best use data for analysis\n",
    "    - Complete.\n",
    "    \n",
    "### Hypothesis Testing Checklist\n",
    "- Test runtime to domestic revenue and worldwide revenue - Complete.\n",
    "    - Runtime to revenue would assist with recommending best length of film to make for optimal revenue outlook\n",
    "- Break down runtime into buckets of time periods to calculate for correlation - Complete.\n",
    "    - Will isolate periods with best correlation to complement observations from runtime and revenue correlation tests.\n",
    "____________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Observations and Exploration\n",
    "\n",
    "- persons % bunch of null values in birth_year, death_year, and in primary_profession\n",
    "- writers % NONE ARE NULL\n",
    "- directors % NONE ARE NULL\n",
    "- known_for % NONE ARE NULL\n",
    "- principals % NO NULLS IN CATEGORY\n",
    "- movie_basics % missing data in genres, runtime_minutes\n",
    "- movie_ratings % NONE ARE NULL\n",
    "- movie_akas % NO TITLES ARE NULL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating connection to database\n",
    "conn = sql.connect(\"databases/im.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# movie basics query stage 1\n",
    "q = \"\"\"\n",
    "SELECT\n",
    "    *\n",
    "FROM\n",
    "    movie_basics\n",
    "/*where statement below reduces dataset from 146144 rows to 112233*/\n",
    "WHERE\n",
    "    runtime_minutes IS NOT NULL AND genres IS NOT NULL\n",
    ";\"\"\"\n",
    "pd.read_sql(q, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test to see how many values of each genre there are\n",
    "q = \"\"\"\n",
    "SELECT\n",
    "    *\n",
    "FROM\n",
    "    movie_basics\n",
    "/*where statement below reduces dataset from 146144 rows to 112233*/\n",
    "WHERE\n",
    "    runtime_minutes IS NOT NULL AND genres IS NOT NULL\n",
    ";\"\"\"\n",
    "test2_df = pd.read_sql(q, conn)\n",
    "test2_df.value_counts('genres')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# movie ratings query stage 1\n",
    "q = \"\"\"\n",
    "SELECT\n",
    "    *\n",
    "FROM\n",
    "    movie_ratings\n",
    "/*where statement below reduces dataset from 73856 rows to 73856 NO NULLS*/\n",
    "WHERE\n",
    "    averagerating IS NOT NULL AND numvotes IS NOT NULL\n",
    ";\"\"\"\n",
    "pd.read_sql(q, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# movie_akas query stage 1\n",
    "q = \"\"\"\n",
    "SELECT\n",
    "    *\n",
    "FROM\n",
    "    movie_akas\n",
    "/*where statement below reduces dataset from 331703 rows to 331703 NO NULLS*/\n",
    "WHERE\n",
    "    title IS NOT NULL\n",
    ";\"\"\"\n",
    "pd.read_sql(q, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# persons table query stage 1\n",
    "q = \"\"\"\n",
    "SELECT\n",
    "    *\n",
    "FROM\n",
    "    persons\n",
    "WHERE\n",
    "    primary_profession IS NULL\n",
    ";\"\"\"\n",
    "pd.read_sql(q, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# principals exploration query\n",
    "q = \"\"\"\n",
    "SELECT\n",
    "    *\n",
    "FROM\n",
    "    principals\n",
    ";\"\"\"\n",
    "pd.read_sql(q, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# principals category query\n",
    "q = \"\"\"\n",
    "SELECT\n",
    "    movie_id, person_id, category\n",
    "FROM\n",
    "    principals\n",
    ";\"\"\"\n",
    "test1_df = pd.read_sql(q, conn)\n",
    "test1_df.value_counts('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directors exploration query\n",
    "q = \"\"\"\n",
    "SELECT\n",
    "    *\n",
    "FROM\n",
    "    directors\n",
    ";\"\"\"\n",
    "pd.read_sql(q, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# known_for exploration query\n",
    "q = \"\"\"\n",
    "SELECT\n",
    "    *\n",
    "FROM\n",
    "    known_for\n",
    ";\"\"\"\n",
    "pd.read_sql(q, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consolidation Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining movie basics and movie ratings\n",
    "q = \"\"\"\n",
    "SELECT\n",
    "    mb.primary_title\n",
    "    ,mb.runtime_minutes\n",
    "    ,mb.genres\n",
    "    ,mr.averagerating AS AverageRating\n",
    "    ,mr.numvotes AS Num_Votes\n",
    "FROM\n",
    "    movie_basics AS mb\n",
    "    JOIN movie_ratings AS mr\n",
    "        USING(movie_id)\n",
    "WHERE\n",
    "    CAST(Num_Votes AS int) > 30\n",
    "    AND mb.runtime_minutes IS NOT NULL\n",
    "ORDER BY\n",
    "    mr.averagerating DESC\n",
    ";\"\"\"\n",
    "pd.read_sql(q, conn)\n",
    "# added in a filter that would filter out rows that have less than 30 votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining movie basics and movie ratings\n",
    "q = \"\"\"\n",
    "SELECT\n",
    "    mb.primary_title, mb.runtime_minutes, mb.genres, mr.averagerating\n",
    "FROM\n",
    "    movie_basics AS mb\n",
    "    JOIN movie_ratings AS mr\n",
    "        USING(movie_id)\n",
    "WHERE\n",
    "    CAST(averagerating AS float) == 10\n",
    "    AND runtime_minutes IS NOT NULL\n",
    "ORDER BY\n",
    "    mr.averagerating DESC\n",
    ";\"\"\"\n",
    "# checking to see titles with a rating of 10.0\n",
    "# update to above comment: restricting num_votes by 30 (like above) will\n",
    "test3_df = pd.read_sql(q, conn)\n",
    "test3_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# persons to principals to movie table NO FILTERS\n",
    "q = \"\"\"\n",
    "SELECT \n",
    "    pe.person_id\n",
    "    ,pe.primary_name\n",
    "    ,AVG(mr.averagerating) AS AverageRating\n",
    "    ,COUNT(mb.primary_title) AS Num_of_Appearances\n",
    "FROM\n",
    "    persons AS pe\n",
    "    JOIN principals AS pr\n",
    "        USING(person_id)\n",
    "    JOIN movie_basics AS mb\n",
    "        USING(movie_id)\n",
    "    JOIN movie_ratings as mr\n",
    "        USING(movie_id)\n",
    "GROUP BY\n",
    "    pe.primary_name\n",
    "ORDER BY\n",
    "    Num_of_Appearances DESC\n",
    "LIMIT 10\n",
    ";\"\"\"\n",
    "pd.read_sql(q, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding the average ratings per film and num of appearances for writers\n",
    "q = \"\"\"\n",
    "SELECT \n",
    "    pe.person_id\n",
    "    ,pr.category\n",
    "    ,pe.primary_name\n",
    "    ,AVG(mr.averagerating) AS AverageRating\n",
    "    ,COUNT(mb.primary_title) AS Num_of_Appearances\n",
    "FROM\n",
    "    persons AS pe\n",
    "    JOIN principals AS pr\n",
    "        USING(person_id)\n",
    "    JOIN movie_basics AS mb\n",
    "        USING(movie_id)\n",
    "    JOIN movie_ratings as mr\n",
    "        USING(movie_id)\n",
    "WHERE\n",
    "    pr.category = 'writer'\n",
    "    \n",
    "GROUP BY\n",
    "    pe.primary_name\n",
    "ORDER BY\n",
    "    Num_of_Appearances DESC\n",
    ";\"\"\"\n",
    "pd.read_sql(q, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding the average ratings per film and num of appearances for directors\n",
    "q = \"\"\"\n",
    "SELECT \n",
    "    pe.person_id\n",
    "    ,pr.category\n",
    "    ,pe.primary_name\n",
    "    ,AVG(mr.averagerating) AS AverageRating\n",
    "    ,COUNT(mb.primary_title) AS Num_of_Appearances\n",
    "FROM\n",
    "    persons AS pe\n",
    "    JOIN principals AS pr\n",
    "        USING(person_id)\n",
    "    JOIN movie_basics AS mb\n",
    "        USING(movie_id)\n",
    "    JOIN movie_ratings as mr\n",
    "        USING(movie_id)\n",
    "WHERE\n",
    "    pr.category = 'director'\n",
    "    \n",
    "GROUP BY\n",
    "    pe.primary_name\n",
    "HAVING\n",
    "    CAST(Num_of_Appearances AS int) > 1\n",
    "ORDER BY\n",
    "    Num_of_Appearances DESC\n",
    ";\"\"\"\n",
    "pd.read_sql(q, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding the average ratings per film and num of appearances for lead actor/actress\n",
    "# lead actor/actress is found by filtering on principals' column called ordering for the 1st actor\n",
    "q = \"\"\"\n",
    "SELECT \n",
    "    pe.person_id\n",
    "    ,pr.category\n",
    "    ,pe.primary_name\n",
    "    ,AVG(mr.averagerating) AS AverageRating\n",
    "    ,COUNT(mb.primary_title) AS Num_of_Appearances\n",
    "FROM\n",
    "    persons AS pe\n",
    "    JOIN principals AS pr\n",
    "        USING(person_id)\n",
    "    JOIN movie_basics AS mb\n",
    "        USING(movie_id)\n",
    "    JOIN movie_ratings as mr\n",
    "        USING(movie_id)\n",
    "WHERE\n",
    "    pr.category IN ('actor', 'actress')\n",
    "    AND CAST(AverageRating AS float) >= 6\n",
    "    AND CAST(pr.ordering AS int) == 1\n",
    "GROUP BY\n",
    "    pe.primary_name\n",
    "HAVING\n",
    "    CAST(Num_of_Appearances AS int) > 2\n",
    "ORDER BY\n",
    "    Num_of_Appearances DESC\n",
    ";\"\"\"\n",
    "# filtering for only actor/actresses who had an average rating of 6 or greater\n",
    "pd.read_sql(q, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding the average ratings per film and num of appearances for actor/actress\n",
    "q = \"\"\"\n",
    "SELECT \n",
    "    pe.person_id\n",
    "    ,pr.category\n",
    "    ,pe.primary_name\n",
    "    ,AVG(mr.averagerating) AS AverageRating\n",
    "    ,COUNT(mb.primary_title) AS Num_of_Appearances\n",
    "FROM\n",
    "    persons AS pe\n",
    "    JOIN principals AS pr\n",
    "        USING(person_id)\n",
    "    JOIN movie_basics AS mb\n",
    "        USING(movie_id)\n",
    "    JOIN movie_ratings as mr\n",
    "        USING(movie_id)\n",
    "WHERE\n",
    "    pr.category IN ('actor', 'actress')\n",
    "    AND CAST(AverageRating AS float) >= 6\n",
    "GROUP BY\n",
    "    pe.primary_name\n",
    "HAVING\n",
    "    CAST(Num_of_Appearances AS int) > 2\n",
    "ORDER BY\n",
    "    Num_of_Appearances DESC\n",
    ";\"\"\"\n",
    "# filtering for only actor/actresses who had an average rating of 6 or greater\n",
    "pd.read_sql(q, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# finding the average ratings per film and num of appearances for producer\n",
    "# hard to quantify where to limit here regarding appearances -- producers often only produce once, apparently\n",
    "q = \"\"\"\n",
    "SELECT \n",
    "    pe.person_id\n",
    "    ,pr.category\n",
    "    ,pe.primary_name\n",
    "    ,AVG(mr.averagerating) AS AverageRating\n",
    "    ,COUNT(mb.primary_title) AS Num_of_Appearances\n",
    "FROM\n",
    "    persons AS pe\n",
    "    JOIN principals AS pr\n",
    "        USING(person_id)\n",
    "    JOIN movie_basics AS mb\n",
    "        USING(movie_id)\n",
    "    JOIN movie_ratings as mr\n",
    "        USING(movie_id)\n",
    "WHERE\n",
    "    pr.category = 'producer'\n",
    "    AND CAST(AverageRating AS float) >= 6\n",
    "GROUP BY\n",
    "    pe.primary_name\n",
    "HAVING\n",
    "    CAST(Num_of_Appearances AS int) > 1\n",
    "ORDER BY\n",
    "    AverageRating DESC\n",
    ";\"\"\"\n",
    "pd.read_sql(q, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to Check for Statistically Significant Correlation\n",
    "\n",
    "1. State your null and alternative hypotheses, along with your alpha.\n",
    "2. Retrieve the sample being tested\n",
    "3. Calculate the test statistic, r\n",
    "4. Calculate degrees of freedom and find r-critical using table or calculator (source I used since we have large datasets with degrees of freedom that are hard to find on a table and I could not locate a stastical package to calculate the r-critical in-notebook): https://www.calculators.tech/t-value-calculator)\n",
    "5. If the absolute value of r is greater than r-critical, the correlation is statistically significant and we reject the null hypothesis. If the absolute value of r is less than r-critical, the correlation is not statistically signifcant and we fail to reject the null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Runtime and Average Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# added WHERE clause to remove movies from dataframe if longer than 3.5 hours - took away 65 values from dataset\n",
    "# and reduced runtime mean, std dev.!\n",
    "q = \"\"\"\n",
    "SELECT\n",
    "    mb.movie_id\n",
    "    ,mb.primary_title AS title\n",
    "    ,mb.runtime_minutes AS Runtime\n",
    "    ,mb.genres\n",
    "    ,mr.averagerating AS AverageRating\n",
    "    ,mr.numvotes AS Num_Votes\n",
    "FROM\n",
    "    movie_basics AS mb\n",
    "    JOIN movie_ratings AS mr\n",
    "        USING(movie_id)\n",
    "WHERE\n",
    "    CAST(Num_Votes AS int) > 30\n",
    "    AND CAST(mb.runtime_minutes as float) <= 210\n",
    "    AND mb.runtime_minutes IS NOT NULL\n",
    "    AND mb.genres IS NOT NULL\n",
    "ORDER BY\n",
    "    mb.runtime_minutes DESC\n",
    ";\"\"\"\n",
    "df_allrt = pd.read_sql(q, conn)\n",
    "df_allrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_allrt.duplicated().value_counts() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ho:\n",
    "##### - There is no correlation between runtime and average rating. \n",
    "\n",
    "### Ha:\n",
    "##### - There is a statistically significant correlation between runtime and average rating at the 95% level. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_allrt['Runtime'].count() - 2 # getting degrees of freedom to determine r-critical\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r-critical value to test if found r is statistically signifcant\n",
    "critical_r = 0.0081\n",
    "# Source: https://www.calculators.tech/t-value-calculator\n",
    "# (Unable to calculate by hand as I have been unable to find a direct formula to find this - must use either r-critical table or a r-crit calculator like the above source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# calculating correlation\n",
    "\n",
    "x = df_allrt['Runtime']\n",
    "y = df_allrt['AverageRating']\n",
    "\n",
    "r = x.corr(y) # result is the pearson correlation coefficient -- seems we do have a positive correlation!\n",
    "r\n",
    "\n",
    "print(f'Pearson Correlation: {r} | r-critical: {critical_r} | Is r greater? {abs(r) >= critical_r}')\n",
    "if abs(r) >= critical_r:\n",
    "    print(\"Reject the null\")\n",
    "elif abs(r) < critical_r:\n",
    "    print(\"Fail to reject null\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"talk\")\n",
    "sns.lmplot(x=\"Runtime\", y=\"AverageRating\", data=df_allrt, line_kws={'color': 'red'}, height=8, aspect=1.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion:\n",
    "- For 95% of cases, there is a weak positive correlation of 0.1014 between runtime and rating.\n",
    "- Now, we will drill in further to observe individual groupings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operating Notion with Runtime Samples:\n",
    "- \"The Academy of Motion Picture Arts and Sciences defines a feature as a film that runs for more than 40 minutes (with short films being 40 or fewer minutes). Still, the Screen Actors Guild asserts that a feature's running time is 60 minutes, so there's not exactly a widespread agreement.\"\n",
    "\n",
    "Source: https://www.arcstudiopro.com/blog/what-is-a-feature-film#:~:text=The%20Academy%20of%20Motion%20Picture,not%20exactly%20a%20widespread%20agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardizing population for secondary visualizations to follow\n",
    "mu = df_allrt['AverageRating'].mean()\n",
    "std = df_allrt['AverageRating'].std()\n",
    "\n",
    "pop_standardized_rating = [(x-mu)/std for x in df_allrt['AverageRating']]\n",
    "pop_z_mean = np.mean(pop_standardized_rating)\n",
    "pop_z_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Less than 40 Minutes Testing\n",
    "\n",
    "### Z-Test\n",
    "\n",
    "### Ho:\n",
    "##### - There is no difference between the average rating of a movie that has a runtime of less than 40 minutes and other movies in the population.\n",
    "\n",
    "### Ha:\n",
    "##### - There is a statistically significant difference between the average rating of a movie that has a runtime of less than 40 minutes and the population. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# runtime sample 1 - short films (between 0 and 40 minutes)\n",
    "q = \"\"\"\n",
    "SELECT\n",
    "    mb.movie_id\n",
    "    ,mb.primary_title AS title\n",
    "    ,mb.runtime_minutes AS Runtime\n",
    "    ,mb.genres\n",
    "    ,mr.averagerating AS AverageRating\n",
    "    ,mr.numvotes AS Num_Votes\n",
    "FROM\n",
    "    movie_basics AS mb\n",
    "    JOIN movie_ratings AS mr\n",
    "        USING(movie_id)\n",
    "WHERE\n",
    "    CAST(Num_Votes AS int) > 30\n",
    "    AND CAST(mb.runtime_minutes as float) <= 40\n",
    "    AND mb.runtime_minutes IS NOT NULL\n",
    "    AND mb.genres IS NOT NULL\n",
    "    AND mb.primary_title != 'The Death of a Security Guard'\n",
    "ORDER BY\n",
    "    mb.runtime_minutes DESC\n",
    ";\"\"\"\n",
    "df_up40 = pd.read_sql(q, conn)\n",
    "df_up40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z-test - less than 40 minutes ratings run\n",
    "\n",
    "# two-tailed z-test\n",
    "\n",
    "a = 0.025\n",
    "\n",
    "x_bar = df_up40['AverageRating'].mean()\n",
    "n = df_up40['AverageRating'].count()\n",
    "std = df_allrt['AverageRating'].std()\n",
    "mu = df_allrt['AverageRating'].mean()\n",
    "\n",
    "z = (x_bar - mu)/(std/np.sqrt(n))\n",
    "p = 1 - stats.norm.cdf(np.absolute(z))\n",
    "\n",
    "# displaying results\n",
    "print(f'Sample Mean: {x_bar} | Population Mean: {mu} | Sample Size: {n}')\n",
    "print(f'p-value: {p} | z-score: {z} | Is p less than alpha? {p < a}')\n",
    "if p < a:\n",
    "    print(\"Reject the null\")\n",
    "elif p >= a:\n",
    "    print(\"Fail to reject null\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing distribution with for loop\n",
    "samp_standardized_rating = [(x-mu)/std for x in df_up40['AverageRating']]\n",
    "z_mean = np.mean(samp_standardized_rating)\n",
    "print(f' Standardized Sample Mean: {z_mean}')\n",
    "\n",
    "# visualizing above distribution as histogram\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "\n",
    "ax.hist(samp_standardized_rating, bins=11, density=True, color='r', alpha=0.9)\n",
    "ax.set_xlabel('Z Scores')\n",
    "ax.set_title('Less than 40 Minutes - Ratings')\n",
    "\n",
    "# applying normalized curve over histogram\n",
    "sns.kdeplot(samp_standardized_rating, ax=ax, color='k')\n",
    "\n",
    "# marking standardized_mean\n",
    "ax.vlines(x=z_mean, ymin=0, ymax=0.7, color='b', label='Mean: 0.7702')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting tested runtime sample against population\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "\n",
    "plt.hist(pop_standardized_rating, bins=45, density=True, color='b', alpha = 0.5)\n",
    "sns.kdeplot(pop_standardized_rating, ax=ax, color='y')\n",
    "\n",
    "plt.hist(samp_standardized_rating, bins=11, density=True, color='r', alpha = 0.5)\n",
    "sns.kdeplot(samp_standardized_rating, ax=ax, color='k')\n",
    "\n",
    "plt.vlines(x=z_mean, ymin=0, ymax=0.7, color='m', label='x<=40 Mean: 0.7702')\n",
    "plt.vlines(x=pop_z_mean, ymin=0, ymax=0.7, label='Population Mean: 0.0')\n",
    "                                              \n",
    "plt.xlabel('Z Scores')\n",
    "plt.title('Less than 40 Minutes to All Films - Ratings')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation\n",
    "\n",
    "### Ho:\n",
    "##### - There is no correlation between runtime and average rating for movies that are less than 40 minutes. \n",
    "\n",
    "### Ha:\n",
    "##### - There is a statistically significant correlation between runtime and average rating at the 95% level for movies that are less than 40 minutes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r-critical value to test if found r is statistically signifcant\n",
    "critical_r = 0.2510\n",
    "# Source: https://www.calculators.tech/t-value-calculator\n",
    "# (Unable to calculate by hand as I have been unable to find a direct formula to find this - must use either r-critical table or a r-crit calculator like the above source)\n",
    "df = df_up40['Runtime'].count() - 2 # getting degrees of freedom to determine r-critical\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating correlation\n",
    "\n",
    "x = df_up40['Runtime']\n",
    "y = df_up40['AverageRating']\n",
    "\n",
    "r = x.corr(y) # result is the pearson correlation coefficient\n",
    "r\n",
    "\n",
    "print(f'Pearson Correlation: {r} | r-critical: {critical_r} | Is r greater? {abs(r) >= critical_r}')\n",
    "if abs(r) >= critical_r:\n",
    "    print(\"Reject the null\")\n",
    "elif abs(r) < critical_r:\n",
    "    print(\"Fail to reject null\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x=\"Runtime\", y=\"AverageRating\", data=df_up40, line_kws={'color': 'red'}, height=8, aspect=1.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 40 to 60 Minutes Testing\n",
    "\n",
    "### Z-Test\n",
    "\n",
    "### Ho:\n",
    "##### - There is no difference between the average rating of a movie that has a runtime of between 40 minutes and 60 minutes and other movies in the population.\n",
    "\n",
    "### Ha:\n",
    "##### - There is a statistically significant difference between the average rating of a movie that has a runtime of between 40 minutes and 60 minutes and other movies in the population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# runtime sample 2 - long-form short films (40.0001 minutes to 60 minutes)\n",
    "q = \"\"\"\n",
    "SELECT\n",
    "    mb.movie_id\n",
    "    ,mb.primary_title AS title\n",
    "    ,mb.runtime_minutes AS Runtime\n",
    "    ,mb.genres\n",
    "    ,mr.averagerating AS AverageRating\n",
    "    ,mr.numvotes AS Num_Votes\n",
    "FROM\n",
    "    movie_basics AS mb\n",
    "    JOIN movie_ratings AS mr\n",
    "        USING(movie_id)\n",
    "WHERE\n",
    "    CAST(Num_Votes AS int) > 30\n",
    "    AND CAST(mb.runtime_minutes as float) BETWEEN 40.0001 AND 60\n",
    "    AND mb.runtime_minutes IS NOT NULL\n",
    "    AND mb.genres IS NOT NULL\n",
    "ORDER BY\n",
    "    mb.runtime_minutes DESC\n",
    ";\"\"\"\n",
    "df_4060 = pd.read_sql(q, conn)\n",
    "df_4060"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# z-test - 40 to 60 minutes ratings run\n",
    "\n",
    "a = 0.025\n",
    "\n",
    "# two-tailed z-test\n",
    "\n",
    "x_bar = df_4060['AverageRating'].mean()\n",
    "n = df_4060['AverageRating'].count()\n",
    "std = df_allrt['AverageRating'].std()\n",
    "mu = df_allrt['AverageRating'].mean()\n",
    "\n",
    "z = (x_bar - mu)/(std/np.sqrt(n))\n",
    "p = 1 - stats.norm.cdf(np.absolute(z))\n",
    "\n",
    "# displaying results\n",
    "print(f'Sample Mean: {x_bar} | Population Mean: {mu} | Sample Size: {n}')\n",
    "print(f'p-value: {p} | z-score: {z} | Is p less than alpha? {p < a}')\n",
    "if p < a:\n",
    "    print(\"Reject the null\")\n",
    "elif p >= a:\n",
    "    print(\"Fail to reject null\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing distribution with for loop\n",
    "samp_standardized_rating = [(x-mu)/std for x in df_4060['AverageRating']]\n",
    "z_mean = np.mean(samp_standardized_rating)\n",
    "print(f' Standardized Sample Mean: {z_mean}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizing above distribution as histogram\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "\n",
    "ax.hist(samp_standardized_rating, bins=15, density=True, color='r')\n",
    "ax.set_xlabel('Z Scores')\n",
    "ax.set_title('40 to 60 Minutes - Ratings')\n",
    "\n",
    "# applying normalized curve over histogram\n",
    "sns.kdeplot(samp_standardized_rating, ax=ax, color='k')\n",
    "\n",
    "# marking standardized_mean\n",
    "ax.vlines(x=z_mean, ymin=0, ymax=0.7, color='b', label='Mean: 0.6132')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting tested runtime sample against population\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "\n",
    "plt.hist(pop_standardized_rating, bins=45, density=True, color='b', alpha = 0.5)\n",
    "sns.kdeplot(pop_standardized_rating, ax=ax, color='y')\n",
    "\n",
    "plt.hist(samp_standardized_rating, bins=15, density=True, color='r', alpha = 0.5)\n",
    "sns.kdeplot(samp_standardized_rating, ax=ax, color='k')\n",
    "\n",
    "plt.vlines(x=z_mean, ymin=0, ymax=0.7, color='m', label='40 < x <= 60 Mean: 0.6132')\n",
    "plt.vlines(x=pop_z_mean, ymin=0, ymax=0.7, label='Population Mean: 0.0')\n",
    "                                              \n",
    "plt.xlabel('Z Scores')\n",
    "plt.title('40 to 60 Minutes to All Films - Ratings')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation\n",
    "\n",
    "### Ho:\n",
    "##### - There is no correlation between runtime and average rating for movies that are between 40 and 60 minutes. \n",
    "\n",
    "### Ha:\n",
    "##### - There is a statistically significant correlation between runtime and average rating at the 95% level for movies that are between 40 and 60 minutes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r-critical value to test if found r is statistically signifcant\n",
    "critical_r = 0.0529\n",
    "# Source: https://www.calculators.tech/t-value-calculator\n",
    "# (Unable to calculate by hand as I have been unable to find a direct formula to find this - must use either r-critical table or a r-crit calculator like the above source)\n",
    "df = df_4060['Runtime'].count() - 2 # getting degrees of freedom to determine r-critical\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# calculating correlation\n",
    "\n",
    "x = df_4060['Runtime']\n",
    "y = df_4060['AverageRating']\n",
    "\n",
    "r = x.corr(y) # result is the pearson correlation coefficient\n",
    "r\n",
    "\n",
    "print(f'Pearson Correlation: {r} | r-critical: {critical_r} | Is r greater? {abs(r) >= critical_r}')\n",
    "if abs(r) >= critical_r:\n",
    "    print(\"Reject the null\")\n",
    "elif abs(r) < critical_r:\n",
    "    print(\"Fail to reject null\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.lmplot(x=\"Runtime\", y=\"AverageRating\", data=df_4060, line_kws={'color': 'red'}, height=8, aspect=1.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 60 to 90 Minutes Testing\n",
    "\n",
    "### Z-Test\n",
    "\n",
    "### Ho:\n",
    "##### - There is no difference between the average rating of a movie that has a runtime of between 60 minutes and 90 minutes and other movies in the population.\n",
    "\n",
    "### Ha:\n",
    "##### - There is a statistically significant difference between the average rating of a movie that has a runtime of between 60 minutes and 90 minutes and other movies in the population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# runtime sample 3 - short-mid length films (60.0001 minutes to 90 minutes)\n",
    "q = \"\"\"\n",
    "SELECT\n",
    "    mb.movie_id\n",
    "    ,mb.primary_title AS title\n",
    "    ,mb.runtime_minutes AS Runtime\n",
    "    ,mb.genres\n",
    "    ,mr.averagerating AS AverageRating\n",
    "    ,mr.numvotes AS Num_Votes\n",
    "FROM\n",
    "    movie_basics AS mb\n",
    "    JOIN movie_ratings AS mr\n",
    "        USING(movie_id)\n",
    "WHERE\n",
    "    CAST(Num_Votes AS int) > 30\n",
    "    AND CAST(mb.runtime_minutes as float) BETWEEN 60.0001 AND 90\n",
    "    AND mb.runtime_minutes IS NOT NULL\n",
    "    AND mb.genres IS NOT NULL\n",
    "ORDER BY\n",
    "    mb.runtime_minutes DESC\n",
    ";\"\"\"\n",
    "df_6090 = pd.read_sql(q, conn)\n",
    "df_6090"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# z-test - 60 to 90 minutes ratings run\n",
    "\n",
    "a = 0.025\n",
    "\n",
    "# two-tailed z-test\n",
    "\n",
    "x_bar = df_6090['AverageRating'].mean()\n",
    "n = df_6090['AverageRating'].count()\n",
    "std = df_allrt['AverageRating'].std()\n",
    "mu = df_allrt['AverageRating'].mean()\n",
    "\n",
    "z = (x_bar - mu)/(std/np.sqrt(n))\n",
    "p = 1 - stats.norm.cdf(np.absolute(z))\n",
    "\n",
    "# displaying results\n",
    "print(f'Sample Mean: {x_bar} | Population Mean: {mu} | Sample Size: {n}')\n",
    "print(f'p-value: {p} | z-score: {z} | Is p less than alpha? {p < a}')\n",
    "if p < a:\n",
    "    print(\"Reject the null\")\n",
    "elif p >= a:\n",
    "    print(\"Fail to reject null\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing distribution with for loop\n",
    "samp_standardized_rating = [(x-mu)/std for x in df_6090['AverageRating']]\n",
    "z_mean = np.mean(samp_standardized_rating)\n",
    "print(f' Standardized Sample Mean: {z_mean}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizing above distribution as histogram\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "\n",
    "ax.hist(samp_standardized_rating, bins=22, density=True, color='r')\n",
    "ax.set_xlabel('Z Scores')\n",
    "ax.set_title('60 to 90 Minutes - Ratings')\n",
    "\n",
    "# applying normalized curve over histogram\n",
    "sns.kdeplot(samp_standardized_rating, ax=ax, color='k')\n",
    "\n",
    "# marking standardized_mean\n",
    "ax.vlines(x=z_mean, ymin=0, ymax=0.7, color='b', label='Mean: -0.1648')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting tested runtime sample against population\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "\n",
    "plt.hist(pop_standardized_rating, bins=45, density=True, color='b', alpha = 0.5)\n",
    "sns.kdeplot(pop_standardized_rating, ax=ax, color='y')\n",
    "\n",
    "plt.hist(samp_standardized_rating, bins=22, density=True, color='r', alpha = 0.5)\n",
    "sns.kdeplot(samp_standardized_rating, ax=ax, color='k')\n",
    "\n",
    "plt.vlines(x=z_mean, ymin=0, ymax=0.7, color='m', label='60 < x <= 90 Mean: -0.1648')\n",
    "plt.vlines(x=pop_z_mean, ymin=0, ymax=0.7, label='Population Mean: 0.0')\n",
    "                                              \n",
    "plt.xlabel('Z Scores')\n",
    "plt.title('60 to 90 Minutes to All Films - Ratings')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation\n",
    "\n",
    "### Ho:\n",
    "##### - There is no correlation between runtime and average rating for movies that are between 60 and 90 minutes. \n",
    "\n",
    "### Ha:\n",
    "##### - There is a statistically significant correlation between runtime and average rating at the 95% level for movies that are between 60 and 90 minutes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r-critical value to test if found r is statistically signifcant\n",
    "critical_r = 0.0132\n",
    "# Source: https://www.calculators.tech/t-value-calculator\n",
    "# (Unable to calculate by hand as I have been unable to find a direct formula to find this - must use either r-critical table or a r-crit calculator like the above source)\n",
    "df = df_6090['Runtime'].count() - 2 # getting degrees of freedom to determine r-critical\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating correlation\n",
    "\n",
    "x = df_6090['Runtime']\n",
    "y = df_6090['AverageRating']\n",
    "\n",
    "r = x.corr(y) # result is the pearson correlation coefficient\n",
    "r\n",
    "\n",
    "print(f'Pearson Correlation: {r} | r-critical: {critical_r} | Is r greater? {abs(r) >= critical_r}')\n",
    "if abs(r) >= critical_r:\n",
    "    print(\"Reject the null\")\n",
    "elif abs(r) < critical_r:\n",
    "    print(\"Fail to reject null\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x=\"Runtime\", y=\"AverageRating\", data=df_6090, line_kws={'color': 'red'}, height=8, aspect=1.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 90 to 120 Minutes Testing\n",
    "\n",
    "### Z-Test\n",
    "\n",
    "### Ho\n",
    "##### - There is no difference between the average rating of a movie that has a runtime of between 90 minutes and 120 minutes and other movies in the population.\n",
    "\n",
    "### Ha:\n",
    "##### - There is a statistically significant difference between the average rating of a movie that has a runtime of between 90 minutes and 120 minutes and other movies in the population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# runtime sample 4 - relative average length films (90.0001 minutes to 120 minutes)\n",
    "q = \"\"\"\n",
    "SELECT\n",
    "    mb.movie_id\n",
    "    ,mb.primary_title AS title\n",
    "    ,mb.runtime_minutes AS Runtime\n",
    "    ,mb.genres\n",
    "    ,mr.averagerating AS AverageRating\n",
    "    ,mr.numvotes AS Num_Votes\n",
    "FROM\n",
    "    movie_basics AS mb\n",
    "    JOIN movie_ratings AS mr\n",
    "        USING(movie_id)\n",
    "WHERE\n",
    "    CAST(Num_Votes AS int) > 30\n",
    "    AND CAST(mb.runtime_minutes as float) BETWEEN 90.0001 AND 120\n",
    "    AND mb.runtime_minutes IS NOT NULL\n",
    "    AND mb.genres IS NOT NULL\n",
    "ORDER BY\n",
    "    mb.runtime_minutes DESC\n",
    ";\"\"\"\n",
    "df_90120 = pd.read_sql(q, conn)\n",
    "df_90120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z-test - 90 to 120 minutes ratings run\n",
    "\n",
    "a = 0.025\n",
    "\n",
    "# two-tailed z-test\n",
    "\n",
    "x_bar = df_90120['AverageRating'].mean()\n",
    "n = df_90120['AverageRating'].count()\n",
    "std = df_allrt['AverageRating'].std()\n",
    "mu = df_allrt['AverageRating'].mean()\n",
    "\n",
    "z = (x_bar - mu)/(std/np.sqrt(n))\n",
    "p = 1 - stats.norm.cdf(np.absolute(z))\n",
    "\n",
    "# displaying results\n",
    "print(f'Sample Mean: {x_bar} | Population Mean: {mu} | Sample Size: {n}')\n",
    "print(f'p-value: {p} | z-score: {z} | Is p less than alpha? {p < a}')\n",
    "if p < a:\n",
    "    print(\"Reject the null\")\n",
    "elif p >= a:\n",
    "    print(\"Fail to reject null\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing distribution with for loop\n",
    "samp_standardized_rating = [(x-mu)/std for x in df_90120['AverageRating']]\n",
    "z_mean = np.mean(samp_standardized_rating)\n",
    "print(f' Standardized Sample Mean: {z_mean}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizing above distribution as histogram\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "\n",
    "ax.hist(samp_standardized_rating, bins=24, density=True, color='r')\n",
    "ax.set_xlabel('Z Scores')\n",
    "ax.set_title('90 to 120 minutes - Ratings')\n",
    "\n",
    "# applying normalized curve over histogram\n",
    "sns.kdeplot(samp_standardized_rating, ax=ax, color='k')\n",
    "\n",
    "# marking standardized_mean\n",
    "ax.vlines(x=z_mean, ymin=0, ymax=0.7, color='b', label='Mean: 0.0270')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting tested runtime sample against population\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "\n",
    "plt.hist(pop_standardized_rating, bins=45, density=True, color='b', alpha = 0.5)\n",
    "sns.kdeplot(pop_standardized_rating, ax=ax, color='y')\n",
    "\n",
    "plt.hist(samp_standardized_rating, bins=24, density=True, color='r', alpha = 0.5)\n",
    "sns.kdeplot(samp_standardized_rating, ax=ax, color='k')\n",
    "\n",
    "plt.vlines(x=z_mean, ymin=0, ymax=0.7, color='m', label='90 < x <= 120 Mean: 0.0270')\n",
    "plt.vlines(x=pop_z_mean, ymin=0, ymax=0.7, label='Population Mean: 0.0')\n",
    "                                              \n",
    "plt.xlabel('Z Scores')\n",
    "plt.title('90 to 120 minutes to All Films - Ratings')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation\n",
    "\n",
    "### Ho:\n",
    "##### - There is no correlation between runtime and average rating for movies that are between 90 and 120 minutes. \n",
    "\n",
    "### Ha:\n",
    "##### - There is a statistically significant correlation between runtime and average rating at the 95% level for movies that are between 90 and 120 minutes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r-critical value to test if found r is statistically signifcant\n",
    "critical_r = 0.0118\n",
    "# Source: https://www.calculators.tech/t-value-calculator\n",
    "# (Unable to calculate by hand as I have been unable to find a direct formula to find this - must use either r-critical table or a r-crit calculator like the above source)\n",
    "df = df_90120['Runtime'].count() - 2 # getting degrees of freedom to determine r-critical\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating correlation\n",
    "\n",
    "x = df_90120['Runtime']\n",
    "y = df_90120['AverageRating']\n",
    "\n",
    "r = x.corr(y) # result is the pearson correlation coefficient\n",
    "r\n",
    "\n",
    "print(f'Pearson Correlation: {r} | r-critical: {critical_r} | Is r greater? {abs(r) >= critical_r}')\n",
    "if abs(r) >= critical_r:\n",
    "    print(\"Reject the null\")\n",
    "elif abs(r) < critical_r:\n",
    "    print(\"Fail to reject null\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x=\"Runtime\", y=\"AverageRating\", data=df_90120, line_kws={'color': 'red'}, height=8, aspect=1.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 120 Minutes and Up Testing\n",
    "\n",
    "### Z-Test\n",
    "\n",
    "### Ho\n",
    "##### - There is no difference between the average rating of a movie that has a runtime of 120 minutes or greater and other movies in the population.\n",
    "\n",
    "### Ha:\n",
    "##### - There is a statistically significant difference between the average rating of a movie that has a runtime of 120 minutes or greater and other movies in the population at the 95% level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# runtime sample 5 - long length films (120.0001 minutes and up films)\n",
    "q = \"\"\"\n",
    "SELECT\n",
    "    mb.movie_id\n",
    "    ,mb.primary_title AS title\n",
    "    ,mb.runtime_minutes AS Runtime\n",
    "    ,mb.genres\n",
    "    ,mr.averagerating AS AverageRating\n",
    "    ,mr.numvotes AS Num_Votes\n",
    "FROM\n",
    "    movie_basics AS mb\n",
    "    JOIN movie_ratings AS mr\n",
    "        USING(movie_id)\n",
    "WHERE\n",
    "    CAST(Num_Votes AS int) > 30\n",
    "    AND CAST(mb.runtime_minutes as float) BETWEEN 120.0001 AND 210\n",
    "    AND mb.runtime_minutes IS NOT NULL\n",
    "    AND mb.genres IS NOT NULL\n",
    "ORDER BY\n",
    "    mb.runtime_minutes DESC\n",
    ";\"\"\"\n",
    "df_120up = pd.read_sql(q, conn)\n",
    "df_120up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z-test - 120 minutes and up ratings run\n",
    "\n",
    "a = 0.025\n",
    "\n",
    "# two-tailed z-test\n",
    "\n",
    "x_bar = df_120up['AverageRating'].mean()\n",
    "n = df_120up['AverageRating'].count()\n",
    "std = df_allrt['AverageRating'].std()\n",
    "mu = df_allrt['AverageRating'].mean()\n",
    "\n",
    "z = (x_bar - mu)/(std/np.sqrt(n))\n",
    "p = 1 - stats.norm.cdf(np.absolute(z))\n",
    "\n",
    "# displaying results\n",
    "print(f'Sample Mean: {x_bar} | Population Mean: {mu} | Sample Size: {n}')\n",
    "print(f'p-value: {p} | z-score: {z} | Is p less than alpha? {p < a}')\n",
    "if p < a:\n",
    "    print(\"Reject the null\")\n",
    "elif p >= a:\n",
    "    print(\"Fail to reject null\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing distribution with for loop\n",
    "samp_standardized_rating = [(x-mu)/std for x in df_120up['AverageRating']]\n",
    "z_mean = np.mean(samp_standardized_rating)\n",
    "print(f' Standardized Sample Mean: {z_mean}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizing above distribution as histogram\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "\n",
    "ax.hist(samp_standardized_rating, bins=15, density=True, color='r')\n",
    "ax.set_xlabel('Z Scores')\n",
    "ax.set_title('120 Minutes and Up - Ratings')\n",
    "\n",
    "# applying normalized curve over histogram\n",
    "sns.kdeplot(samp_standardized_rating, ax=ax, color='k')\n",
    "\n",
    "# marking standardized_mean\n",
    "ax.vlines(x=z_mean, ymin=0, ymax=0.7, color='b', label='Mean: 0.2899')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting tested runtime sample against population\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "\n",
    "plt.hist(pop_standardized_rating, bins=45, density=True, color='b', alpha = 0.5)\n",
    "sns.kdeplot(pop_standardized_rating, ax=ax, color='y')\n",
    "\n",
    "plt.hist(samp_standardized_rating, bins=15, density=True, color='r', alpha = 0.5)\n",
    "sns.kdeplot(samp_standardized_rating, ax=ax, color='k')\n",
    "\n",
    "plt.vlines(x=z_mean, ymin=0, ymax=0.7, color='m', label='120 < x Mean: 0.2899')\n",
    "plt.vlines(x=pop_z_mean, ymin=0, ymax=0.7, label='Population Mean: 0.0')\n",
    "                                              \n",
    "plt.xlabel('Z Scores')\n",
    "plt.title('120 Minutes and Up to All Films - Ratings')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation:\n",
    "\n",
    "##### Ho:\n",
    "##### - There is no correlation between runtime and average rating for movies that are 120 minutes or longer. \n",
    "\n",
    "##### Ha:\n",
    "##### - There is a statistically significant correlation between runtime and average rating at the 95% level for movies that are 120 minutes or longer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r-critical value to test if found r is statistically signifcant\n",
    "critical_r = 0.0235\n",
    "# Source: https://www.calculators.tech/t-value-calculator\n",
    "# (Unable to calculate by hand as I have been unable to find a direct formula to find this - must use either r-critical table or a r-crit calculator like the above source)\n",
    "df = df_120up['Runtime'].count() - 2 # getting degrees of freedom to determine r-critical\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating correlation\n",
    "\n",
    "x = df_120up['Runtime']\n",
    "y = df_120up['AverageRating']\n",
    "\n",
    "r = x.corr(y) # result is the pearson correlation coefficient\n",
    "r\n",
    "\n",
    "print(f'Pearson Correlation: {r} | r-critical: {critical_r} | Is r greater? {abs(r) >= critical_r}')\n",
    "if abs(r) >= critical_r:\n",
    "    print(\"Reject the null\")\n",
    "elif abs(r) < critical_r:\n",
    "    print(\"Fail to reject null\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the regression showing the line of best fit with slope of r\n",
    "sns.lmplot(x=\"Runtime\", y=\"AverageRating\", data=df_120up, line_kws={'color': 'red'}, height=8, aspect=1.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions from Runtime Sample Testing for Average Ratings\n",
    "\n",
    "Z-Tests:\n",
    "- For films that are less than 40 minute runtimes, we can reject the null hypothesis with a statistically significant p-value of 0.0000001193, meaning that in 95% of cases we can expect our average ratings to be higher because of this set of runtimes.\n",
    "    ##### - Reject the Null\n",
    "- For films that have between 40 and 60 minute runtimes, we can reject the null hypothesis with a statistically significant p-value of 0.0, meaning that in 95% of cases we can expect our average ratings to be higher because of this set of runtimes.\n",
    "    ##### - Reject the Null\n",
    "- For films that have between 60 and 90 minute runtimes, we can reject the null hypothesis with a statistically significant p-value of 0.0, meaning that in 95% of cases we can expect our average ratings to be lower because of this set of runtimes.\n",
    "    ##### - Reject the Null\n",
    "- For films that have between 90 and 120 minute runtimes, we can reject the null hypothesis with a statistically significant p-value of 0.00008571, meaning that in 95% of cases we can expect our average ratings to be higher because of this set of runtimes.\n",
    "    ##### - Reject the Null\n",
    "- For films that have either 120 minute runtimes or longer, we can reject the null hypothesis with a statistically significant p-value of 0.0, meaning that in 95% of cases we can expect our average ratings to be higher because of this set of runtimes.\n",
    "    ##### - Reject the Null\n",
    "\n",
    "Correlation:\n",
    "- In 95% of cases, movies that 90 minutes or longer have a weak positive correlation between their runtime and their ratings. \n",
    "- In 95% of cases, movies that last between 60 and 90 minutes have a weak negative correlation between their runtime and ratings.\n",
    "- For movies that are less than 60 minutes long, we cannot conclude that there is a statistically significant correlation either.\n",
    "\n",
    "For all films less than 3.5 hours long (where we cut off movie runtimes that client would be unlikely to want to pursue), there is a statistically significant weak positive correlation between runtime and average rating of a film in 95% of cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging Data from SQL IMdb and Box Office Records (Elliot's Effort)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Domestic Revenue per Rating Table \n",
    "- Merging on title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# merging dr_movie_db with the sql database data\n",
    "domgross_im_db = dr_movie_db.merge(df_allrt,how='inner',on='title')\n",
    "domgross_im_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# checking for unintentionally duplicated values\n",
    "domgross_im_db.duplicated('title').value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dropping found unintentionally duplicated values\n",
    "domgross_im_db = domgross_im_db.drop_duplicates(subset='title')\n",
    "domgross_im_db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis for Runtime and Domestic Gross Revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardizing population for secondary visualizations to follow\n",
    "mu = domgross_im_db['domestic_gross'].mean()\n",
    "std = domgross_im_db['domestic_gross'].std()\n",
    "\n",
    "pop_standardized_rating = [(x-mu)/std for x in domgross_im_db['domestic_gross']]\n",
    "pop_z_mean = np.mean(pop_standardized_rating)\n",
    "pop_z_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Up to 40 Minutes Testing\n",
    "\n",
    "### Z-Test\n",
    "\n",
    "### Ho:\n",
    "##### - There is no difference between the domestic revenue of a movie that has a runtime of 40 minutes or less and other movies in the population.\n",
    "\n",
    "### Ha:\n",
    "##### - There is a statistically significant difference between the domestic revenue of a movie that has a runtime of between 40 minutes or less minutes and other movies in the population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pulling sample based on runtime from combined data\n",
    "domgross_40_db = domgross_im_db.loc[domgross_im_db['Runtime'] <= 40]\n",
    "domgross_40_db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Unable to perform z-test for this as there are no rows in sample for this range."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 40 to 60 Minutes Testing\n",
    "\n",
    "### Z-Test\n",
    "\n",
    "### Ho:\n",
    "##### - There is no difference between the domestic revenue of a movie that has a runtime of between 40 minutes and 60 minutes and other movies in the population.\n",
    "\n",
    "### Ha:\n",
    "##### - There is a statistically significant difference between the domestic revenue of a movie that has a runtime of between 40 minutes and 60 minutes and other movies in the population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# pulling sample based on runtime from combined data\n",
    "domgross_4060_db = domgross_im_db.loc[(domgross_im_db['Runtime'] > 40) & (domgross_im_db['Runtime'] <= 60)]\n",
    "domgross_4060_db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Unable to perform z-test for this as there are no rows in sample for this range."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 60 to 90 Minutes Testing\n",
    "\n",
    "### Z-Test\n",
    "\n",
    "### Ho:\n",
    "##### - There is no difference between the domestic revenue of a movie that has a runtime of between 60 minutes and 90 minutes and other movies in the population.\n",
    "\n",
    "### Ha:\n",
    "##### - There is a statistically significant difference between the domestic revenue of a movie that has a runtime of between 60 minutes and 90 minutes and other movies in the population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pulling sample based on runtime from combined data\n",
    "domgross_6090_db = domgross_im_db.loc[(domgross_im_db['Runtime'] > 60) & (domgross_im_db['Runtime'] <= 90)]\n",
    "domgross_6090_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z-test - 60 minutes to 90 minutes domestic revenue run\n",
    "\n",
    "a = 0.025\n",
    "\n",
    "# two-tailed z-test\n",
    "x_bar = domgross_6090_db['domestic_gross'].mean()\n",
    "n = domgross_6090_db['domestic_gross'].count()\n",
    "std = domgross_im_db['domestic_gross'].std()\n",
    "mu = domgross_im_db['domestic_gross'].mean()\n",
    "\n",
    "z = (x_bar - mu)/(std/np.sqrt(n))\n",
    "p = 1 - stats.norm.cdf(np.absolute(z))\n",
    "\n",
    "# displaying results\n",
    "print(f'Sample Mean: {x_bar} | Population Mean: {mu} | Sample Size: {n}')\n",
    "print(f'p-value: {p} | z-score: {z} | Is p less than alpha? {p < a}')\n",
    "if p < a:\n",
    "    print(\"Reject the null\")\n",
    "elif p >= a:\n",
    "    print(\"Fail to reject null\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing distribution with for loop\n",
    "samp_standardized_rating = [(x-mu)/std for x in domgross_6090_db['domestic_gross']]\n",
    "z_mean = np.mean(samp_standardized_rating)\n",
    "print(f' Standardized Sample Mean: {z_mean}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizing above distribution as histogram\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "\n",
    "ax.hist(samp_standardized_rating, bins=11, density=True, color='r')\n",
    "ax.set_xlabel('Z Scores')\n",
    "ax.set_title('60 to 90 Minutes - DM Revenue')\n",
    "\n",
    "# applying normalized curve over histogram\n",
    "sns.kdeplot(samp_standardized_rating, ax=ax, color='k')\n",
    "\n",
    "# marking standardized_mean\n",
    "ax.vlines(x=z_mean, ymin=0, ymax=0.7, color='b', label='Mean: -0.2567')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting tested runtime sample against population\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "\n",
    "plt.hist(pop_standardized_rating, bins=16, density=True, color='b', alpha = 0.5)\n",
    "sns.kdeplot(pop_standardized_rating, ax=ax, color='y')\n",
    "\n",
    "plt.hist(samp_standardized_rating, bins=11, density=True, color='r', alpha = 0.5)\n",
    "sns.kdeplot(samp_standardized_rating, ax=ax, color='k')\n",
    "\n",
    "plt.vlines(x=z_mean, ymin=0, ymax=0.7, color='m', label='60 < x <= 90 Mean: -0.2567')\n",
    "plt.vlines(x=pop_z_mean, ymin=0, ymax=0.7, label='Population Mean: 0.0')\n",
    "                                              \n",
    "plt.xlabel('Z Scores')\n",
    "plt.title('60 to 90 Minutes to All Films - DM Revenue')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 90 to 120 Minutes Testing\n",
    "\n",
    "### Z-Test\n",
    "\n",
    "### Ho:\n",
    "##### - There is no difference between the domestic revenue of a movie that has a runtime of between 90 minutes and 120 minutes and other movies in the population.\n",
    "\n",
    "### Ha:\n",
    "##### - There is a statistically significant difference between the domestic revenue of a movie that has a runtime of between 90 minutes and 120 minutes and other movies in the population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pulling sample based on runtime from combined data\n",
    "domgross_90120_db = domgross_im_db.loc[(domgross_im_db['Runtime'] > 90) & (domgross_im_db['Runtime'] <= 120)]\n",
    "domgross_90120_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z-test - 90 minutes to 120 minutes domestic revenue run\n",
    "\n",
    "a = 0.025\n",
    "\n",
    "# two-tailed z-test\n",
    "x_bar = domgross_90120_db['domestic_gross'].mean()\n",
    "n = domgross_90120_db['domestic_gross'].count()\n",
    "std = domgross_im_db['domestic_gross'].std()\n",
    "mu = domgross_im_db['domestic_gross'].mean()\n",
    "\n",
    "z = (x_bar - mu)/(std/np.sqrt(n))\n",
    "p = 1 - stats.norm.cdf(np.absolute(z))\n",
    "\n",
    "# displaying results\n",
    "print(f'Sample Mean: {x_bar} | Population Mean: {mu} | Sample Size: {n}')\n",
    "print(f'p-value: {p} | z-score: {z} | Is p less than alpha? {p < a}')\n",
    "if p < a:\n",
    "    print(\"Reject the null\")\n",
    "elif p >= a:\n",
    "    print(\"Fail to reject null\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing distribution with for loop\n",
    "samp_standardized_rating = [(x-mu)/std for x in domgross_90120_db['domestic_gross']]\n",
    "z_mean = np.mean(samp_standardized_rating)\n",
    "print(f' Standardized Sample Mean: {z_mean}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizing above distribution as histogram\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "\n",
    "ax.hist(samp_standardized_rating, bins=22, density=True, color='r')\n",
    "ax.set_xlabel('Z Scores')\n",
    "ax.set_title('90 to 120 Minutes - DM Revenue')\n",
    "\n",
    "# applying normalized curve over histogram\n",
    "sns.kdeplot(samp_standardized_rating, ax=ax, color='k')\n",
    "\n",
    "# marking standardized_mean\n",
    "ax.vlines(x=z_mean, ymin=0, ymax=0.7, color='b', label='Mean: -0.04584')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting tested runtime sample against population\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "\n",
    "plt.hist(pop_standardized_rating, bins=45, density=True, color='b', alpha = 0.5)\n",
    "sns.kdeplot(pop_standardized_rating, ax=ax, color='y')\n",
    "\n",
    "plt.hist(samp_standardized_rating, bins=15, density=True, color='r', alpha = 0.5)\n",
    "sns.kdeplot(samp_standardized_rating, ax=ax, color='k')\n",
    "\n",
    "plt.vlines(x=z_mean, ymin=0, ymax=0.7, color='m', label='90 < x <= 120 Mean: -0.04584')\n",
    "plt.vlines(x=pop_z_mean, ymin=0, ymax=0.7, label='Population Mean: 0.0')\n",
    "                                              \n",
    "plt.xlabel('Z Scores')\n",
    "plt.title('90 to 120 Minutes to All Films - DM Revenue')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 120 Minutes and Up Testing\n",
    "\n",
    "### Z-Test\n",
    "\n",
    "### Ho:\n",
    "##### - There is no difference between the domestic revenue of a movie that has a runtime of 120 minutes or greater and other movies in the population.\n",
    "\n",
    "### Ha:\n",
    "##### - There is a statistically significant difference between the domestic revenue of a movie that has a runtime of 120 minutes or greater and other movies in the population at the 95% level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pulling sample based on runtime from combined data\n",
    "domgross_120up_db = domgross_im_db.loc[domgross_im_db['Runtime'] > 120]\n",
    "domgross_120up_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z-test - 120 minutes and up domestic revenue run\n",
    "\n",
    "a = 0.025\n",
    "\n",
    "# two-tailed z-test\n",
    "x_bar = domgross_120up_db['domestic_gross'].mean()\n",
    "n = domgross_120up_db['domestic_gross'].count()\n",
    "std = domgross_im_db['domestic_gross'].std()\n",
    "mu = domgross_im_db['domestic_gross'].mean()\n",
    "\n",
    "z = (x_bar - mu)/(std/np.sqrt(n))\n",
    "p = 1 - stats.norm.cdf(np.absolute(z))\n",
    "\n",
    "# displaying results\n",
    "print(f'Sample Mean: {x_bar} | Population Mean: {mu} | Sample Size: {n}')\n",
    "print(f'p-value: {p} | z-score: {z} | Is p less than alpha? {p < a}')\n",
    "if p < a:\n",
    "    print(\"Reject the null\")\n",
    "elif p >= a:\n",
    "    print(\"Fail to reject null\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing distribution with for loop\n",
    "samp_standardized_rating = [(x-mu)/std for x in domgross_120up_db['domestic_gross']]\n",
    "z_mean = np.mean(samp_standardized_rating)\n",
    "print(f' Standardized Sample Mean: {z_mean}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizing above distribution as histogram\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "\n",
    "ax.hist(samp_standardized_rating, bins=11, density=True, color='r')\n",
    "ax.set_xlabel('Z Scores')\n",
    "ax.set_title('120 Minutes and Up - DM Revenue')\n",
    "\n",
    "# applying normalized curve over histogram\n",
    "sns.kdeplot(samp_standardized_rating, ax=ax, color='k')\n",
    "\n",
    "# marking standardized_mean\n",
    "ax.vlines(x=z_mean, ymin=0, ymax=0.7, color='b', label='Mean: 0.3130')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting tested runtime sample against population\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "\n",
    "plt.hist(pop_standardized_rating, bins=45, density=True, color='b', alpha = 0.5)\n",
    "sns.kdeplot(pop_standardized_rating, ax=ax, color='y')\n",
    "\n",
    "plt.hist(samp_standardized_rating, bins=15, density=True, color='r', alpha = 0.5)\n",
    "sns.kdeplot(samp_standardized_rating, ax=ax, color='k')\n",
    "\n",
    "plt.vlines(x=z_mean, ymin=0, ymax=0.7, color='m', label='120 < x Mean: 0.3130')\n",
    "plt.vlines(x=pop_z_mean, ymin=0, ymax=0.7, label='Population Mean: 0.0')\n",
    "                                              \n",
    "plt.xlabel('Z Scores')\n",
    "plt.title('120 Minutes and Up to All Films - DM Revenue')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation\n",
    "\n",
    "### Ho:\n",
    "##### - There is no correlation between runtime and the domestic gross revenue for a given movie at the 95% level.  \n",
    "\n",
    "### Ha:\n",
    "##### - There is a statistically significant correlation between runtime and the domestic gross revenue at the 95% level for a given movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r-critical value to test if found r is statistically signifcant\n",
    "critical_r = 0.0510\n",
    "# Source: https://www.calculators.tech/t-value-calculator\n",
    "# (Unable to calculate by hand as I have been unable to find a direct formula to find this - must use either r-critical table or a r-crit calculator like the above source)\n",
    "df = domgross_im_db['Runtime'].count() - 2 # getting degrees of freedom to determine r-critical\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating correlation\n",
    "\n",
    "x = domgross_im_db['Runtime']\n",
    "y = domgross_im_db['domestic_gross']\n",
    "\n",
    "r = x.corr(y) # result is the pearson correlation coefficient\n",
    "r\n",
    "\n",
    "print(f'Pearson Correlation: {r} | r-critical: {critical_r} | Is r greater? {abs(r) >= critical_r}')\n",
    "if abs(r) >= critical_r:\n",
    "    print(\"Reject the null\")\n",
    "elif abs(r) < critical_r:\n",
    "    print(\"Fail to reject null\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x=\"Runtime\", y=\"domestic_gross\", data=domgross_im_db, line_kws={'color': 'red'}, height=8, aspect=1.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Worldwide Revenue per Rating Table \n",
    "- Merging on title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging dr_movie_db with the sql database data\n",
    "wwgross_im_db = wwr_movie_db.merge(df_allrt,how='inner',on='title')\n",
    "wwgross_im_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking for unintentionally duplicated values\n",
    "wwgross_im_db.duplicated('title').value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dropping found unintentionally duplicated values\n",
    "wwgross_im_db = wwgross_im_db.drop_duplicates(subset='title')\n",
    "wwgross_im_db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis Testing for Runtime and Worldwide Gross Revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardizing population for secondary visualizations to follow\n",
    "mu = wwgross_im_db['worldwide_gross'].mean()\n",
    "std = wwgross_im_db['worldwide_gross'].std()\n",
    "\n",
    "pop_standardized_rating = [(x-mu)/std for x in wwgross_im_db['worldwide_gross']]\n",
    "pop_z_mean = np.mean(pop_standardized_rating)\n",
    "pop_z_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Less than 40 Minutes Testing\n",
    "\n",
    "### Z-Test\n",
    "\n",
    "### Ho:\n",
    "##### - There is no difference between the worldwide revenue of a movie that has a runtime of less than 40 minutes and other movies in the population.\n",
    "\n",
    "### Ha:\n",
    "##### - There is a statistically significant difference between the worldwide revenue of a movie that has a runtime of less than 40 minutes and the population. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wwgross_40_db = wwgross_im_db.loc[wwgross_im_db['Runtime'] <= 40]\n",
    "wwgross_40_db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Unable to perform z-test for this as there are no rows in sample for this range."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 40 to 60 Minutes Testing\n",
    "\n",
    "### Z-Test\n",
    "\n",
    "### Ho:\n",
    "##### - There is no difference between the worldwide revenue of a movie that has a runtime of between 40 minutes and 60 minutes and other movies in the population.\n",
    "\n",
    "### Ha:\n",
    "##### - There is a statistically significant difference between the worldwide revenue of a movie that has a runtime of between 40 minutes and 60 minutes and other movies in the population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wwgross_4060_db = wwgross_im_db.loc[(wwgross_im_db['Runtime'] > 40) & (wwgross_im_db['Runtime'] <= 60)]\n",
    "wwgross_4060_db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Unable to perform z-test for this as there are no rows in sample for this range."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 60 to 90 Minutes Testing\n",
    "\n",
    "### Z-Test\n",
    "\n",
    "### Ho:\n",
    "##### - There is no difference between the worldwide revenue of a movie that has a runtime of between 60 minutes and 90 minutes and other movies in the population.\n",
    "\n",
    "### Ha:\n",
    "##### - There is a statistically significant difference between the worldwide revenue of a movie that has a runtime of between 60 minutes and 90 minutes and other movies in the population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wwgross_6090_db = wwgross_im_db.loc[(wwgross_im_db['Runtime'] > 60) & (wwgross_im_db['Runtime'] <= 90)]\n",
    "wwgross_6090_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z-test - 60 minutes to 90 minutes worldwide revenue run\n",
    "\n",
    "a = 0.025\n",
    "\n",
    "# two-tailed z-test\n",
    "x_bar = wwgross_6090_db['worldwide_gross'].mean()\n",
    "n = wwgross_6090_db['worldwide_gross'].count()\n",
    "std = wwgross_im_db['worldwide_gross'].std()\n",
    "mu = wwgross_im_db['worldwide_gross'].mean()\n",
    "\n",
    "z = (x_bar - mu)/(std/np.sqrt(n))\n",
    "p = 1 - stats.norm.cdf(np.absolute(z))\n",
    "\n",
    "# displaying results\n",
    "print(f'Sample Mean: {x_bar} | Population Mean: {mu} | Sample Size: {n}')\n",
    "print(f'p-value: {p} | z-score: {z} | Is p less than alpha? {p < a}')\n",
    "if p < a:\n",
    "    print(\"Reject the null\")\n",
    "elif p >= a:\n",
    "    print(\"Fail to reject null\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing distribution with for loop\n",
    "samp_standardized_rating = [(x-mu)/std for x in wwgross_6090_db['worldwide_gross']]\n",
    "z_mean = np.mean(samp_standardized_rating)\n",
    "print(f' Standardized Sample Mean: {z_mean}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizing above distribution as histogram\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "\n",
    "ax.hist(samp_standardized_rating, bins=11, density=True, color='r')\n",
    "ax.set_xlabel('Z Scores')\n",
    "ax.set_title('60 to 90 Minutes - WW Revenue')\n",
    "\n",
    "# applying normalized curve over histogram\n",
    "sns.kdeplot(samp_standardized_rating, ax=ax, color='k')\n",
    "\n",
    "# marking standardized_mean\n",
    "ax.vlines(x=z_mean, ymin=0, ymax=0.7, color='b', label='Mean: -0.3105')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting tested runtime sample against population\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "\n",
    "plt.hist(pop_standardized_rating, bins=16, density=True, color='b', alpha = 0.5)\n",
    "sns.kdeplot(pop_standardized_rating, ax=ax, color='y')\n",
    "\n",
    "plt.hist(samp_standardized_rating, bins=11, density=True, color='r', alpha = 0.5)\n",
    "sns.kdeplot(samp_standardized_rating, ax=ax, color='k')\n",
    "\n",
    "plt.vlines(x=z_mean, ymin=0, ymax=0.7, color='m', label='60 < x <= 90 Mean: -0.3105')\n",
    "plt.vlines(x=pop_z_mean, ymin=0, ymax=0.7, label='Population Mean: 0.0')\n",
    "                                              \n",
    "plt.xlabel('Z Scores')\n",
    "plt.title('60 to 90 Minutes to All Films - WW Revenue')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 90 to 120 Minutes Testing\n",
    "\n",
    "### Z-Test\n",
    "\n",
    "### Ho:\n",
    "##### - There is no difference between the worldwide revenue of a movie that has a runtime of between 90 minutes and 120 minutes and other movies in the population.\n",
    "\n",
    "### Ha:\n",
    "##### - There is a statistically significant difference between the worldwide revenue of a movie that has a runtime of between 90 minutes and 120 minutes and other movies in the population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wwgross_90120_db = wwgross_im_db.loc[(wwgross_im_db['Runtime'] > 90) & (wwgross_im_db['Runtime'] <= 120)]\n",
    "wwgross_90120_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z-test - 90 minutes to 120 minutes worldwide revenue run\n",
    "\n",
    "a = 0.025\n",
    "\n",
    "# two-tailed z-test\n",
    "x_bar = wwgross_90120_db['worldwide_gross'].mean()\n",
    "n = wwgross_90120_db['worldwide_gross'].count()\n",
    "std = wwgross_im_db['worldwide_gross'].std()\n",
    "mu = wwgross_im_db['worldwide_gross'].mean()\n",
    "\n",
    "z = (x_bar - mu)/(std/np.sqrt(n))\n",
    "p = 1 - stats.norm.cdf(np.absolute(z))\n",
    "\n",
    "# displaying results\n",
    "print(f'Sample Mean: {x_bar} | Population Mean: {mu} | Sample Size: {n}')\n",
    "print(f'p-value: {p} | z-score: {z} | Is p less than alpha? {p < a}')\n",
    "if p < a:\n",
    "    print(\"Reject the null\")\n",
    "elif p >= a:\n",
    "    print(\"Fail to reject null\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing distribution with for loop\n",
    "samp_standardized_rating = [(x-mu)/std for x in wwgross_90120_db['worldwide_gross']]\n",
    "z_mean = np.mean(samp_standardized_rating)\n",
    "print(f' Standardized Sample Mean: {z_mean}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizing above distribution as histogram\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "\n",
    "ax.hist(samp_standardized_rating, bins=15, density=True, color='r')\n",
    "ax.set_xlabel('Z Scores')\n",
    "ax.set_title('90 to 120 Minutes - WW Revenue')\n",
    "\n",
    "# applying normalized curve over histogram\n",
    "sns.kdeplot(samp_standardized_rating, ax=ax, color='k')\n",
    "\n",
    "# marking standardized_mean\n",
    "ax.vlines(x=z_mean, ymin=0, ymax=0.7, color='b', label='Mean: -0.0203')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting tested runtime sample against population\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "\n",
    "plt.hist(pop_standardized_rating, bins=45, density=True, color='b', alpha = 0.5)\n",
    "sns.kdeplot(pop_standardized_rating, ax=ax, color='y')\n",
    "\n",
    "plt.hist(samp_standardized_rating, bins=15, density=True, color='r', alpha = 0.5)\n",
    "sns.kdeplot(samp_standardized_rating, ax=ax, color='k')\n",
    "\n",
    "plt.vlines(x=z_mean, ymin=0, ymax=0.7, color='m', label='90 < x <= 120 Mean: -0.0203')\n",
    "plt.vlines(x=pop_z_mean, ymin=0, ymax=0.7, label='Population Mean: 0.0')\n",
    "                                              \n",
    "plt.xlabel('Z Scores')\n",
    "plt.title('90 to 120 Minutes to All Films - WW Revenue')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 120 and up Minutes Testing\n",
    "\n",
    "### Z-Test\n",
    "\n",
    "### Ho:\n",
    "##### - There is no difference between the worldwide revenue of a movie that has a runtime of 120 minutes or greater and other movies in the population.\n",
    "\n",
    "### Ha:\n",
    "##### - There is a statistically significant difference between the worldwide revenue of a movie that has a runtime of 120 minutes or greater and other movies in the population at the 95% level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wwgross_120up_db = wwgross_im_db.loc[wwgross_im_db['Runtime'] > 120]\n",
    "wwgross_120up_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z-test - 120 minutes and up worldwide revenue run\n",
    "\n",
    "a = 0.025\n",
    "\n",
    "# two-tailed z-test\n",
    "x_bar = wwgross_120up_db['worldwide_gross'].mean()\n",
    "n = wwgross_120up_db['worldwide_gross'].count()\n",
    "std = wwgross_im_db['worldwide_gross'].std()\n",
    "mu = wwgross_im_db['worldwide_gross'].mean()\n",
    "\n",
    "z = (x_bar - mu)/(std/np.sqrt(n))\n",
    "p = 1 - stats.norm.cdf(np.absolute(z))\n",
    "\n",
    "# displaying results\n",
    "print(f'Sample Mean: {x_bar} | Population Mean: {mu} | Sample Size: {n}')\n",
    "print(f'p-value: {p} | z-score: {z} | Is p less than alpha? {p < a}')\n",
    "if p < a:\n",
    "    print(\"Reject the null\")\n",
    "elif p >= a:\n",
    "    print(\"Fail to reject null\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing distribution with for loop\n",
    "samp_standardized_rating = [(x-mu)/std for x in wwgross_120up_db['worldwide_gross']]\n",
    "z_mean = np.mean(samp_standardized_rating)\n",
    "print(f' Standardized Sample Mean: {z_mean}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizing above distribution as histogram\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "\n",
    "ax.hist(samp_standardized_rating, bins=15, density=True, color='r')\n",
    "ax.set_xlabel('Z Scores')\n",
    "ax.set_title('120 Minutes and Up - WW Revenue')\n",
    "\n",
    "# applying normalized curve over histogram\n",
    "sns.kdeplot(samp_standardized_rating, ax=ax, color='k')\n",
    "\n",
    "# marking standardized_mean\n",
    "ax.vlines(x=z_mean, ymin=0, ymax=0.7, color='b', label='Mean: 0.2631')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting tested runtime sample against population\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "\n",
    "plt.hist(pop_standardized_rating, bins=45, density=True, color='b', alpha = 0.5)\n",
    "sns.kdeplot(pop_standardized_rating, ax=ax, color='y')\n",
    "\n",
    "plt.hist(samp_standardized_rating, bins=15, density=True, color='r', alpha = 0.5)\n",
    "sns.kdeplot(samp_standardized_rating, ax=ax, color='k')\n",
    "\n",
    "plt.vlines(x=z_mean, ymin=0, ymax=0.7, color='m', label='120 < x Mean: 0.2631')\n",
    "plt.vlines(x=pop_z_mean, ymin=0, ymax=0.7, label='Population Mean: 0.0')\n",
    "                                              \n",
    "plt.xlabel('Z Scores')\n",
    "plt.title('120 Minutes and Up to All Films - WW Revenue')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Domestic Gross Z-Tests:\n",
    "- For films that are less than 40 minute runtimes, we cannot perform a hypothesis test because our filter returns no values in this runtime range.\n",
    "    ##### - Inconclusive\n",
    "- For films that have between 40 and 60 minute runtimes, we cannot perform a hypothesis test because our filter returns no values in this runtime range.\n",
    "    ##### - Inconclusive\n",
    "- For films that have between 60 and 90 minute runtimes, we can reject the null hypothesis with a statistically significant p-value of 0.0026, meaning that in 95% of cases we can expect our revenue to be lower (due to negative z-score) if a film falls within this set of runtimes.\n",
    "    ##### - Reject the Null\n",
    "- For films that have between 90 and 120 minute runtimes, we fail to reject the null hypothesis for a p-value of 0.1094 because it is greater than our alpha 0.025.\n",
    "    ##### - Fail to reject the Null\n",
    "- For films that have either 120 minute runtimes or longer, we can reject the null hypothesis with a statistically significant p-value of 0.000004, meaning that in 95% of cases we can expect our revenue to be higher (due to positive z-score) because of the movie falling this range of runtimes.\n",
    "    ##### - Reject the Null\n",
    "    \n",
    "### Worldwide Gross Z-Tests:\n",
    "- For films that are less than 40 minute runtimes, we cannot perform a hypothesis test because our filter returns no values in this runtime range.\n",
    "    ##### - Inconclusive\n",
    "- For films that have between 40 and 60 minute runtimes, we can reject the null hypothesis with a statistically significant p-value of 0.0, meaning that in 95% of cases we can expect our average ratings to be higher because of this set of runtimes.\n",
    "    ##### - Inconclusive\n",
    "- For films that have between 60 and 90 minute runtimes, we can reject the null hypothesis with a statistically significant p-value of 0.0004, meaning that in 95% of cases we can expect our revenue to be lower (due to negative z-score) if a film falls within this set of runtimes.\n",
    "    ##### - Reject the Null\n",
    "- For films that have between 90 and 120 minute runtimes, we fail to reject the null hypothesis for a p-value of 0.2937 because it is greater than our alpha 0.025.\n",
    "    ##### - Fail to reject the Null\n",
    "- For films that have either 120 minute runtimes or longer, we can reject the null hypothesis with a statistically significant p-value of 0.0001, meaning that in 95% of cases we can expect our revenue to be higher (due to positive z-score) because of the movie falling this range of runtimes.\n",
    "    ##### - Reject the Null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation for Worldwide Gross Revenue\n",
    "\n",
    "### Ho:\n",
    "##### - There is no correlation between runtime and the worldwide gross revenue for a given movie at the 95% level.  \n",
    "\n",
    "### Ha:\n",
    "##### - There is a statistically significant correlation between runtime and the worldwide gross revenue at the 95% level for a given movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r-critical value to test if found r is statistically signifcant\n",
    "critical_r = 0.0515\n",
    "# Source: https://www.calculators.tech/t-value-calculator\n",
    "# (Unable to calculate by hand as I have been unable to find a direct formula to find this - must use either r-critical table or a r-crit calculator like the above source)\n",
    "df = wwgross_im_db['Runtime'].count() - 2 # getting degrees of freedom to determine r-critical\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating correlation\n",
    "\n",
    "x = wwgross_im_db['Runtime']\n",
    "y = wwgross_im_db['worldwide_gross']\n",
    "\n",
    "r = x.corr(y) # result is the pearson correlation coefficient\n",
    "r\n",
    "\n",
    "print(f'Pearson Correlation: {r} | r-critical: {critical_r} | Is r greater? {abs(r) >= critical_r}')\n",
    "if abs(r) >= critical_r:\n",
    "    print(\"Reject the null\")\n",
    "elif abs(r) < critical_r:\n",
    "    print(\"Fail to reject null\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x=\"Runtime\", y=\"worldwide_gross\", data=wwgross_im_db, line_kws={'color': 'red'}, height=8, aspect=1.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the \"Movie info\" file\n",
    "movie_info_df = pd.read_csv('databases/rt.movie_info.tsv', sep='\\t', encoding = 'utf-8', index_col=0)\n",
    "movie_info_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data frame overview. Column information, name-data type.\n",
    "movie_info_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting missing values\n",
    "movie_info_df.isna().sum()\n",
    "\n",
    "# Removing duplicate records\n",
    "movie_info_df = movie_info_df.drop_duplicates()\n",
    "\n",
    "# Changing NaN values for String \"Not Available\"\n",
    "movie_info_df['rating'] = movie_info_df['rating'].fillna('N/A')\n",
    "movie_info_df['genre'] = movie_info_df['genre'].fillna('N/A')\n",
    "movie_info_df['director'] = movie_info_df['director'].fillna('N/A')\n",
    "movie_info_df['theater_date'] = movie_info_df['theater_date'].fillna('N/A')\n",
    "movie_info_df['dvd_date'] = movie_info_df['dvd_date'].fillna('N/A')\n",
    "movie_info_df['runtime'] = movie_info_df['runtime'].fillna('N/A')\n",
    "movie_info_df['studio'] = movie_info_df['studio'].fillna('N/A')\n",
    "movie_info_df['writer'] = movie_info_df['writer'].fillna('N/A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing NaN values for 0 in Box Office column\n",
    "movie_info_df['box_office'] = movie_info_df['box_office'].fillna(0)\n",
    "\n",
    "# Remmoving commas from Box Office values\n",
    "movie_info_df['box_office'] = movie_info_df['box_office'].replace({',':''}, regex=True)\n",
    "\n",
    "# Converting Box Office values into Integers\n",
    "movie_info_df['box_office'] = movie_info_df['box_office'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking possible Currency values\n",
    "currency_values = set(movie_info_df.loc[:,\"currency\"])\n",
    "\n",
    "# Changing NaN values for \"$\" in Currency column since is the only currency in the DB\n",
    "movie_info_df['currency'] = movie_info_df['currency'].fillna('$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Note: The information that we are interested in extracting from this database is the synopsis of each film, \n",
    "therefore, we have decided to delete those rows that do not have one.\n",
    "\"\"\"\n",
    "# Dropping rows with no synopsis\n",
    "cleansed_movie_info = movie_info_df.dropna(subset=['synopsis'])\n",
    "\n",
    "# Confirming that there in no more NaN values in our cleansed Data Frame\n",
    "cleansed_movie_info.isna().sum() # No more NaN values! We can start our analysis using the cleansed_movie_info DF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating new Data Frame to work on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Note: In order to analyze the most popular movies per year and genre, \n",
    "we created a new Data Frame containing only the Synopsis, Rating, Genres, Theater Date and Box Office.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spliting the theater date, keeping only the year.\n",
    "only_year = cleansed_movie_info[\"theater_date\"].str.split(\",\", n = 1, expand = True)\n",
    "# Creating columns for new DF\n",
    "years = np.array(only_year[1])\n",
    "# converting Year string into float\n",
    "years = years.astype(np.float) \n",
    "\n",
    "synopsis = np.array(cleansed_movie_info[\"synopsis\"])\n",
    "ratings = np.array(cleansed_movie_info[\"rating\"])\n",
    "box_office = np.array(cleansed_movie_info[\"box_office\"])\n",
    "\n",
    "# Creating Main Movie Info DF\n",
    "main_movie_info = pd.DataFrame() \n",
    "\n",
    "# Adding columns to new DF\n",
    "main_movie_info['Synopsis'] = synopsis\n",
    "main_movie_info['Ratings'] = ratings\n",
    "main_movie_info['Box Office'] = box_office\n",
    "main_movie_info['Years'] = years\n",
    "main_movie_info['Years'] = main_movie_info['Years'].fillna(0) # Filling with 0 the empty records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Sppliting the Genres into different columns\n",
    "split_genre = cleansed_movie_info[\"genre\"].str.split(\"|\", n = 6, expand = True)\n",
    "\n",
    "# Some movies have more than five different genres\n",
    "genre1 = np.array(split_genre[0])\n",
    "genre2 = np.array(split_genre[1])\n",
    "genre3 = np.array(split_genre[2])\n",
    "genre4 = np.array(split_genre[3])\n",
    "genre5 = np.array(split_genre[4])\n",
    "genre6 = np.array(split_genre[5])\n",
    "genre7 = np.array(split_genre[6])\n",
    "\n",
    "# # Adding a column for each genre in the new DF\n",
    "main_movie_info['Genre 1'] = genre1\n",
    "main_movie_info['Genre 2'] = genre2\n",
    "#main_movie_info['Genre 3'] = genre3\n",
    "#main_movie_info['Genre 4'] = genre4\n",
    "#main_movie_info['Genre 5'] = genre5\n",
    "#main_movie_info['Genre 6'] = genre6\n",
    "#main_movie_info['Genre 7'] = genre7\n",
    "\n",
    "\"\"\"\n",
    "Note: We decided to leave only 2 genre columns because most of the films only have 2 types of genres\n",
    "\"\"\"\n",
    "# main_movie_info overview\n",
    "main_movie_info.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many movies have been filmed in the last decades?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing data by filtering movies per Decade\n",
    "_20sfilms = main_movie_info.loc[(main_movie_info['Years'] >= 1920) & (main_movie_info['Years'] <= 1929)]\n",
    "_30sfilms = main_movie_info.loc[(main_movie_info['Years'] >= 1930) & (main_movie_info['Years'] <= 1939)]\n",
    "_40sfilms = main_movie_info.loc[(main_movie_info['Years'] >= 1940) & (main_movie_info['Years'] <= 1949)]\n",
    "_50sfilms = main_movie_info.loc[(main_movie_info['Years'] >= 1950) & (main_movie_info['Years'] <= 1959)]\n",
    "_60sfilms = main_movie_info.loc[(main_movie_info['Years'] >= 1960) & (main_movie_info['Years'] <= 1969)]\n",
    "_70sfilms = main_movie_info.loc[(main_movie_info['Years'] >= 1970) & (main_movie_info['Years'] <= 1979)]\n",
    "_80sfilms = main_movie_info.loc[(main_movie_info['Years'] >= 1980) & (main_movie_info['Years'] <= 1989)]\n",
    "_90sfilms = main_movie_info.loc[(main_movie_info['Years'] >= 1990) & (main_movie_info['Years'] <= 1999)]\n",
    "_00sfilms = main_movie_info.loc[(main_movie_info['Years'] >= 2000) & (main_movie_info['Years'] <= 2009)]\n",
    "_2010sfilms = main_movie_info.loc[(main_movie_info['Years'] >= 2010) & (main_movie_info['Years'] <= 2019)]\n",
    "\n",
    "# Counting movies per decade\n",
    "decades = [1920, 1930, 1940, 1950, 1960, 1970, 1980, 1999, 2000, 2010]\n",
    "movies_per_decade = [len(_20sfilms),len(_30sfilms),len(_40sfilms),len(_50sfilms),len(_60sfilms),len(_70sfilms),len(_80sfilms),len(_90sfilms),len(_00sfilms),len(_2010sfilms)]\n",
    "\n",
    "print('_________________________________________________________\\n')\n",
    "print('How many movies have been filmed in the last decades?\\n')\n",
    "print('Movies Per Decade:')\n",
    "for x,y in zip(decades,movies_per_decade):\n",
    "    print(x,y)\n",
    "print('_________________________________________________________\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing data\n",
    "x_decades = decades\n",
    "y_count = movies_per_decade\n",
    "\n",
    "# Graph attributes\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.xlabel('Decades', color='purple')\n",
    "plt.ylabel('Movies', color='purple')\n",
    "plt.title('Movies Per Decade', color='indigo')\n",
    "\n",
    "# Plotting\n",
    "plt.plot(x_decades, y_count, marker = 'o', markerfacecolor = 'r', color = 'plum')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which are the most popular genres in the last decades?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepering data for visualization \n",
    "# _decades = list of pd.serie that conteins all genres of movies released per decade \n",
    "_decades_ = [_20sfilms, _30sfilms, _40sfilms, _50sfilms, _60sfilms, _70sfilms, _80sfilms, _90sfilms, _00sfilms, _2010sfilms]\n",
    "\n",
    "# Creating a dictionary for each decade, it contains the total movies filmed per genre         \n",
    "_20sgenres = dict(collections.Counter(_20sfilms.loc[:,'Genre 1']))\n",
    "_30sgenres = dict(collections.Counter(_30sfilms.loc[:,'Genre 1']))\n",
    "_40sgenres = dict(collections.Counter(_40sfilms.loc[:,'Genre 1']))\n",
    "_50sgenres = dict(collections.Counter(_50sfilms.loc[:,'Genre 1']))\n",
    "_60sgenres = dict(collections.Counter(_60sfilms.loc[:,'Genre 1']))\n",
    "_70sgenres = dict(collections.Counter(_70sfilms.loc[:,'Genre 1']))\n",
    "_80sgenres = dict(collections.Counter(_80sfilms.loc[:,'Genre 1']))\n",
    "_90sgenres = dict(collections.Counter(_90sfilms.loc[:,'Genre 1']))\n",
    "_00sgenres = dict(collections.Counter(_00sfilms.loc[:,'Genre 1']))\n",
    "_2010sgenres = dict(collections.Counter(_2010sfilms.loc[:,'Genre 1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To visualize the most popular genres we're ploting data from the last 4 decades (80s - 2010s)\n",
    "# 80s Decade\n",
    "_80_labels = _80sgenres.keys()\n",
    "_80_values = _80sgenres.values()\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.title('Popular movie genre in the 1980s Decade', color='indigo')\n",
    "\n",
    "# Plotting\n",
    "plt.pie(_80_values, labels = _80_labels)\n",
    "plt.show()\n",
    "\n",
    "# 90s Decade\n",
    "_90_labels = _90sgenres.keys()\n",
    "_90_values = _90sgenres.values()\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.title('Popular movie genre in the 1990s Decade', color='indigo')\n",
    "\n",
    "# Plotting\n",
    "plt.pie(_90_values, labels = _90_labels)\n",
    "plt.show()\n",
    "\n",
    "# 2000 Decade\n",
    "_2000_labels = _00sgenres.keys()\n",
    "_2000_values = _00sgenres.values()\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.title('Popular movie genre in the 2000s Decade', color='indigo')\n",
    "\n",
    "# Plotting\n",
    "plt.pie(_2000_values, labels = _2000_labels)\n",
    "plt.show()\n",
    "\n",
    "# 2010 Decade\n",
    "_2010_labels = _2010sgenres.keys()\n",
    "_2010_values = _2010sgenres.values()\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.title('Popular movie genre in the 2010s Decade', color='indigo')\n",
    "\n",
    "# Plotting\n",
    "plt.pie(_2010_values, labels = _2010_labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('_________________________________________________________\\n')\n",
    "print('Which are the most popular genres in the last decades?\\n')\n",
    "print('As we can see in the pie plots, Action and Adventure, Comedy and Drama are the most popular Gernres in the las Decades.')\n",
    "print('We recomend filming this type of movies.')\n",
    "print('_________________________________________________________\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are the most popular themes per genre?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In order to find the most popular content we joined the synopsis per genre and cleand the vocabulary that is used. Finaly, we count the repetitions of each word and sort them to obtain the most popular \"key words\" to create our recomendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning synopsis\n",
    "def clean_synopsis(word, stop_words):\n",
    "    word = word.lower()\n",
    "    words = re.findall('[a-zÃ¡Ã©Ã­Ã³ÃºÃ¼Ã±]+', word)# Making sure synopsis words dont have a-zÃ¡Ã©Ã­Ã³ÃºÃ¼Ã± \n",
    "    new_words = [w for w in words if ((not w in stop_words) and len(w)>=3 and len(w)<=24)] # Keeping only words ->\n",
    "    return new_words                        #  different from stop words and also removing short or long words\n",
    "                                            # this function returns the cleaned words from the synopsis\n",
    "    \n",
    "# Creating a vocabulary based on synopsis with matching Genre and Decade\n",
    "def create_vocabulary(decade_genre_df):\n",
    "    vocabulary = []    # Vocabulary joins all synopsis words with matching Genre and Decade \n",
    "    for synopsis in decade_genre_df :\n",
    "        s = clean_synopsis(synopsis.strip(),s_w) # striping word from synopsis, this will clean a word at a time\n",
    "        vocabulary.extend(s)\n",
    "\n",
    "    return dict(collections.Counter(vocabulary)) # returns a dictionary like: key -> word, value -> repetitions of that word \n",
    "\n",
    "s_w = stopwords.words('english')\n",
    "#stops = set(stopwords.words('english')) # Uncoment to print ount english stop words \n",
    "#print(stops)\n",
    "\n",
    "# more words that we eant to ignore to refine our vocabulary\n",
    "s_w.extend(['film','one','two','story','director','new','action','adventure','peter', 'john', 'back',\n",
    "            'world','man', 'well','life', 'also', 'first','get','comedy','however', 'become', 'david','allen','jack'\n",
    "           'true', 'award', 'academy','deckard','willie', 'even','celie', 'loretta', 'whose','lynn','james'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# synopsis with matching Genre and Decade\n",
    "\n",
    "# Action and Adventure\n",
    "#_80s_action_Adventure\n",
    "_80s_action_Adventure = _80sfilms.loc[_80sfilms['Genre 1'] == 'Action and Adventure',\"Synopsis\"]\n",
    "_80s_acction_adventure_voc = create_vocabulary(_80s_action_Adventure) # Calling function to create vocabulary\n",
    "\n",
    "#_90s_action_Adventure \n",
    "_90s_action_Adventure = _90sfilms.loc[_90sfilms['Genre 1'] == 'Action and Adventure',\"Synopsis\"]\n",
    "_90s_acction_adventure_voc = create_vocabulary(_90s_action_Adventure)\n",
    "\n",
    "#_00s_action_Adventure \n",
    "_00s_action_Adventure = _00sfilms.loc[_00sfilms['Genre 1'] == 'Action and Adventure',\"Synopsis\"]\n",
    "_00s_acction_adventure_voc = create_vocabulary(_00s_action_Adventure)\n",
    "\n",
    "#_00s_action_Adventure \n",
    "_2010s_action_Adventure = _2010sfilms.loc[_2010sfilms['Genre 1'] == 'Action and Adventure',\"Synopsis\"]\n",
    "_2010s_acction_adventure_voc = create_vocabulary(_2010s_action_Adventure)\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------------------\n",
    "#_80s_Comedy\n",
    "_80s_Comedy = _80sfilms.loc[_80sfilms['Genre 1'] == 'Comedy',\"Synopsis\"]\n",
    "_80s_Comedy_voc = create_vocabulary(_80s_Comedy)\n",
    "\n",
    "#_90s_Comedy \n",
    "_90s_Comedy = _90sfilms.loc[_90sfilms['Genre 1'] == 'Comedy',\"Synopsis\"]\n",
    "_90s_Comedy_voc = create_vocabulary(_90s_Comedy)\n",
    "\n",
    "#_00s_Comedy \n",
    "_00s_Comedy = _00sfilms.loc[_00sfilms['Genre 1'] == 'Comedy',\"Synopsis\"]\n",
    "_00s_Comedy_voc = create_vocabulary(_00s_Comedy)\n",
    "\n",
    "#_00s_Comedy \n",
    "_2010s_Comedy = _2010sfilms.loc[_2010sfilms['Genre 1'] == 'Comedy',\"Synopsis\"]\n",
    "_2010s_Comedy_voc = create_vocabulary(_2010s_Comedy)\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------------------\n",
    "#_80s_Drama\n",
    "_80s_Drama = _80sfilms.loc[_80sfilms['Genre 1'] == 'Drama',\"Synopsis\"]\n",
    "_80s_Drama_voc = create_vocabulary(_80s_Drama)\n",
    "\n",
    "#_90s_Drama \n",
    "_90s_Drama = _90sfilms.loc[_90sfilms['Genre 1'] == 'Drama',\"Synopsis\"]\n",
    "_90s_Drama_voc = create_vocabulary(_90s_Drama)\n",
    "\n",
    "#_00s_Drama\n",
    "_00s_Drama = _00sfilms.loc[_00sfilms['Genre 1'] == 'Drama',\"Synopsis\"]\n",
    "_00s_Drama_voc = create_vocabulary(_00s_Drama)\n",
    "\n",
    "#_00s_Drama\n",
    "_2010s_Drama = _2010sfilms.loc[_2010sfilms['Genre 1'] == 'Drama',\"Synopsis\"]\n",
    "_2010s_Drama_voc = create_vocabulary(_2010s_Drama)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_popular_themes(vocabulary):\n",
    "    _counter = 0\n",
    "    popular_themes = []\n",
    "    for word in sorted(vocabulary, key=vocabulary.get, reverse=True): # Sorting vocabulary dict in order to get the most \n",
    "        popular_themes.append(word)                                   # repeted words: \"popular words\"\n",
    "        _counter += 1\n",
    "        if _counter == 5: # Saving only the 5 most popular words in our vocabulary\n",
    "            break\n",
    "    \n",
    "    return popular_themes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Popular themes in Action Adventure movies\n",
    "most_popular_80s_acction_adventure = most_popular_themes(_80s_acction_adventure_voc)\n",
    "most_popular_90s_acction_adventure = most_popular_themes(_90s_acction_adventure_voc)\n",
    "most_popular_00s_acction_adventure = most_popular_themes(_00s_acction_adventure_voc)\n",
    "most_popular_2010s_acction_adventure = most_popular_themes(_2010s_acction_adventure_voc)\n",
    "\n",
    "# Popular themes in Comedy movies\n",
    "most_popular_80s_Comedy = most_popular_themes(_80s_Comedy_voc)\n",
    "most_popular_90s_Comedy = most_popular_themes(_90s_Comedy_voc)\n",
    "most_popular_00s_Comedy= most_popular_themes(_00s_Comedy_voc)\n",
    "most_popular_2010s_Comedy = most_popular_themes(_2010s_Comedy_voc)\n",
    "\n",
    "# Popular themes in Drama movies\n",
    "most_popular_80s_Drama = most_popular_themes(_80s_Drama_voc)\n",
    "most_popular_90s_Drama = most_popular_themes(_90s_Drama_voc)\n",
    "most_popular_00s_Drama = most_popular_themes(_00s_Drama_voc)\n",
    "most_popular_2010s_Drama = most_popular_themes(_2010s_Drama_voc)\n",
    "\n",
    "# Printing results of the most popular words per genre\n",
    "print('Most popular words in Acction Adventure Vocabulary')\n",
    "print(most_popular_80s_acction_adventure)\n",
    "print(most_popular_90s_acction_adventure)\n",
    "print(most_popular_00s_acction_adventure)\n",
    "print(most_popular_2010s_acction_adventure)\n",
    "print('_______________________________________________')\n",
    "\n",
    "print('Most popular words in Comedy Vocabulary')\n",
    "print(most_popular_80s_Comedy)\n",
    "print(most_popular_90s_Comedy)\n",
    "print(most_popular_00s_Comedy)\n",
    "print(most_popular_2010s_Comedy)\n",
    "print('_______________________________________________')\n",
    "\n",
    "print('Most popular words in Drama Vocabulary')\n",
    "print(most_popular_80s_Drama)\n",
    "print(most_popular_90s_Drama)\n",
    "print(most_popular_00s_Drama)\n",
    "print(most_popular_2010s_Drama)\n",
    "print('_______________________________________________')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our recomendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Based on the insights founded in the Analysis on the data provided, we establish that the best opctions for filming \n",
    "1)  Category: Acction/Adventure. \n",
    "    Theme: cops with superpowers fighting a civil war in a big city.\n",
    "\n",
    "2)  Category: Comedy \n",
    "    Theme: New kid arrives to high shcool, finds new love and seeks to please his friends. \n",
    "\n",
    "3)  Category: Drama\n",
    "    Theme: Thue based story of a young family. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enrique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read tmdb file, make sure values are in the same format, and drop null values\n",
    "tmdbmovie_db = pd.read_csv('databases/tmdb.movies.csv', na_filter=True, na_values='[]', encoding = 'utf-8', index_col = 0)\n",
    "tmdbmovie_db.dropna()\n",
    "\n",
    "#drop extra title column\n",
    "tmdbmovie_db = tmdbmovie_db.drop('original_title', axis = 1)\n",
    "\n",
    "#standardize release date into date format\n",
    "tmdbmovie_db['release_date'] = pd.to_datetime(tmdbmovie_db['release_date'])\n",
    "\n",
    "#strip whitespace from title\n",
    "tmdbmovie_db['title'] = tmdbmovie_db['title'].str.strip()\n",
    "\n",
    "#remove duplicates\n",
    "tmdbmovie_db = tmdbmovie_db.drop_duplicates()\n",
    "\n",
    "#convert genre_ids to name\n",
    "#df.where()\n",
    "\n",
    "tmdbmovie_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read tmdb file, make sure values are in the same format, and drop null values\n",
    "tmdbmovie_db = pd.read_csv('databases/tmdb.movies.csv', na_filter=True, na_values='[]', encoding = 'utf-8', index_col = 0)\n",
    "tmdbmovie_db.dropna()\n",
    "\n",
    "#drop extra title column\n",
    "tmdbmovie_db = tmdbmovie_db.drop('original_title', axis = 1)\n",
    "\n",
    "#standardize release date into date format\n",
    "tmdbmovie_db['release_date'] = pd.to_datetime(tmdbmovie_db['release_date'])\n",
    "\n",
    "#strip whitespace from title\n",
    "tmdbmovie_db['title'] = tmdbmovie_db['title'].str.strip()\n",
    "\n",
    "#remove duplicates\n",
    "tmdbmovie_db = tmdbmovie_db.drop_duplicates()\n",
    "\n",
    "#convert genre_ids to name\n",
    "#df.where()\n",
    "\n",
    "tmdbmovie_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read tn file, make sure values are in the same format, and drop null values\n",
    "tnmovie_db = pd.read_csv('databases/tn.movie_budgets.csv', na_filter=True, na_values='[]', encoding = 'utf-8', index_col = 0)\n",
    "tnmovie_db.dropna()\n",
    "\n",
    "#standardize release date into date format\n",
    "tnmovie_db['release_date'] = pd.to_datetime(tnmovie_db['release_date'])\n",
    "\n",
    "#strip whitespace from title\n",
    "tnmovie_db['movie'] = tnmovie_db['movie'].str.strip()\n",
    "\n",
    "#strip $\n",
    "tnmovie_db['production_budget'] = tnmovie_db['production_budget'].str.strip('$')\n",
    "tnmovie_db['domestic_gross'] = tnmovie_db['domestic_gross'].str.strip('$')\n",
    "tnmovie_db['worldwide_gross'] = tnmovie_db['worldwide_gross'].str.strip('$')\n",
    "\n",
    "#remove ,\n",
    "tnmovie_db['production_budget'] = tnmovie_db['production_budget'].replace(\",\", \"\", regex=True)\n",
    "tnmovie_db['domestic_gross'] = tnmovie_db['domestic_gross'].replace(\",\", \"\", regex=True)\n",
    "tnmovie_db['worldwide_gross'] = tnmovie_db['worldwide_gross'].replace(\",\", \"\", regex=True)\n",
    "\n",
    "#convert to integers\n",
    "tnmovie_db['production_budget'] = tnmovie_db['production_budget'].astype(int)\n",
    "tnmovie_db['domestic_gross'] = tnmovie_db['domestic_gross'].astype(int)\n",
    "tnmovie_db['worldwide_gross'] = tnmovie_db['worldwide_gross'].astype(float)\n",
    "\n",
    "#create metric ratios\n",
    "tnmovie_db['dom_gross / budget'] = tnmovie_db['domestic_gross'] / tnmovie_db['production_budget']\n",
    "tnmovie_db['ww_gross / budget'] = tnmovie_db['worldwide_gross'] / tnmovie_db['production_budget']\n",
    "tnmovie_db['dom_profit'] = tnmovie_db['domestic_gross'] - tnmovie_db['production_budget']\n",
    "tnmovie_db['profit'] = tnmovie_db['worldwide_gross'] - tnmovie_db['production_budget']\n",
    "\n",
    "tnmovie_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge title and movie name\n",
    "tnmovie_db = tnmovie_db.rename(columns = {\"movie\":\"title\"})\n",
    "\n",
    "#special cases where movie titles do not match\n",
    "tnmovie_db['title'].replace({'Harry Potter and the Deathly Hallows: Part I' : 'Harry Potter and the Deathly Hallows: Part 1'}, inplace=True)\n",
    "tnmovie_db['title'].replace({'Harry Potter and the Deathly Hallows: Part II' : 'Harry Potter and the Deathly Hallows: Part 2'}, inplace=True)\n",
    "tmdbmovie_db['title'].replace({'Fast & Furious 6':'Fast and Furious 6'}, inplace=True)\n",
    "tnmovie_db['title'].replace({'Star Wars: The Force Awakens' : 'Star Wars Ep. VII: The Force Awakens'}, inplace=True)\n",
    "tnmovie_db['title'].replace({'Star Wars: The Last Jedi' : 'Star Wars Ep. VIII: The Last Jedi'}, inplace=True)\n",
    "\n",
    "#merge databases\n",
    "movie_db = tmdbmovie_db.merge(tnmovie_db, how = 'left')\n",
    "\n",
    "#drop null values\n",
    "movie_db.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove values that have 0 in the domestic_gross column\n",
    "newmovie_db = movie_db.drop(movie_db[movie_db['domestic_gross'] < 1].index)\n",
    "newmovie_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check to see if worldwide_gross and domestic_gross is 0 to remove outliers\n",
    "dcount = 0\n",
    "for x in movie_db['domestic_gross']:\n",
    "    if x == 0:\n",
    "        dcount += 1\n",
    "print(dcount)\n",
    "\n",
    "wwcount = 0\n",
    "for x in movie_db['worldwide_gross']:\n",
    "    if x == 0:\n",
    "        wwcount += 1\n",
    "print(wwcount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newmovie_db.dtypesnewmovie_db['popularity'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newmovie_db['ww_gross / budget'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newmovie_db['dom_gross / budget'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newmovie_db['genre_ids'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newmovie_db.value_counts('genre_ids').nlargest(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newmovie_db.value_counts('popularity').nlargest(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfg = newmovie_db.groupby(['release_date', 'genre_ids']).agg({'profit': sum}).reset_index()\n",
    "dfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(movie_db['genre_ids'], bins='auto')\n",
    "ax.set_xlabel('genre')\n",
    "ax.set_ylabel('ww_gross / budget')\n",
    "ax.set_title('Distribution of genre in Raw Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "sns.lineplot(x='release_date', y='profit', data=dfg, hue='genre_ids')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.hist(movie_db['genre_ids'], bins='auto')\n",
    "ax.set_xlabel('genre')\n",
    "ax.set_ylabel('ww_gross / budget')\n",
    "ax.set_title('Distribution of genre in Raw Data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our recommendation would be, if you are looking for a gamble then Adventure, War, Action and Fantasy could produce some great results. The leading profit genres (Action, Drama, Adventure) paint the more reliable story, and genre Action appears to be increasing in popularity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beside here we try to find a correlation of what we have stated in the graphs above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "H0 = there's a significative correlation between genre, the ratios and popularity (worlwide_gross/production_rate, dom_gross / budget and popularity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "H1 = there's not a significative correlation between genre,the ratios and popularity (worlwide_gross/production_rate and dom_gross / budget and popularity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANOVA is the most appropriate technique since we are trying to determine whether there is a difference in genre across 3 categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#import statsmodels.api as sm\n",
    "#from statsmodels.formula.api import ols\n",
    "\n",
    "#formula = 'none'\n",
    "#lm = ols(formula, movie_db).fit()\n",
    "#sm.stats.anova_lm(lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparation, modelling, visualisation and interpretation of the data, allowed us to conduct analysis of the movies that have been created since 2010.\n",
    "\n",
    "- Adventure films on average are the most profitable\n",
    "- The industry leaders preferred creating Action, Drama & Comedy films"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## John"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening + Reading the Movie_Gross CSV file\n",
    "tmdb_movie_gross = pd.read_csv('DataBases/bom.movie_gross.csv', encoding = 'utf-8')\n",
    "\n",
    "# Remove duplicate records\n",
    "tmdb_movie_gross = tmdb_movie_gross.drop_duplicates()\n",
    "\n",
    "# Replace NaN / null values to a \"0\" because we're reviewing gross/money. no value = no money generated in domestic gross\n",
    "## Standardize domestic_gross into an int\n",
    "tmdb_movie_gross['domestic_gross'] = tmdb_movie_gross['domestic_gross'].fillna(0)\n",
    "tmdb_movie_gross['domestic_gross'] = tmdb_movie_gross['domestic_gross'].astype(int)\n",
    "\n",
    "# Standardize foreign_gross into a float because you cannot turn decimals into an int\n",
    "## Inorder to change values into a float, you must get rid of the commas\n",
    "### Replace NaN / null values to a \"0\" because we're reviewing gross/money. no value = no money generated in foreign_gross\n",
    "tmdb_movie_gross['foreign_gross'] = tmdb_movie_gross['foreign_gross'].replace(\",\", \"\", regex=True)\n",
    "tmdb_movie_gross['foreign_gross'] = tmdb_movie_gross['foreign_gross'].astype(float)\n",
    "tmdb_movie_gross['foreign_gross'] = tmdb_movie_gross['foreign_gross'].fillna(0)\n",
    "\n",
    "# Because there were 5 entries that were null in Studio, we change the null value to a string that says \"N/A\" which just means that we don't know the studio that produced the film\n",
    "tmdb_movie_gross['studio'] = tmdb_movie_gross['studio'].fillna('N/A')\n",
    "\n",
    "#Display Movie_Gross Data\n",
    "tmdb_movie_gross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display info, type, and # of values in each column\n",
    "tmdb_movie_gross.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test to see if all columns have the same ammount of values\n",
    "tmdb_movie_gross.duplicated().value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test to see if there are NaN values\n",
    "tmdb_movie_gross.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Peer Programing/Assisting with Elliot's Branch for Data Viz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Coppied Over for Review\n",
    "\n",
    "#read tmdb file, make sure values are in the same format, and drop null values\n",
    "tmdb_movie_db = pd.read_csv('databases/tmdb.movies.csv', na_filter=True, na_values='[]', encoding = 'utf-8', index_col = 0)\n",
    "tmdb_movie_db.dropna()\n",
    "#drop extra title column\n",
    "tmdb_movie_db = tmdb_movie_db.drop('original_title', axis = 1)\n",
    "#standardize release date into date format\n",
    "tmdb_movie_db['release_date'] = pd.to_datetime(tmdb_movie_db['release_date'])\n",
    "#strip whitespace from title\n",
    "tmdb_movie_db['title'] = tmdb_movie_db['title'].str.strip()\n",
    "#remove duplicates\n",
    "tmdb_movie_db = tmdb_movie_db.drop_duplicates()\n",
    "#convert genre_ids to name\n",
    "#df.where()\n",
    "\n",
    "tmdb_movie_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Coppied Over for Review\n",
    "\n",
    "#read tn file, make sure values are in the same format, and drop null values\n",
    "tn_movie_db = pd.read_csv('databases/tn.movie_budgets.csv', na_filter=True, na_values='[]', encoding = 'utf-8', index_col = 0)\n",
    "tn_movie_db.dropna()\n",
    "#standardize release date into date format\n",
    "tn_movie_db['release_date'] = pd.to_datetime(tn_movie_db['release_date'])\n",
    "#strip whitespace from title\n",
    "tn_movie_db['movie'] = tn_movie_db['movie'].str.strip()\n",
    "#strip $\n",
    "tn_movie_db['production_budget'] = tn_movie_db['production_budget'].str.strip('$')\n",
    "tn_movie_db['domestic_gross'] = tn_movie_db['domestic_gross'].str.strip('$')\n",
    "tn_movie_db['worldwide_gross'] = tn_movie_db['worldwide_gross'].str.strip('$')\n",
    "#remove ,\n",
    "tn_movie_db['production_budget'] = tn_movie_db['production_budget'].replace(\",\", \"\", regex=True)\n",
    "tn_movie_db['domestic_gross'] = tn_movie_db['domestic_gross'].replace(\",\", \"\", regex=True)\n",
    "tn_movie_db['worldwide_gross'] = tn_movie_db['worldwide_gross'].replace(\",\", \"\", regex=True)\n",
    "#convert to integers\n",
    "tn_movie_db['production_budget'] = tn_movie_db['production_budget'].astype(int)\n",
    "tn_movie_db['domestic_gross'] = tn_movie_db['domestic_gross'].astype(int)\n",
    "tn_movie_db['worldwide_gross'] = tn_movie_db['worldwide_gross'].astype(float)\n",
    "#create metric ratios\n",
    "tn_movie_db['dom_gross / budget'] = tn_movie_db['domestic_gross'] / tn_movie_db['production_budget']\n",
    "tn_movie_db['ww_gross / budget'] = tn_movie_db['worldwide_gross'] / tn_movie_db['production_budget']\n",
    "tn_movie_db['dom_profit'] = tn_movie_db['domestic_gross'] - tn_movie_db['production_budget']\n",
    "tn_movie_db['profit'] = tn_movie_db['worldwide_gross'] - tn_movie_db['production_budget']\n",
    "\n",
    "tn_movie_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Copied Over for Review \n",
    "\n",
    "#merge title and movie name\n",
    "tn_movie_db = tn_movie_db.rename(columns = {\"movie\":\"title\"})\n",
    "\n",
    "#special cases where movie titles do not match\n",
    "tn_movie_db['title'].replace({'Harry Potter and the Deathly Hallows: Part I' : 'Harry Potter and the Deathly Hallows: Part 1'}, inplace=True)\n",
    "tn_movie_db['title'].replace({'Harry Potter and the Deathly Hallows: Part II' : 'Harry Potter and the Deathly Hallows: Part 2'}, inplace=True)\n",
    "tmdb_movie_db['title'].replace({'Fast & Furious 6':'Fast and Furious 6'}, inplace=True)\n",
    "tn_movie_db['title'].replace({'Star Wars: The Force Awakens' : 'Star Wars Ep. VII: The Force Awakens'}, inplace=True)\n",
    "tn_movie_db['title'].replace({'Star Wars: The Last Jedi' : 'Star Wars Ep. VIII: The Last Jedi'}, inplace=True)\n",
    "\n",
    "#merge databases\n",
    "movie_db = tmdb_movie_db.merge(tn_movie_db, how = 'left')\n",
    "\n",
    "\n",
    "#drop null values\n",
    "movie_db = movie_db.dropna()\n",
    "\n",
    "movie_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check to make sure that there are no values with 0\n",
    "## new_movie_db.loc[movie_db['worldwide_gross'] < 1]\n",
    "## sorted(new_movie_db['worldwide_gross'].value_counts().index.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_movie_db = movie_db.drop(movie_db[movie_db['domestic_gross'] < 1].index)\n",
    "new_movie_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check + count all values\n",
    "movie_db['genre_ids'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Bar Chart\n",
    "## Genre's X Axis is conjested\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 12))\n",
    "\n",
    "#ax.hist(movie_db['dom_gross / budget'].mean(), 10, tick_label = movie_db['genre_ids'])\n",
    "ax.hist(movie_db['genre_ids'], bins='auto')\n",
    "\n",
    "ax.set_title('Average Dom_gross / Budget Ratio per Genres')\n",
    "ax.set_ylabel('Average Dom_gross / Budget')\n",
    "ax.set_xlabel('Movie Genres');\n",
    "\n",
    "\n",
    "\n",
    "#x = movie_db['genre_ids']\n",
    "\n",
    "#y = movie_db['dom_gross / budget'].mean()\n",
    "\n",
    "#plt.hist(x, bins = 1000, edgecolor='black', color='#00C8AD')\n",
    "#plt.xlabel('Movie Genres')\n",
    "#plt.ylabel('Average Dom_gross / Budget')\n",
    "#plt.title('Average Dom_gross / Budget Ratio per Genres')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = movie_db['genre_ids']\n",
    "\n",
    "y = movie_db['ww_gross / budget'].mean()\n",
    "\n",
    "plt.hist(x, bins = 50, edgecolor='black')\n",
    "plt.xlabel('Movie Genres')\n",
    "plt.ylabel('Average WW_gross / Budget')\n",
    "plt.title('Average WW_gross / Budget Ratio per Genres')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'profit per genre'\n",
    "\n",
    "### Coppied Over for Peer Review\n",
    "\n",
    "## fig, ax = plt.subplots(figsize=(10, 12))\n",
    "## ax.hist(movie_db['dom_gross / budget'].mean(), 10, tick_label = movie_db['genre_ids'])\n",
    "## ax.hist(movie_db['genre_ids'], bins='auto')\n",
    "\n",
    "#ax.set_title('Profit by Genre')\n",
    "#ax.set_ylabel('Movie Profit')\n",
    "#x.set_xlabel('Movie Genres');\n",
    "\n",
    "# 'profit per genre'\n",
    "\n",
    "#df_mr1.value_counts('genres').nlargest(12)\n",
    "\n",
    "#for z test\n",
    "#df_mr1.describe()\n",
    "\n",
    "##ztest ,propability_value = stests.ztest(dataframe['movie_db'], x2=None, value=146)\n",
    "##print(float(propability_value))\n",
    "##if propability_value<0.05:\n",
    "##print(\"Null hyphothesis rejected , Alternative hyphothesis accepted\")\n",
    "##else:\n",
    "##print(\"Null hyphothesis accepted , Alternative hyphothesis rejected\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
